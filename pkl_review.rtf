{\rtf1\ansi\ansicpg949\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fmodern\fcharset0 Courier;}
{\colortbl;\red255\green255\blue255;\red245\green245\blue245;\red0\green0\blue0;\red131\green0\blue165;
\red144\green1\blue18;\red15\green112\blue1;\red0\green0\blue255;\red86\green65\blue25;\red0\green0\blue109;
\red19\green85\blue52;\red31\green99\blue128;}
{\*\expandedcolortbl;;\cssrgb\c96863\c96863\c96863;\cssrgb\c0\c0\c0;\cssrgb\c59216\c13725\c70588;
\cssrgb\c63922\c8235\c8235;\cssrgb\c0\c50196\c0;\cssrgb\c0\c0\c100000;\cssrgb\c41569\c32157\c12941;\cssrgb\c0\c6275\c50196;
\cssrgb\c6667\c40000\c26667;\cssrgb\c14510\c46275\c57647;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\deftab720
\pard\pardeftab720\partightenfactor0

\f0\fs28 \cf0 \cb2 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec3   \cf4 \strokec4 import\cf0 \strokec3  numpy \cf4 \strokec4 as\cf0 \strokec3  np\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  matplotlib.pyplot \cf4 \strokec4 as\cf0 \strokec3  plt\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  seaborn \cf4 \strokec4 as\cf0 \strokec3  sns\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  pandas \cf4 \strokec4 as\cf0 \strokec3  pd\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  os\cb1 \
\cb2   \cf4 \strokec4 from\cf0 \strokec3  scipy \cf4 \strokec4 import\cf0 \strokec3  stats\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  pickle\cb1 \
\cb2   \cf4 \strokec4 from\cf0 \strokec3  tqdm \cf4 \strokec4 import\cf0 \strokec3  tqdm\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  warnings\cb1 \
\cb2   \cf4 \strokec4 from\cf0 \strokec3  collections \cf4 \strokec4 import\cf0 \strokec3  deque\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  random\cb1 \
\cb2   warnings.filterwarnings(\cf5 \strokec5 'ignore'\cf0 \strokec3 )\cb1 \
\cb2   \cf4 \strokec4 import\cf0 \strokec3  pandas \cf4 \strokec4 as\cf0 \strokec3  pd\cb1 \
\
\
\cb2   \cf6 \strokec6 # Create result directories\cf0 \cb1 \strokec3 \
\cb2   os.makedirs(\cf5 \strokec5 "content/Results"\cf0 \strokec3 , exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2   os.makedirs(\cf5 \strokec5 "content/Results"\cf0 \strokec3 , exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  MetaAnalysisManager:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Manages meta-analysis using Fibonacci sequence master seeds"""\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf6 \strokec6 # Fibonacci sequence (for meta-analysis)\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .SEEDS = [\cf10 \strokec10 34\cf0 \strokec3 , \cf10 \strokec10 55\cf0 \strokec3 , \cf10 \strokec10 89\cf0 \strokec3 , \cf10 \strokec10 144\cf0 \strokec3 , \cf10 \strokec10 233\cf0 \strokec3 , \cf10 \strokec10 377\cf0 \strokec3 , \cf10 \strokec10 610\cf0 \strokec3 , \cf10 \strokec10 987\cf0 \strokec3 , \cf10 \strokec10 1597\cf0 \strokec3 , \cf10 \strokec10 2584\cf0 \strokec3 , \cf10 \strokec10 4181\cf0 \strokec3 , \cf10 \strokec10 6765\cf0 \strokec3 ]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED = \cf10 \strokec10 300\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_SEEDS = [\cf10 \strokec10 34\cf0 \strokec3 , \cf10 \strokec10 55\cf0 \strokec3 , \cf10 \strokec10 89\cf0 \strokec3 ]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_N_RUNS_PER_SEED = \cf10 \strokec10 300\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .TOTAL_EXPERIMENTS = \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .SEEDS) * \cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED\cb1 \
\
\
\cb2         \cf6 \strokec6 # Logging and tracking\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .seed_logs = \{\}\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .meta_results = \{\}\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_seeds_and_runs\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Get environment-specific seeds and runs"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .SEEDS, \cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 generate_experiment_seeds\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 master_seed\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Generate experiment seeds from a Fibonacci master seed"""\cf0 \cb1 \strokec3 \
\cb2         np.random.seed(master_seed)\cb1 \
\cb2         experiment_seeds = []\cb1 \
\
\cb2         n_runs = \cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED  \cf6 \strokec6 # 300\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Generate experiment seeds\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (n_runs):\cb1 \
\cb2             seed = np.random.randint(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1000000\cf0 \strokec3 )  \cf6 \strokec6 # Wide range to avoid collisions\cf0 \cb1 \strokec3 \
\cb2             experiment_seeds.append(seed)\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .seed_logs[master_seed] = \{\cb1 \
\cb2             \cf5 \strokec5 'first_10_seeds'\cf0 \strokec3 : experiment_seeds[:\cf10 \strokec10 10\cf0 \strokec3 ],\cb1 \
\cb2             \cf5 \strokec5 'total_seeds'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (experiment_seeds),\cb1 \
\cb2             \cf5 \strokec5 'seed_range'\cf0 \strokec3 : [\cf8 \strokec8 min\cf0 \strokec3 (experiment_seeds), \cf8 \strokec8 max\cf0 \strokec3 (experiment_seeds)]\cb1 \
\cb2         \}\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  experiment_seeds\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 save_configuration\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 filepath\cf0 \strokec3 =\cf5 \strokec5 "content/Results/config.txt"\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Save complete meta-analysis configuration"""\cf0 \cb1 \strokec3 \
\cb2         os.makedirs(os.path.dirname(filepath), exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (filepath, \cf5 \strokec5 'w'\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2             f.write(\cf5 \strokec5 "Meta-Analysis Configuration\\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 50\cf0 \strokec3  + \cf5 \strokec5 "\\n\\n"\cf0 \strokec3 )\cb1 \
\
\cb2             \cf6 \strokec6 # Regular environments\cf0 \cb1 \strokec3 \
\cb2             f.write(\cf5 \strokec5 "REGULAR ENVIRONMENTS (EnvA, EnvB, EnvC):\\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Master Seeds: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .SEEDS\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Runs per Master Seed: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Total Experiments: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .SEEDS) * \cf9 \strokec9 self\cf0 \strokec3 .N_RUNS_PER_SEED\}\cf5 \strokec5 \\n\\n"\cf0 \strokec3 )\cb1 \
\
\cb2             \cf6 \strokec6 # RandomShift environment\cf0 \cb1 \strokec3 \
\cb2             f.write(\cf5 \strokec5 "CROSS-DATASET ENVIRONMENT (RandomShift):\\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Master Seeds: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_SEEDS\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Runs per Master Seed: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_N_RUNS_PER_SEED\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf7 \strokec7 f\cf5 \strokec5 "Total Experiments: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_SEEDS) * \cf9 \strokec9 self\cf0 \strokec3 .RANDOMSHIFT_N_RUNS_PER_SEED\}\cf5 \strokec5 \\n\\n"\cf0 \strokec3 )\cb1 \
\
\cb2             f.write(\cf5 \strokec5 "Seed Generation Details:\\n"\cf0 \strokec3 )\cb1 \
\cb2             f.write(\cf5 \strokec5 "-"\cf0 \strokec3  * \cf10 \strokec10 30\cf0 \strokec3  + \cf5 \strokec5 "\\n"\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  master_seed, log \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .seed_logs.items():\cb1 \
\cb2                 f.write(\cf7 \strokec7 f\cf5 \strokec5 "Master Seed \cf0 \strokec3 \{master_seed\}\cf5 \strokec5 :\\n"\cf0 \strokec3 )\cb1 \
\cb2                 f.write(\cf7 \strokec7 f\cf5 \strokec5 "  First 10 experiment seeds: \cf0 \strokec3 \{log[\cf5 \strokec5 'first_10_seeds'\cf0 \strokec3 ]\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2                 f.write(\cf7 \strokec7 f\cf5 \strokec5 "  Seed range: \cf0 \strokec3 \{log[\cf5 \strokec5 'seed_range'\cf0 \strokec3 ]\}\cf5 \strokec5 \\n"\cf0 \strokec3 )\cb1 \
\cb2                 f.write(\cf7 \strokec7 f\cf5 \strokec5 "  Total generated: \cf0 \strokec3 \{log[\cf5 \strokec5 'total_seeds'\cf0 \strokec3 ]\}\cf5 \strokec5 \\n\\n"\cf0 \strokec3 )\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # Global manager instances\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2 MANAGER = MetaAnalysisManager()\cb1 \
\
\cb2   \cf7 \strokec7 class\cf0 \strokec3  EnvironmentA:\cb1 \
\cb2       \cf5 \strokec5 """Environment A with deterministic seed control"""\cf0 \cb1 \strokec3 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 total_trials\cf0 \strokec3 =\cf10 \strokec10 200\cf0 \strokec3 , \cf9 \strokec9 sigma\cf0 \strokec3 =\cf10 \strokec10 0.15\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .total_trials = total_trials\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .n_actions = \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .sigma = sigma\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2           \cf6 \strokec6 # Set up reproducible random state\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_context()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 step\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2           reward = \cf9 \strokec9 self\cf0 \strokec3 .get_reward(action)\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_context()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  reward, \cf9 \strokec9 self\cf0 \strokec3 .context\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_reward\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2           t = \cf9 \strokec9 self\cf0 \strokec3 .trial\cb1 \
\cb2           \cf4 \strokec4 if\cf0 \strokec3  t < \cf10 \strokec10 50\cf0 \strokec3 :\cb1 \
\cb2               means = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 ]\cb1 \
\cb2           \cf4 \strokec4 elif\cf0 \strokec3  t < \cf10 \strokec10 100\cf0 \strokec3 :\cb1 \
\cb2               means = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.3\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 ]\cb1 \
\cb2           \cf4 \strokec4 elif\cf0 \strokec3  t < \cf10 \strokec10 150\cf0 \strokec3 :\cb1 \
\cb2               means = [\cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.3\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 ]\cb1 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               means = [\cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.4\cf0 \strokec3 , \cf10 \strokec10 0.3\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 ]\cb1 \
\
\cb2           \cf6 \strokec6 # Use controlled random state for noise\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.normal(means[action], \cf9 \strokec9 self\cf0 \strokec3 .sigma)\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_context\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           t = \cf9 \strokec9 self\cf0 \strokec3 .trial\cb1 \
\cb2           norm_t = t / \cf9 \strokec9 self\cf0 \strokec3 .total_trials\cb1 \
\cb2           \cf4 \strokec4 if\cf0 \strokec3  t < \cf10 \strokec10 50\cf0 \strokec3 :\cb1 \
\cb2               phase_id = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 elif\cf0 \strokec3  t < \cf10 \strokec10 100\cf0 \strokec3 :\cb1 \
\cb2               phase_id = \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 elif\cf0 \strokec3  t < \cf10 \strokec10 150\cf0 \strokec3 :\cb1 \
\cb2               phase_id = \cf10 \strokec10 2\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               phase_id = \cf10 \strokec10 3\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = np.array([norm_t, phase_id])\cb1 \
\
\cb2   \cf7 \strokec7 class\cf0 \strokec3  EnvironmentB:\cb1 \
\cb2       \cf5 \strokec5 """Environment B with deterministic seed control"""\cf0 \cb1 \strokec3 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 total_trials\cf0 \strokec3 =\cf10 \strokec10 200\cf0 \strokec3 , \cf9 \strokec9 sigma\cf0 \strokec3 =\cf10 \strokec10 0.05\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .total_trials = total_trials\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .n_actions = \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .sigma = sigma\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2           \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_context()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 step\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2           reward = \cf9 \strokec9 self\cf0 \strokec3 .get_reward(action)\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_context()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  reward, \cf9 \strokec9 self\cf0 \strokec3 .context\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_reward\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2           t = \cf9 \strokec9 self\cf0 \strokec3 .trial\cb1 \
\cb2           base = [\cf10 \strokec10 0.2\cf0 \strokec3 ] * \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2           phase = t // \cf10 \strokec10 40\cf0 \cb1 \strokec3 \
\
\cb2           \cf4 \strokec4 if\cf0 \strokec3  phase % \cf10 \strokec10 2\cf0 \strokec3  == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2               base[\cf10 \strokec10 0\cf0 \strokec3 ] = \cf10 \strokec10 0.95\cf0 \strokec3 ; base[\cf10 \strokec10 4\cf0 \strokec3 ] = \cf10 \strokec10 0.01\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               base[\cf10 \strokec10 0\cf0 \strokec3 ] = \cf10 \strokec10 0.01\cf0 \strokec3 ; base[\cf10 \strokec10 4\cf0 \strokec3 ] = \cf10 \strokec10 0.95\cf0 \cb1 \strokec3 \
\
\cb2           \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  [\cf10 \strokec10 1\cf0 \strokec3 , \cf10 \strokec10 2\cf0 \strokec3 , \cf10 \strokec10 3\cf0 \strokec3 ]:\cb1 \
\cb2               base[i] = \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\
\cb2           reward = base[action] + \cf9 \strokec9 self\cf0 \strokec3 .rng.normal(\cf10 \strokec10 0\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .sigma)\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  np.clip(reward, \cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_context\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           t = \cf9 \strokec9 self\cf0 \strokec3 .trial\cb1 \
\cb2           norm_t = t / \cf9 \strokec9 self\cf0 \strokec3 .total_trials\cb1 \
\cb2           phase = t // \cf10 \strokec10 40\cf0 \cb1 \strokec3 \
\cb2           phase_id = phase % \cf10 \strokec10 2\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = np.array([norm_t, phase_id])\cb1 \
\
\
\cb2   \cf7 \strokec7 class\cf0 \strokec3  EnvironmentC:\cb1 \
\cb2       \cf5 \strokec5 """Environment C with controlled randomness while maintaining stochastic nature"""\cf0 \cb1 \strokec3 \
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 total_trials\cf0 \strokec3 =\cf10 \strokec10 200\cf0 \strokec3 , \cf9 \strokec9 sigma\cf0 \strokec3 =\cf10 \strokec10 0.15\cf0 \strokec3 ,\cb1 \
\cb2                   \cf9 \strokec9 disturbance_prob\cf0 \strokec3 =\cf10 \strokec10 0.05\cf0 \strokec3 , \cf9 \strokec9 disturbance_strength\cf0 \strokec3 =\cf10 \strokec10 0.7\cf0 \strokec3 ,\cb1 \
\cb2                   \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .total_trials = total_trials\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .n_actions = \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .sigma = sigma\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_prob = disturbance_prob\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_strength = disturbance_strength\cb1 \
\
\cb2           \cf6 \strokec6 # Set up controlled random state\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2           \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2           \cf6 \strokec6 # Generate random but reproducible configuration\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 ._generate_random_configuration()\cb1 \
\
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .active_disturbance = \cf7 \strokec7 False\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_action = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_duration = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_reward_structure()\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _generate_random_configuration\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           \cf5 \strokec5 """Generate random configuration using controlled randomness"""\cf0 \cb1 \strokec3 \
\cb2           \cf6 \strokec6 # Generate 3 random change points between 30-180 (but deterministic)\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .change_points = \cf8 \strokec8 sorted\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .rng.choice(\cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 30\cf0 \strokec3 , \cf10 \strokec10 181\cf0 \strokec3 ), size=\cf10 \strokec10 3\cf0 \strokec3 , replace=\cf7 \strokec7 False\cf0 \strokec3 ).tolist())\cb1 \
\
\cb2           \cf6 \strokec6 # Generate different optimal actions and rewards for each segment\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions = []\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .optimal_rewards = []\cb1 \
\cb2           used_actions = \cf11 \strokec11 set\cf0 \strokec3 ()\cb1 \
\
\cb2           \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 4\cf0 \strokec3 ):  \cf6 \strokec6 # 4 segments total\cf0 \cb1 \strokec3 \
\cb2               \cf6 \strokec6 # Ensure different optimal action for each segment\cf0 \cb1 \strokec3 \
\cb2               \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (used_actions) < \cf9 \strokec9 self\cf0 \strokec3 .n_actions:\cb1 \
\cb2                   unused_actions = [a \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions) \cf4 \strokec4 if\cf0 \strokec3  a \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  used_actions]\cb1 \
\cb2                   \cf4 \strokec4 if\cf0 \strokec3  unused_actions:\cb1 \
\cb2                       opt_action = \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(unused_actions)\cb1 \
\cb2                   \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                       prev_action = \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions[\cf10 \strokec10 -1\cf0 \strokec3 ] \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 -1\cf0 \cb1 \strokec3 \
\cb2                       opt_action = (prev_action + \cf10 \strokec10 1\cf0 \strokec3 ) % \cf9 \strokec9 self\cf0 \strokec3 .n_actions\cb1 \
\cb2               \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                   prev_action = \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions[\cf10 \strokec10 -1\cf0 \strokec3 ] \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 -1\cf0 \cb1 \strokec3 \
\cb2                   available_actions = [a \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions) \cf4 \strokec4 if\cf0 \strokec3  a != prev_action]\cb1 \
\cb2                   opt_action = \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(available_actions)\cb1 \
\
\cb2               used_actions.add(opt_action)\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions.append(opt_action)\cb1 \
\
\cb2               \cf6 \strokec6 # Generate different optimal reward levels\cf0 \cb1 \strokec3 \
\cb2               opt_reward = \cf9 \strokec9 self\cf0 \strokec3 .rng.uniform(\cf10 \strokec10 0.75\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 )\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .optimal_rewards.append(opt_reward)\cb1 \
\
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .active_disturbance = \cf7 \strokec7 False\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_action = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .disturbance_duration = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_reward_structure()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 step\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2           reward = \cf9 \strokec9 self\cf0 \strokec3 .rng.normal(\cf9 \strokec9 self\cf0 \strokec3 .means[action], \cf9 \strokec9 self\cf0 \strokec3 .sigma)\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .trial += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .update_reward_structure()\cb1 \
\cb2           \cf4 \strokec4 return\cf0 \strokec3  reward, \cf9 \strokec9 self\cf0 \strokec3 .context\cb1 \
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_reward_structure\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           t = \cf9 \strokec9 self\cf0 \strokec3 .trial\cb1 \
\cb2           norm_t = t / \cf9 \strokec9 self\cf0 \strokec3 .total_trials\cb1 \
\
\cb2           \cf6 \strokec6 # Determine current segment\cf0 \cb1 \strokec3 \
\cb2           phase = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 for\cf0 \strokec3  i, cp \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .change_points):\cb1 \
\cb2               \cf4 \strokec4 if\cf0 \strokec3  t >= cp:\cb1 \
\cb2                   phase = i + \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2               \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                   \cf4 \strokec4 break\cf0 \cb1 \strokec3 \
\
\cb2           optimal_action = \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions[phase]\cb1 \
\cb2           optimal_reward = \cf9 \strokec9 self\cf0 \strokec3 .optimal_rewards[phase]\cb1 \
\
\cb2           \cf6 \strokec6 # Set basic reward structure\cf0 \cb1 \strokec3 \
\cb2           means = [\cf10 \strokec10 0.2\cf0 \strokec3 ] * \cf9 \strokec9 self\cf0 \strokec3 .n_actions\cb1 \
\cb2           means[optimal_action] = optimal_reward\cb1 \
\
\cb2           \cf6 \strokec6 # Handle disturbances with controlled randomness\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .active_disturbance:\cb1 \
\cb2               \cf9 \strokec9 self\cf0 \strokec3 .disturbance_duration -= \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2               \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .disturbance_duration > \cf10 \strokec10 0\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .disturbance_action != optimal_action:\cb1 \
\cb2                   means[\cf9 \strokec9 self\cf0 \strokec3 .disturbance_action] = \cf9 \strokec9 self\cf0 \strokec3 .disturbance_strength\cb1 \
\cb2               \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                   \cf9 \strokec9 self\cf0 \strokec3 .active_disturbance = \cf7 \strokec7 False\cf0 \cb1 \strokec3 \
\cb2                   \cf9 \strokec9 self\cf0 \strokec3 .disturbance_action = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2           \cf4 \strokec4 elif\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.random() < \cf9 \strokec9 self\cf0 \strokec3 .disturbance_prob:\cb1 \
\cb2               non_optimal_actions = [a \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions) \cf4 \strokec4 if\cf0 \strokec3  a != optimal_action]\cb1 \
\cb2               \cf4 \strokec4 if\cf0 \strokec3  non_optimal_actions:\cb1 \
\cb2                   \cf9 \strokec9 self\cf0 \strokec3 .disturbance_action = \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(non_optimal_actions)\cb1 \
\cb2                   \cf9 \strokec9 self\cf0 \strokec3 .active_disturbance = \cf7 \strokec7 True\cf0 \cb1 \strokec3 \
\cb2                   \cf9 \strokec9 self\cf0 \strokec3 .disturbance_duration = \cf9 \strokec9 self\cf0 \strokec3 .rng.randint(\cf10 \strokec10 1\cf0 \strokec3 , \cf10 \strokec10 3\cf0 \strokec3 )\cb1 \
\cb2                   means[\cf9 \strokec9 self\cf0 \strokec3 .disturbance_action] = \cf9 \strokec9 self\cf0 \strokec3 .disturbance_strength\cb1 \
\
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .means = means\cb1 \
\cb2           \cf9 \strokec9 self\cf0 \strokec3 .context = np.array([norm_t, phase])\cb1 \
\
\
\
\cb2       \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_current_optimal_info\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2           \cf5 \strokec5 """Get current segment's optimal action and reward"""\cf0 \cb1 \strokec3 \
\cb2           phase = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \cf4 \strokec4 for\cf0 \strokec3  i, cp \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .change_points):\cb1 \
\cb2               \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .trial >= cp:\cb1 \
\cb2                   phase = i + \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2               \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                   \cf4 \strokec4 break\cf0 \cb1 \strokec3 \
\
\cb2           \cf4 \strokec4 return\cf0 \strokec3  \{\cb1 \
\cb2               \cf5 \strokec5 'phase'\cf0 \strokec3 : phase,\cb1 \
\cb2               \cf5 \strokec5 'optimal_action'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .optimal_actions[phase],\cb1 \
\cb2               \cf5 \strokec5 'optimal_reward'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .optimal_rewards[phase],\cb1 \
\cb2               \cf5 \strokec5 'change_point'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .change_points[phase\cf10 \strokec10 -1\cf0 \strokec3 ] \cf4 \strokec4 if\cf0 \strokec3  phase > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2           \}\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # =====================\cf0 \cb1 \strokec3 \
\cf6 \cb2 \strokec6 # 1. RandomShiftEnvironment\cf0 \cb1 \strokec3 \
\cf6 \cb2 \strokec6 # =====================\cf0 \cb1 \strokec3 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  RandomShiftEnvironment:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 total_trials\cf0 \strokec3 =\cf10 \strokec10 600\cf0 \strokec3 , \cf9 \strokec9 n_actions\cf0 \strokec3 =\cf10 \strokec10 5\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .total_trials = total_trials\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .n_actions = n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .sigma = \cf10 \strokec10 0.12\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Master seed for reproducibility\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .master_rng = np.random.RandomState(random_state)\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .master_rng = np.random.RandomState()\cb1 \
\
\cb2         \cf6 \strokec6 # Enhanced features for ECIA\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history = deque(maxlen=\cf10 \strokec10 50\cf0 \strokec3 )  \cf6 \strokec6 # For pattern analysis\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_sequence = deque(maxlen=\cf10 \strokec10 10\cf0 \strokec3 )  \cf6 \strokec6 # For sequence rewards\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .extreme_event_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Pattern storage for reuse (ECIA advantage)\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .stored_patterns = []  \cf6 \strokec6 # Store patterns from phase 1\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Multi-layered temporal patterns\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .short_term_cycle = \cf10 \strokec10 0\cf0 \strokec3   \cf6 \strokec6 # 10-15 trials\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .medium_term_cycle = \cf10 \strokec10 0\cf0 \strokec3   \cf6 \strokec6 # 50-80 trials\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .long_term_phase = \cf10 \strokec10 0\cf0 \strokec3    \cf6 \strokec6 # 150+ trials\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Generate enhanced segment schedule\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .segments = \cf9 \strokec9 self\cf0 \strokec3 ._generate_enhanced_segments()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .segment_start_trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Current state\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_rewards = [\cf10 \strokec10 0.2\cf0 \strokec3 ] * \cf9 \strokec9 self\cf0 \strokec3 .n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .base_noise_level = \cf10 \strokec10 0.12\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Initialize first segment\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._initialize_current_segment()\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _generate_enhanced_segments\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Generate segments with rich complexity patterns and pattern reuse"""\cf0 \cb1 \strokec3 \
\cb2         segments = []\cb1 \
\cb2         current_trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Long-term phases (3 phases of ~200 trials each)\cf0 \cb1 \strokec3 \
\cb2         phase_types = [\cf5 \strokec5 'learning'\cf0 \strokec3 , \cf5 \strokec5 'challenging'\cf0 \strokec3 , \cf5 \strokec5 'mastery'\cf0 \strokec3 ]\cb1 \
\cb2         phase_length = \cf9 \strokec9 self\cf0 \strokec3 .total_trials // \cf10 \strokec10 3\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  phase_idx, phase_type \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (phase_types):\cb1 \
\cb2             phase_start = phase_idx * phase_length\cb1 \
\cb2             phase_end = \cf8 \strokec8 min\cf0 \strokec3 ((phase_idx + \cf10 \strokec10 1\cf0 \strokec3 ) * phase_length, \cf9 \strokec9 self\cf0 \strokec3 .total_trials)\cb1 \
\
\cb2             \cf6 \strokec6 # Generate segments within each phase\cf0 \cb1 \strokec3 \
\cb2             phase_trials = phase_start\cb1 \
\cb2             \cf4 \strokec4 while\cf0 \strokec3  phase_trials < phase_end:\cb1 \
\cb2                 \cf6 \strokec6 # Segment length based on phase type\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  phase_type == \cf5 \strokec5 'learning'\cf0 \strokec3 :\cb1 \
\cb2                     segment_length = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.randint(\cf10 \strokec10 80\cf0 \strokec3 , \cf10 \strokec10 120\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  phase_type == \cf5 \strokec5 'challenging'\cf0 \strokec3 :\cb1 \
\cb2                     segment_length = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.randint(\cf10 \strokec10 60\cf0 \strokec3 , \cf10 \strokec10 100\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 else\cf0 \strokec3 :  \cf6 \strokec6 # mastery\cf0 \cb1 \strokec3 \
\cb2                     segment_length = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.randint(\cf10 \strokec10 40\cf0 \strokec3 , \cf10 \strokec10 80\cf0 \strokec3 )\cb1 \
\
\cb2                 segment_end = \cf8 \strokec8 min\cf0 \strokec3 (phase_trials + segment_length, phase_end)\cb1 \
\
\cb2                 segment = \{\cb1 \
\cb2                     \cf5 \strokec5 'start'\cf0 \strokec3 : phase_trials,\cb1 \
\cb2                     \cf5 \strokec5 'end'\cf0 \strokec3 : segment_end,\cb1 \
\cb2                     \cf5 \strokec5 'length'\cf0 \strokec3 : segment_end - phase_trials,\cb1 \
\cb2                     \cf5 \strokec5 'phase_type'\cf0 \strokec3 : phase_type,\cb1 \
\cb2                     \cf5 \strokec5 'phase_idx'\cf0 \strokec3 : phase_idx,\cb1 \
\cb2                     \cf5 \strokec5 'config'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 ._generate_segment_config(phase_type, phase_idx, segment_end - phase_trials)\cb1 \
\cb2                 \}\cb1 \
\
\cb2                 segments.append(segment)\cb1 \
\cb2                 phase_trials = segment_end\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  segments\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _generate_segment_config\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 phase_type\cf0 \strokec3 , \cf9 \strokec9 phase_idx\cf0 \strokec3 , \cf9 \strokec9 segment_length\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Generate enhanced segment configuration with pattern reuse"""\cf0 \cb1 \strokec3 \
\cb2         config = \{\cb1 \
\cb2             \cf5 \strokec5 'phase_type'\cf0 \strokec3 : phase_type,\cb1 \
\cb2             \cf5 \strokec5 'reward_structure'\cf0 \strokec3 : \cf5 \strokec5 'layered'\cf0 \strokec3 ,\cb1 \
\cb2             \cf5 \strokec5 'is_reused_pattern'\cf0 \strokec3 : \cf7 \strokec7 False\cf0 \cb1 \strokec3 \
\cb2         \}\cb1 \
\
\cb2         \cf6 \strokec6 # Pattern reuse logic (only after phase 1)\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  phase_idx > \cf10 \strokec10 0\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .stored_patterns \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .master_rng.random() < \cf10 \strokec10 0.25\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Reuse pattern from phase 1\cf0 \cb1 \strokec3 \
\cb2             base_pattern = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.choice(\cf9 \strokec9 self\cf0 \strokec3 .stored_patterns)\cb1 \
\
\cb2             \cf6 \strokec6 # 60% identical, 40% similar variation\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .master_rng.random() < \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 \cf6 \strokec6 # Completely identical pattern\cf0 \cb1 \strokec3 \
\cb2                 config.update(base_pattern)\cb1 \
\cb2                 config[\cf5 \strokec5 'is_reused_pattern'\cf0 \strokec3 ] = \cf7 \strokec7 True\cf0 \cb1 \strokec3 \
\cb2                 config[\cf5 \strokec5 'reuse_type'\cf0 \strokec3 ] = \cf5 \strokec5 'identical'\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 \cf6 \strokec6 # Similar pattern with variations\cf0 \cb1 \strokec3 \
\cb2                 config.update(\cf9 \strokec9 self\cf0 \strokec3 ._create_similar_pattern(base_pattern))\cb1 \
\cb2                 config[\cf5 \strokec5 'is_reused_pattern'\cf0 \strokec3 ] = \cf7 \strokec7 True\cf0 \cb1 \strokec3 \
\cb2                 config[\cf5 \strokec5 'reuse_type'\cf0 \strokec3 ] = \cf5 \strokec5 'similar'\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Generate new pattern\cf0 \cb1 \strokec3 \
\cb2             config.update(\cf9 \strokec9 self\cf0 \strokec3 ._generate_new_pattern_config(phase_type, segment_length))\cb1 \
\
\cb2             \cf6 \strokec6 # Store pattern if it's phase 1 (learning phase)\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  phase_idx == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 pattern_to_store = config.copy()\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .stored_patterns.append(pattern_to_store)\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  config\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _generate_new_pattern_config\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 phase_type\cf0 \strokec3 , \cf9 \strokec9 segment_length\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Generate new pattern configuration"""\cf0 \cb1 \strokec3 \
\cb2         \cf6 \strokec6 # Generate layered reward structure with uneven gaps\cf0 \cb1 \strokec3 \
\cb2         actions = \cf11 \strokec11 list\cf0 \strokec3 (\cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions))\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .master_rng.shuffle(actions)\cb1 \
\
\cb2         config = \{\}\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  phase_type == \cf5 \strokec5 'learning'\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Clear hierarchy with uneven gaps for complex learning\cf0 \cb1 \strokec3 \
\cb2             config.update(\{\cb1 \
\cb2                 \cf5 \strokec5 'excellent_actions'\cf0 \strokec3 : actions[:\cf10 \strokec10 1\cf0 \strokec3 ],      \cf6 \strokec6 # 0.80-0.90\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'good_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 1\cf0 \strokec3 :\cf10 \strokec10 2\cf0 \strokec3 ],          \cf6 \strokec6 # 0.75-0.82 (small gap: 0.065)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'medium_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 2\cf0 \strokec3 :\cf10 \strokec10 3\cf0 \strokec3 ],        \cf6 \strokec6 # 0.45-0.55 (large gap: 0.285)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'poor_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 3\cf0 \strokec3 :\cf10 \strokec10 4\cf0 \strokec3 ],          \cf6 \strokec6 # 0.15-0.25 (large gap: 0.30)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'bad_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 4\cf0 \strokec3 :],            \cf6 \strokec6 # 0.05-0.15 (small gap: 0.10)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'noise_multiplier'\cf0 \strokec3 : \cf10 \strokec10 0.8\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'extreme_event_prob'\cf0 \strokec3 : \cf10 \strokec10 0.02\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'sequence_bonus_prob'\cf0 \strokec3 : \cf10 \strokec10 0.1\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3 : segment_length // \cf10 \strokec10 2\cf0 \strokec3 ,  \cf6 \strokec6 # ECIA-specific: sudden reversal\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'shock_magnitude'\cf0 \strokec3 : \cf10 \strokec10 0.4\cf0 \cb1 \strokec3 \
\cb2             \})\cb1 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  phase_type == \cf5 \strokec5 'challenging'\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Moderate hierarchy with context-dependent patterns\cf0 \cb1 \strokec3 \
\cb2             config.update(\{\cb1 \
\cb2                 \cf5 \strokec5 'excellent_actions'\cf0 \strokec3 : actions[:\cf10 \strokec10 1\cf0 \strokec3 ],      \cf6 \strokec6 # 0.80-0.85\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'good_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 1\cf0 \strokec3 :\cf10 \strokec10 3\cf0 \strokec3 ],          \cf6 \strokec6 # 0.75-0.80 (small gap)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'medium_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 3\cf0 \strokec3 :\cf10 \strokec10 4\cf0 \strokec3 ],        \cf6 \strokec6 # 0.40-0.50 (large gap)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'poor_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 4\cf0 \strokec3 :],           \cf6 \strokec6 # 0.20-0.30 (large gap)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'bad_actions'\cf0 \strokec3 : [],\cb1 \
\cb2                 \cf5 \strokec5 'noise_multiplier'\cf0 \strokec3 : \cf10 \strokec10 1.0\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'extreme_event_prob'\cf0 \strokec3 : \cf10 \strokec10 0.05\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'sequence_bonus_prob'\cf0 \strokec3 : \cf10 \strokec10 0.15\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'context_dependent_bonus'\cf0 \strokec3 : \cf10 \strokec10 0.15\cf0 \strokec3 ,  \cf6 \strokec6 # ECIA-specific: context sensitivity\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'memory_window'\cf0 \strokec3 : \cf10 \strokec10 20\cf0 \strokec3   \cf6 \strokec6 # Long-term memory dependency\cf0 \cb1 \strokec3 \
\cb2             \})\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :  \cf6 \strokec6 # mastery\cf0 \cb1 \strokec3 \
\cb2             \cf6 \strokec6 # Complex patterns requiring sophisticated learning\cf0 \cb1 \strokec3 \
\cb2             config.update(\{\cb1 \
\cb2                 \cf5 \strokec5 'excellent_actions'\cf0 \strokec3 : actions[:\cf10 \strokec10 2\cf0 \strokec3 ],      \cf6 \strokec6 # 0.75-0.80\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'good_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 2\cf0 \strokec3 :\cf10 \strokec10 3\cf0 \strokec3 ],          \cf6 \strokec6 # 0.70-0.75 (small gap)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'medium_actions'\cf0 \strokec3 : actions[\cf10 \strokec10 3\cf0 \strokec3 :],         \cf6 \strokec6 # 0.35-0.45 (large gap)\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'poor_actions'\cf0 \strokec3 : [],\cb1 \
\cb2                 \cf5 \strokec5 'bad_actions'\cf0 \strokec3 : [],\cb1 \
\cb2                 \cf5 \strokec5 'noise_multiplier'\cf0 \strokec3 : \cf10 \strokec10 1.2\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'extreme_event_prob'\cf0 \strokec3 : \cf10 \strokec10 0.08\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'sequence_bonus_prob'\cf0 \strokec3 : \cf10 \strokec10 0.2\cf0 \strokec3 ,\cb1 \
\cb2                 \cf5 \strokec5 'expectation_violation_prob'\cf0 \strokec3 : \cf10 \strokec10 0.06\cf0 \strokec3 ,  \cf6 \strokec6 # ECIA-specific: surprise learning\cf0 \cb1 \strokec3 \
\cb2                 \cf5 \strokec5 'long_term_memory_bonus'\cf0 \strokec3 : \cf10 \strokec10 0.1\cf0 \strokec3   \cf6 \strokec6 # Reward for remembering distant past\cf0 \cb1 \strokec3 \
\cb2             \})\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  config\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _create_similar_pattern\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 base_pattern\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Create similar but not identical pattern"""\cf0 \cb1 \strokec3 \
\cb2         similar_pattern = base_pattern.copy()\cb1 \
\
\cb2         \cf6 \strokec6 # Introduce small variations\cf0 \cb1 \strokec3 \
\cb2         variation_type = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.choice([\cf5 \strokec5 'timing'\cf0 \strokec3 , \cf5 \strokec5 'magnitude'\cf0 \strokec3 , \cf5 \strokec5 'order'\cf0 \strokec3 ])\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  variation_type == \cf5 \strokec5 'timing'\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Change timing of key events by \'b120%\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  similar_pattern:\cb1 \
\cb2                 original_point = similar_pattern[\cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3 ]\cb1 \
\cb2                 variation = \cf11 \strokec11 int\cf0 \strokec3 (original_point * \cf10 \strokec10 0.2\cf0 \strokec3 )\cb1 \
\cb2                 similar_pattern[\cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3 ] = original_point + \cf9 \strokec9 self\cf0 \strokec3 .master_rng.randint(-variation, variation+\cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  variation_type == \cf5 \strokec5 'magnitude'\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Slightly adjust reward magnitudes\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'shock_magnitude'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  similar_pattern:\cb1 \
\cb2                 similar_pattern[\cf5 \strokec5 'shock_magnitude'\cf0 \strokec3 ] *= \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 1.2\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'context_dependent_bonus'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  similar_pattern:\cb1 \
\cb2                 similar_pattern[\cf5 \strokec5 'context_dependent_bonus'\cf0 \strokec3 ] *= \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 1.2\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  variation_type == \cf5 \strokec5 'order'\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Swap positions of some action groups\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'good_actions'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  similar_pattern \cf7 \strokec7 and\cf0 \strokec3  \cf5 \strokec5 'medium_actions'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  similar_pattern:\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (similar_pattern[\cf5 \strokec5 'good_actions'\cf0 \strokec3 ]) == \cf10 \strokec10 1\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (similar_pattern[\cf5 \strokec5 'medium_actions'\cf0 \strokec3 ]) == \cf10 \strokec10 1\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Swap good and medium\cf0 \cb1 \strokec3 \
\cb2                     temp = similar_pattern[\cf5 \strokec5 'good_actions'\cf0 \strokec3 ][\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2                     similar_pattern[\cf5 \strokec5 'good_actions'\cf0 \strokec3 ][\cf10 \strokec10 0\cf0 \strokec3 ] = similar_pattern[\cf5 \strokec5 'medium_actions'\cf0 \strokec3 ][\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2                     similar_pattern[\cf5 \strokec5 'medium_actions'\cf0 \strokec3 ][\cf10 \strokec10 0\cf0 \strokec3 ] = temp\cb1 \
\
\cb2         similar_pattern[\cf5 \strokec5 'reuse_type'\cf0 \strokec3 ] = \cf5 \strokec5 'similar'\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  similar_pattern\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _initialize_current_segment\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Initialize current segment"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx >= \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .segments):\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         segment = \cf9 \strokec9 self\cf0 \strokec3 .segments[\cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .segment_start_trial = segment[\cf5 \strokec5 'start'\cf0 \strokec3 ]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._update_rewards()\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _update_rewards\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Update reward structure with enhanced features"""\cf0 \cb1 \strokec3 \
\cb2         segment = \cf9 \strokec9 self\cf0 \strokec3 .segments[\cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx]\cb1 \
\cb2         config = segment[\cf5 \strokec5 'config'\cf0 \strokec3 ]\cb1 \
\cb2         trial_in_segment = \cf9 \strokec9 self\cf0 \strokec3 .trial - \cf9 \strokec9 self\cf0 \strokec3 .segment_start_trial\cb1 \
\
\cb2         \cf6 \strokec6 # Base reward structure with uneven gaps\cf0 \cb1 \strokec3 \
\cb2         rewards = [\cf10 \strokec10 0.2\cf0 \strokec3 ] * \cf9 \strokec9 self\cf0 \strokec3 .n_actions\cb1 \
\
\cb2         \cf6 \strokec6 # Apply layered reward structure\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'excellent_actions'\cf0 \strokec3 , []):\cb1 \
\cb2             rewards[action] = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.80\cf0 \strokec3 , \cf10 \strokec10 0.90\cf0 \strokec3 )\cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'good_actions'\cf0 \strokec3 , []):\cb1 \
\cb2             rewards[action] = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.75\cf0 \strokec3 , \cf10 \strokec10 0.82\cf0 \strokec3 )  \cf6 \strokec6 # Small gap\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'medium_actions'\cf0 \strokec3 , []):\cb1 \
\cb2             rewards[action] = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.45\cf0 \strokec3 , \cf10 \strokec10 0.55\cf0 \strokec3 )  \cf6 \strokec6 # Large gap from good\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'poor_actions'\cf0 \strokec3 , []):\cb1 \
\cb2             rewards[action] = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.15\cf0 \strokec3 , \cf10 \strokec10 0.25\cf0 \strokec3 )  \cf6 \strokec6 # Large gap from medium\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'bad_actions'\cf0 \strokec3 , []):\cb1 \
\cb2             rewards[action] = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.uniform(\cf10 \strokec10 0.05\cf0 \strokec3 , \cf10 \strokec10 0.15\cf0 \strokec3 )  \cf6 \strokec6 # Small gap from poor\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # ECIA-specific features\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._apply_ecia_features(rewards, config, trial_in_segment)\cb1 \
\
\cb2         \cf6 \strokec6 # Apply sequence bonuses/penalties (for all agents)\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._apply_sequence_effects(rewards, config)\cb1 \
\
\cb2         \cf6 \strokec6 # Apply temporal variations\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._apply_temporal_patterns(rewards, trial_in_segment)\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_rewards = rewards\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _apply_ecia_features\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 rewards\cf0 \strokec3 , \cf9 \strokec9 config\cf0 \strokec3 , \cf9 \strokec9 trial_in_segment\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Apply ECIA-specific learning opportunities"""\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Emotional shock (sudden reversal)\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  config \cf7 \strokec7 and\cf0 \strokec3  trial_in_segment == config[\cf5 \strokec5 'emotional_shock_point'\cf0 \strokec3 ]:\cb1 \
\cb2             excellent_actions = config.get(\cf5 \strokec5 'excellent_actions'\cf0 \strokec3 , [])\cb1 \
\cb2             poor_actions = config.get(\cf5 \strokec5 'poor_actions'\cf0 \strokec3 , [])\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  excellent_actions \cf7 \strokec7 and\cf0 \strokec3  poor_actions:\cb1 \
\cb2                 \cf6 \strokec6 # Dramatic reversal: best becomes worst, worst becomes best\cf0 \cb1 \strokec3 \
\cb2                 excellent_action = excellent_actions[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2                 poor_action = poor_actions[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\
\cb2                 \cf6 \strokec6 # Swap their rewards dramatically\cf0 \cb1 \strokec3 \
\cb2                 rewards[excellent_action] = \cf10 \strokec10 0.1\cf0 \strokec3   \cf6 \strokec6 # Dramatic drop\cf0 \cb1 \strokec3 \
\cb2                 rewards[poor_action] = \cf10 \strokec10 0.85\cf0 \strokec3        \cf6 \strokec6 # Dramatic rise\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Context-dependent bonuses\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'context_dependent_bonus'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  config \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) >= \cf10 \strokec10 5\cf0 \strokec3 :\cb1 \
\cb2             recent_avg = np.mean(\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -5\cf0 \strokec3 :])\cb1 \
\cb2             context_bonus = config[\cf5 \strokec5 'context_dependent_bonus'\cf0 \strokec3 ]\cb1 \
\
\cb2             \cf6 \strokec6 # Bonus based on recent performance context\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  recent_avg > \cf10 \strokec10 0.6\cf0 \strokec3 :  \cf6 \strokec6 # Good performance context\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'excellent_actions'\cf0 \strokec3 , []):\cb1 \
\cb2                     rewards[action] += context_bonus\cb1 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  recent_avg < \cf10 \strokec10 0.4\cf0 \strokec3 :  \cf6 \strokec6 # Poor performance context\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  config.get(\cf5 \strokec5 'medium_actions'\cf0 \strokec3 , []):\cb1 \
\cb2                     rewards[action] += context_bonus * \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Long-term memory bonuses\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'long_term_memory_bonus'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  config \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) >= \cf10 \strokec10 30\cf0 \strokec3 :\cb1 \
\cb2             distant_avg = np.mean(\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -30\cf0 \strokec3 :\cf10 \strokec10 -20\cf0 \strokec3 ])\cb1 \
\cb2             recent_avg = np.mean(\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -10\cf0 \strokec3 :])\cb1 \
\
\cb2             \cf6 \strokec6 # Reward for recognizing long-term patterns\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 abs\cf0 \strokec3 (distant_avg - recent_avg) < \cf10 \strokec10 0.1\cf0 \strokec3 :  \cf6 \strokec6 # Similar patterns\cf0 \cb1 \strokec3 \
\cb2                 memory_bonus = config[\cf5 \strokec5 'long_term_memory_bonus'\cf0 \strokec3 ]\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2                     rewards[i] += memory_bonus\cb1 \
\
\cb2         \cf6 \strokec6 # Expectation violation (surprise learning)\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf5 \strokec5 'expectation_violation_prob'\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  config:\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .master_rng.random() < config[\cf5 \strokec5 'expectation_violation_prob'\cf0 \strokec3 ]:\cb1 \
\cb2                 surprise_action = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.randint(\cf10 \strokec10 0\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .master_rng.random() < \cf10 \strokec10 0.7\cf0 \strokec3 :\cb1 \
\cb2                     rewards[surprise_action] = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.95\cf0 \strokec3 , rewards[surprise_action] + \cf10 \strokec10 0.3\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                     rewards[surprise_action] = \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 0.05\cf0 \strokec3 , rewards[surprise_action] - \cf10 \strokec10 0.3\cf0 \strokec3 )\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _apply_sequence_effects\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 rewards\cf0 \strokec3 , \cf9 \strokec9 config\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Apply sequence bonuses/penalties (fair for all agents)"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_sequence) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             last_actions = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_sequence)[\cf10 \strokec10 -3\cf0 \strokec3 :]\cb1 \
\
\cb2             \cf6 \strokec6 # Diversity bonus\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf11 \strokec11 set\cf0 \strokec3 (last_actions)) == \cf10 \strokec10 3\cf0 \strokec3 :  \cf6 \strokec6 # All different\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .master_rng.random() < config.get(\cf5 \strokec5 'sequence_bonus_prob'\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3 ):\cb1 \
\cb2                     \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2                         rewards[i] += \cf10 \strokec10 0.1\cf0 \cb1 \strokec3 \
\
\cb2             \cf6 \strokec6 # Habit penalty\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf11 \strokec11 set\cf0 \strokec3 (last_actions)) == \cf10 \strokec10 1\cf0 \strokec3 :  \cf6 \strokec6 # All same\cf0 \cb1 \strokec3 \
\cb2                 repeated_action = last_actions[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2                 rewards[repeated_action] *= \cf10 \strokec10 0.85\cf0 \strokec3   \cf6 \strokec6 # 15% penalty\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _apply_temporal_patterns\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 rewards\cf0 \strokec3 , \cf9 \strokec9 trial_in_segment\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Apply multi-layered temporal patterns"""\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Short-term cycle (10-15 trials)\cf0 \cb1 \strokec3 \
\cb2         short_cycle_pos = (trial_in_segment % \cf10 \strokec10 12\cf0 \strokec3 ) / \cf10 \strokec10 12.0\cf0 \cb1 \strokec3 \
\cb2         short_modifier = \cf10 \strokec10 0.05\cf0 \strokec3  * np.sin(\cf10 \strokec10 2\cf0 \strokec3  * np.pi * short_cycle_pos)\cb1 \
\
\cb2         \cf6 \strokec6 # Medium-term cycle (50-80 trials)\cf0 \cb1 \strokec3 \
\cb2         medium_cycle_pos = (trial_in_segment % \cf10 \strokec10 65\cf0 \strokec3 ) / \cf10 \strokec10 65.0\cf0 \cb1 \strokec3 \
\cb2         medium_modifier = \cf10 \strokec10 0.03\cf0 \strokec3  * np.cos(\cf10 \strokec10 2\cf0 \strokec3  * np.pi * medium_cycle_pos)\cb1 \
\
\cb2         \cf6 \strokec6 # Apply modifiers\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2             rewards[i] += short_modifier + medium_modifier\cb1 \
\cb2             rewards[i] = \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 0.05\cf0 \strokec3 , \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.95\cf0 \strokec3 , rewards[i]))  \cf6 \strokec6 # Clamp\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 _update_context\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Update context (keeping it fair - same as original)"""\cf0 \cb1 \strokec3 \
\cb2         norm_t = \cf9 \strokec9 self\cf0 \strokec3 .trial / \cf9 \strokec9 self\cf0 \strokec3 .total_trials\cb1 \
\cb2         phase_id = \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx % \cf10 \strokec10 4\cf0 \strokec3   \cf6 \strokec6 # Simple phase cycling\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context = np.array([norm_t, phase_id])\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 step\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Execute one step with enhanced features"""\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Check if we need to move to next segment\cf0 \cb1 \strokec3 \
\cb2         current_segment = \cf9 \strokec9 self\cf0 \strokec3 .segments[\cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx]\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .trial >= current_segment[\cf5 \strokec5 'end'\cf0 \strokec3 ] \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx < \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .segments) - \cf10 \strokec10 1\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 ._initialize_current_segment()\cb1 \
\
\cb2         \cf6 \strokec6 # Update rewards for current trial\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._update_rewards()\cb1 \
\
\cb2         \cf6 \strokec6 # Get base reward\cf0 \cb1 \strokec3 \
\cb2         base_reward = \cf9 \strokec9 self\cf0 \strokec3 .current_rewards[action]\cb1 \
\
\cb2         \cf6 \strokec6 # Apply noise (enhanced based on phase)\cf0 \cb1 \strokec3 \
\cb2         segment = \cf9 \strokec9 self\cf0 \strokec3 .segments[\cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx]\cb1 \
\cb2         noise_multiplier = segment[\cf5 \strokec5 'config'\cf0 \strokec3 ].get(\cf5 \strokec5 'noise_multiplier'\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\cb2         noise = \cf9 \strokec9 self\cf0 \strokec3 .master_rng.normal(\cf10 \strokec10 0\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .sigma * noise_multiplier)\cb1 \
\cb2         final_reward = np.clip(base_reward + noise, \cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Update tracking\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history.append(final_reward)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_sequence.append(action)\cb1 \
\
\cb2         \cf6 \strokec6 # Update trial and context\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .trial += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._update_context()\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  final_reward, \cf9 \strokec9 self\cf0 \strokec3 .context\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Reset environment to initial state"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_segment_idx = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .segment_start_trial = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_sequence.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .extreme_event_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._initialize_current_segment()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 ._update_context()\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_change_points\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Get actual change points for analysis"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  [segment[\cf5 \strokec5 'start'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  segment \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .segments[\cf10 \strokec10 1\cf0 \strokec3 :]]\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_pattern_reuse_info\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Get information about pattern reuse for analysis"""\cf0 \cb1 \strokec3 \
\cb2         reuse_info = []\cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  segment \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .segments:\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  segment[\cf5 \strokec5 'config'\cf0 \strokec3 ].get(\cf5 \strokec5 'is_reused_pattern'\cf0 \strokec3 , \cf7 \strokec7 False\cf0 \strokec3 ):\cb1 \
\cb2                 reuse_info.append(\{\cb1 \
\cb2                     \cf5 \strokec5 'start'\cf0 \strokec3 : segment[\cf5 \strokec5 'start'\cf0 \strokec3 ],\cb1 \
\cb2                     \cf5 \strokec5 'end'\cf0 \strokec3 : segment[\cf5 \strokec5 'end'\cf0 \strokec3 ],\cb1 \
\cb2                     \cf5 \strokec5 'reuse_type'\cf0 \strokec3 : segment[\cf5 \strokec5 'config'\cf0 \strokec3 ].get(\cf5 \strokec5 'reuse_type'\cf0 \strokec3 , \cf5 \strokec5 'unknown'\cf0 \strokec3 )\cb1 \
\cb2                 \})\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  reuse_info\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb2 \strokec4 import\cf0 \strokec3  numpy \cf4 \strokec4 as\cf0 \strokec3  np\cb1 \
\cf4 \cb2 \strokec4 from\cf0 \strokec3  collections \cf4 \strokec4 import\cf0 \strokec3  deque\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  ECIA:\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 n_actions\cf0 \strokec3 =\cf10 \strokec10 5\cf0 \strokec3 , \cf9 \strokec9 epsilon\cf0 \strokec3 =\cf10 \strokec10 0.03\cf0 \strokec3 , \cf9 \strokec9 eta\cf0 \strokec3 =\cf10 \strokec10 0.55\cf0 \strokec3 , \cf9 \strokec9 xi\cf0 \strokec3 =\cf10 \strokec10 0.001\cf0 \strokec3 ,\cb1 \
\cb2                  \cf9 \strokec9 memory_threshold\cf0 \strokec3 =\cf10 \strokec10 0.015\cf0 \strokec3 , \cf9 \strokec9 memory_influence\cf0 \strokec3 =\cf10 \strokec10 0.3\cf0 \strokec3 ,\cb1 \
\cb2                  \cf9 \strokec9 window_size\cf0 \strokec3 =\cf10 \strokec10 30\cf0 \strokec3 , \cf9 \strokec9 min_eta\cf0 \strokec3 =\cf10 \strokec10 0.095\cf0 \strokec3 , \cf9 \strokec9 memory_size\cf0 \strokec3 =\cf10 \strokec10 15\cf0 \strokec3 ,\cb1 \
\cb2                  \cf9 \strokec9 alpha\cf0 \strokec3 =\cf10 \strokec10 0.22\cf0 \strokec3 , \cf9 \strokec9 memory_similarity_threshold\cf0 \strokec3 =\cf10 \strokec10 0.035\cf0 \strokec3 ,\cb1 \
\cb2                  \cf9 \strokec9 top_k\cf0 \strokec3 =\cf10 \strokec10 3\cf0 \strokec3 , \cf9 \strokec9 emotion_decay\cf0 \strokec3 =\cf10 \strokec10 0.96\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2         \cf6 \strokec6 # Basic parameters\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .n_actions = n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .epsilon = epsilon\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .xi = xi\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .alpha = alpha\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_decay = emotion_decay\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .window_size = window_size\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .min_eta = min_eta\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .top_k = top_k\cb1 \
\
\cb2         \cf6 \strokec6 # Dynamic eta adjustment\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .base_eta = eta\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .eta_adaptation_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Memory system\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .base_memory_threshold = memory_threshold\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .base_memory_influence = memory_influence\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_size = memory_size\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_similarity_threshold = memory_similarity_threshold\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_quality_threshold = \cf10 \strokec10 0.15\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history = deque(maxlen=\cf10 \strokec10 20\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_cooldown = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Environment detection\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_effectiveness_tracker = deque(maxlen=\cf10 \strokec10 50\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .environment_stability_tracker = deque(maxlen=\cf10 \strokec10 30\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .change_detection_window = deque(maxlen=\cf10 \strokec10 15\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .stable_performance_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Context clustering\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context_clusters = \{\}\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .cluster_performance = \{\}\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .use_context_clustering = \cf7 \strokec7 True\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Basic initialization\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .time = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Emotion system\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_names = [\cb1 \
\cb2             \cf5 \strokec5 "fear"\cf0 \strokec3 , \cf5 \strokec5 "joy"\cf0 \strokec3 , \cf5 \strokec5 "hope"\cf0 \strokec3 , \cf5 \strokec5 "sadness"\cf0 \strokec3 ,\cb1 \
\cb2             \cf5 \strokec5 "curiosity"\cf0 \strokec3 , \cf5 \strokec5 "anger"\cf0 \strokec3 , \cf5 \strokec5 "pride"\cf0 \strokec3 , \cf5 \strokec5 "shame"\cf0 \cb1 \strokec3 \
\cb2         ]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_weight = np.array([\cb1 \
\cb2             \cf10 \strokec10 -0.15\cf0 \strokec3 , \cf10 \strokec10 0.4\cf0 \strokec3 , \cf10 \strokec10 0.3\cf0 \strokec3 , \cf10 \strokec10 -0.2\cf0 \strokec3 , \cf10 \strokec10 0.35\cf0 \strokec3 , \cf10 \strokec10 -0.25\cf0 \strokec3 , \cf10 \strokec10 0.25\cf0 \strokec3 , \cf10 \strokec10 -0.3\cf0 \cb1 \strokec3 \
\cb2         ])\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .max_total_emotion_energy = \cf10 \strokec10 2.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_momentum = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Memory storage\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory = []\cb1 \
\
\cb2         \cf6 \strokec6 # Other variables\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker = deque(maxlen=\cf10 \strokec10 25\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes = deque(maxlen=\cf10 \strokec10 10\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_history = deque(maxlen=\cf10 \strokec10 20\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history = deque(maxlen=\cf10 \strokec10 20\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .successful_emotion_patterns = \{\}\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .neurogenesis_cycle = \cf10 \strokec10 25\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_learning_rates = np.array([\cb1 \
\cb2             \cf10 \strokec10 0.15\cf0 \strokec3 , \cf10 \strokec10 0.25\cf0 \strokec3 , \cf10 \strokec10 0.20\cf0 \strokec3 , \cf10 \strokec10 0.12\cf0 \strokec3 , \cf10 \strokec10 0.30\cf0 \strokec3 , \cf10 \strokec10 0.18\cf0 \strokec3 , \cf10 \strokec10 0.22\cf0 \strokec3 , \cf10 \strokec10 0.28\cf0 \cb1 \strokec3 \
\cb2         ])\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_action_history = deque(maxlen=\cf10 \strokec10 12\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context_change_threshold = \cf10 \strokec10 0.1\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .habit_strength_factor = \cf10 \strokec10 0.025\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 assess_environment_stability\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Comprehensive environment stability assessment"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes) < \cf10 \strokec10 5\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Context change stability\cf0 \cb1 \strokec3 \
\cb2         context_changes = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes)\cb1 \
\cb2         avg_change = np.mean(context_changes)\cb1 \
\cb2         change_variance = np.var(context_changes)\cb1 \
\cb2         context_stability = \cf10 \strokec10 1.0\cf0 \strokec3  - \cf8 \strokec8 min\cf0 \strokec3 (avg_change + change_variance * \cf10 \strokec10 0.5\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Reward stability\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) >= \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             recent_rewards = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -10\cf0 \strokec3 :]\cb1 \
\cb2             reward_stability = \cf10 \strokec10 1.0\cf0 \strokec3  - \cf8 \strokec8 min\cf0 \strokec3 (np.std(recent_rewards), \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             reward_stability = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Performance trend stability\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker) >= \cf10 \strokec10 8\cf0 \strokec3 :\cb1 \
\cb2             recent_performance = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker)[\cf10 \strokec10 -8\cf0 \strokec3 :]\cb1 \
\cb2             performance_trend = \cf8 \strokec8 abs\cf0 \strokec3 (np.polyfit(\cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 8\cf0 \strokec3 ), recent_performance, \cf10 \strokec10 1\cf0 \strokec3 )[\cf10 \strokec10 0\cf0 \strokec3 ])\cb1 \
\cb2             trend_stability = \cf10 \strokec10 1.0\cf0 \strokec3  - \cf8 \strokec8 min\cf0 \strokec3 (performance_trend * \cf10 \strokec10 5\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             trend_stability = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Overall stability\cf0 \cb1 \strokec3 \
\cb2         stability = \cf10 \strokec10 0.4\cf0 \strokec3  * context_stability + \cf10 \strokec10 0.4\cf0 \strokec3  * reward_stability + \cf10 \strokec10 0.2\cf0 \strokec3  * trend_stability\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .environment_stability_tracker.append(stability)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.mean(\cf9 \strokec9 self\cf0 \strokec3 .environment_stability_tracker) \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .environment_stability_tracker \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 evaluate_memory_effectiveness\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Memory system effectiveness evaluation"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history) < \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         memory_used_rewards = [r \cf4 \strokec4 for\cf0 \strokec3  used, r \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history \cf4 \strokec4 if\cf0 \strokec3  used]\cb1 \
\cb2         memory_unused_rewards = [r \cf4 \strokec4 for\cf0 \strokec3  used, r \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  used]\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (memory_used_rewards) > \cf10 \strokec10 3\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (memory_unused_rewards) > \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             used_avg = np.mean(memory_used_rewards)\cb1 \
\cb2             unused_avg = np.mean(memory_unused_rewards)\cb1 \
\cb2             effectiveness = (used_avg - unused_avg + \cf10 \strokec10 1.0\cf0 \strokec3 ) / \cf10 \strokec10 2.0\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             effectiveness = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_effectiveness_tracker.append(effectiveness)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.mean(\cf9 \strokec9 self\cf0 \strokec3 .memory_effectiveness_tracker) \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_effectiveness_tracker \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 detect_environment_change\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Environment change detection"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) < \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 False\cf0 \cb1 \strokec3 \
\
\cb2         recent_rewards = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -10\cf0 \strokec3 :]\cb1 \
\cb2         older_rewards = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -20\cf0 \strokec3 :\cf10 \strokec10 -10\cf0 \strokec3 ] \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) >= \cf10 \strokec10 20\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  recent_rewards\cb1 \
\
\cb2         recent_mean = np.mean(recent_rewards)\cb1 \
\cb2         older_mean = np.mean(older_rewards)\cb1 \
\cb2         performance_drop = older_mean - recent_mean > \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\cb2         performance_volatility = np.std(recent_rewards) > \cf10 \strokec10 0.25\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  performance_drop \cf7 \strokec7 or\cf0 \strokec3  performance_volatility\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 calculate_memory_need\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Memory need score calculation (0~1)"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history) < \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Performance volatility\cf0 \cb1 \strokec3 \
\cb2         recent_rewards = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)[\cf10 \strokec10 -10\cf0 \strokec3 :]\cb1 \
\cb2         reward_volatility = np.std(recent_rewards)\cb1 \
\cb2         volatility_score = \cf8 \strokec8 min\cf0 \strokec3 (reward_volatility * \cf10 \strokec10 2\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Exploration vs exploitation imbalance\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history) >= \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             action_diversity = \cf8 \strokec8 len\cf0 \strokec3 (\cf11 \strokec11 set\cf0 \strokec3 (\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history)[\cf10 \strokec10 -10\cf0 \strokec3 :])) / \cf9 \strokec9 self\cf0 \strokec3 .n_actions\cb1 \
\cb2             exploration_score = \cf8 \strokec8 abs\cf0 \strokec3 (action_diversity - \cf10 \strokec10 0.6\cf0 \strokec3 ) * \cf10 \strokec10 2\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             exploration_score = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Q-value variance\cf0 \cb1 \strokec3 \
\cb2         q_variance = np.var(\cf9 \strokec9 self\cf0 \strokec3 .q_values) \cf4 \strokec4 if\cf0 \strokec3  np.\cf8 \strokec8 sum\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .q_values) != \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         uncertainty_score = \cf8 \strokec8 min\cf0 \strokec3 (q_variance * \cf10 \strokec10 5\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Emotion intensity\cf0 \cb1 \strokec3 \
\cb2         emotion_intensity = np.linalg.norm(\cf9 \strokec9 self\cf0 \strokec3 .emotion) / np.sqrt(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         need_score = (\cf10 \strokec10 0.3\cf0 \strokec3  * volatility_score + \cf10 \strokec10 0.25\cf0 \strokec3  * exploration_score +\cb1 \
\cb2                      \cf10 \strokec10 0.25\cf0 \strokec3  * uncertainty_score + \cf10 \strokec10 0.2\cf0 \strokec3  * emotion_intensity)\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.clip(need_score, \cf10 \strokec10 0.0\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 analyze_performance_trend\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Recent performance trend analysis"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker) < \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2         recent_performance = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker)[\cf10 \strokec10 -10\cf0 \strokec3 :]\cb1 \
\cb2         x = np.arange(\cf8 \strokec8 len\cf0 \strokec3 (recent_performance))\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_performance) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             trend = np.polyfit(x, recent_performance, \cf10 \strokec10 1\cf0 \strokec3 )[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  trend\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 adaptive_memory_control\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Simple and clean adaptive memory control - pure experience-based without environment classification"""\cf0 \cb1 \strokec3 \
\cb2         effectiveness = \cf9 \strokec9 self\cf0 \strokec3 .evaluate_memory_effectiveness()\cb1 \
\
\cb2         \cf6 \strokec6 # \uc0\u55356 \u57263  Core: Judge only based on memory effectiveness\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  effectiveness > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Memory is helpful \uc0\u8594  use more\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = \cf10 \strokec10 0.8\cf0 \strokec3  + \cf10 \strokec10 0.2\cf0 \strokec3  * effectiveness\cb1 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  effectiveness > \cf10 \strokec10 0.4\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Memory is somewhat helpful \uc0\u8594  moderate use\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = \cf10 \strokec10 0.4\cf0 \strokec3  + \cf10 \strokec10 0.4\cf0 \strokec3  * effectiveness\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Memory is not very helpful \uc0\u8594  minimize\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = \cf10 \strokec10 0.1\cf0 \strokec3  + \cf10 \strokec10 0.3\cf0 \strokec3  * effectiveness\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = np.clip(\cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level, \cf10 \strokec10 0.05\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Dynamic parameter adjustment\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_memory_threshold = \cf9 \strokec9 self\cf0 \strokec3 .base_memory_threshold / \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 0.1\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .current_memory_influence = \cf9 \strokec9 self\cf0 \strokec3 .base_memory_influence * \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 identify_context_cluster\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 context\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Context cluster identification"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  context \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (context) < \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "default"\cf0 \cb1 \strokec3 \
\
\cb2         norm_t = context[\cf10 \strokec10 0\cf0 \strokec3 ] \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (context) > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         phase_id = \cf11 \strokec11 int\cf0 \strokec3 (context[\cf10 \strokec10 1\cf0 \strokec3 ]) \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (context) > \cf10 \strokec10 1\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         time_cluster = \cf11 \strokec11 int\cf0 \strokec3 (norm_t * \cf10 \strokec10 4\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 f\cf5 \strokec5 "phase_\cf0 \strokec3 \{phase_id\}\cf5 \strokec5 _time_\cf0 \strokec3 \{time_cluster\}\cf5 \strokec5 "\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_memory_quality_score\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Memory quality score calculation"""\cf0 \cb1 \strokec3 \
\cb2         error_score = \cf8 \strokec8 min\cf0 \strokec3 (\cf8 \strokec8 abs\cf0 \strokec3 (prediction_error), \cf10 \strokec10 0.5\cf0 \strokec3 ) / \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         extreme_reward_score = \cf8 \strokec8 abs\cf0 \strokec3 (reward - \cf10 \strokec10 0.5\cf0 \strokec3 ) / \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         emotion_intensity = np.linalg.norm(\cf9 \strokec9 self\cf0 \strokec3 .emotion) / np.sqrt(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.4\cf0 \strokec3  * error_score + \cf10 \strokec10 0.4\cf0 \strokec3  * extreme_reward_score + \cf10 \strokec10 0.2\cf0 \strokec3  * emotion_intensity\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 store_adaptive_memory\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Universal adaptive memory storage"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level < \cf10 \strokec10 0.1\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         quality_score = \cf9 \strokec9 self\cf0 \strokec3 .compute_memory_quality_score(action, reward, prediction_error)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  quality_score < \cf9 \strokec9 self\cf0 \strokec3 .memory_quality_threshold:\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 abs\cf0 \strokec3 (prediction_error) > \cf9 \strokec9 self\cf0 \strokec3 .current_memory_threshold:\cb1 \
\cb2             memory = \{\cb1 \
\cb2                 \cf5 \strokec5 'action'\cf0 \strokec3 : action,\cb1 \
\cb2                 \cf5 \strokec5 'reward'\cf0 \strokec3 : reward,\cb1 \
\cb2                 \cf5 \strokec5 'context'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .context.copy(),\cb1 \
\cb2                 \cf5 \strokec5 'time'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .time,\cb1 \
\cb2                 \cf5 \strokec5 'prediction_error'\cf0 \strokec3 : \cf8 \strokec8 abs\cf0 \strokec3 (prediction_error),\cb1 \
\cb2                 \cf5 \strokec5 'quality_score'\cf0 \strokec3 : quality_score,\cb1 \
\cb2                 \cf5 \strokec5 'emotion_state'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .emotion.copy()\cb1 \
\cb2             \}\cb1 \
\
\cb2             \cf6 \strokec6 # Universal memory storage\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .use_context_clustering \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 cluster_id = \cf9 \strokec9 self\cf0 \strokec3 .identify_context_cluster(\cf9 \strokec9 self\cf0 \strokec3 .context)\cb1 \
\cb2                 memory[\cf5 \strokec5 'cluster_id'\cf0 \strokec3 ] = cluster_id\cb1 \
\
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  cluster_id \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context_clusters:\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id] = []\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .cluster_performance[cluster_id] = deque(maxlen=\cf10 \strokec10 20\cf0 \strokec3 )\cb1 \
\
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id].append(memory)\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .cluster_performance[cluster_id].append(reward)\cb1 \
\
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id]) > \cf9 \strokec9 self\cf0 \strokec3 .memory_size // \cf10 \strokec10 6\cf0 \strokec3 :\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id].sort(\cb1 \
\cb2                         key=\cf7 \strokec7 lambda\cf0 \strokec3  x: x[\cf5 \strokec5 'quality_score'\cf0 \strokec3 ], reverse=\cf7 \strokec7 True\cf0 \cb1 \strokec3 \
\cb2                     )\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id] = \cf9 \strokec9 self\cf0 \strokec3 .context_clusters[cluster_id][:\cf9 \strokec9 self\cf0 \strokec3 .memory_size // \cf10 \strokec10 6\cf0 \strokec3 ]\cb1 \
\
\cb2             \cf6 \strokec6 # Store in general memory as well\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory.append(memory)\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .episodic_memory) > \cf9 \strokec9 self\cf0 \strokec3 .memory_size:\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory.sort(key=\cf7 \strokec7 lambda\cf0 \strokec3  x: (\cb1 \
\cb2                     \cf10 \strokec10 0.6\cf0 \strokec3  * x[\cf5 \strokec5 'quality_score'\cf0 \strokec3 ] + \cf10 \strokec10 0.4\cf0 \strokec3  * (x[\cf5 \strokec5 'time'\cf0 \strokec3 ] / \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 1\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .time))\cb1 \
\cb2                 ), reverse=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory = \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory[:\cf9 \strokec9 self\cf0 \strokec3 .memory_size]\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_adaptive_memory_bias\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Universal adaptive memory bias calculation"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level < \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history.append((\cf7 \strokec7 False\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .prev_reward))\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2         relevant_memories = []\cb1 \
\
\cb2         \cf6 \strokec6 # Universal memory retrieval strategy\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .use_context_clustering \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level > \cf10 \strokec10 0.5\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context_clusters:\cb1 \
\cb2             cluster_id = \cf9 \strokec9 self\cf0 \strokec3 .identify_context_cluster(\cf9 \strokec9 self\cf0 \strokec3 .context)\cb1 \
\cb2             cluster_memories = \cf9 \strokec9 self\cf0 \strokec3 .context_clusters.get(cluster_id, [])\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  cluster_memories:\cb1 \
\cb2                 relevant_memories.extend(cluster_memories[\cf10 \strokec10 -3\cf0 \strokec3 :])\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (relevant_memories) < \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  cid, memories \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context_clusters.items():\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (memories) > \cf10 \strokec10 0\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  cid \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cluster_performance:\cb1 \
\cb2                         cluster_perf = np.mean(\cf9 \strokec9 self\cf0 \strokec3 .cluster_performance[cid])\cb1 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  cluster_perf > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                             relevant_memories.extend(memories[\cf10 \strokec10 -2\cf0 \strokec3 :])\cb1 \
\cb2                             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (relevant_memories) >= \cf10 \strokec10 4\cf0 \strokec3 :\cb1 \
\cb2                                 \cf4 \strokec4 break\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Similarity-based search from general memory\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (relevant_memories) < \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             similarity_memories = []\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  memory \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory[\cf10 \strokec10 -30\cf0 \strokec3 :]:\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  memory.get(\cf5 \strokec5 'context'\cf0 \strokec3 ) \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2                     context_sim = \cf9 \strokec9 self\cf0 \strokec3 .compute_similarity(\cf9 \strokec9 self\cf0 \strokec3 .context, memory[\cf5 \strokec5 'context'\cf0 \strokec3 ])\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  context_sim > \cf9 \strokec9 self\cf0 \strokec3 .memory_similarity_threshold:\cb1 \
\cb2                         emotion_sim = \cf9 \strokec9 self\cf0 \strokec3 .compute_similarity(\cf9 \strokec9 self\cf0 \strokec3 .emotion, memory[\cf5 \strokec5 'emotion_state'\cf0 \strokec3 ])\cb1 \
\cb2                         combined_sim = \cf10 \strokec10 0.7\cf0 \strokec3  * context_sim + \cf10 \strokec10 0.3\cf0 \strokec3  * emotion_sim\cb1 \
\cb2                         similarity_memories.append((combined_sim, memory))\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  similarity_memories:\cb1 \
\cb2                 similarity_memories.sort(key=\cf7 \strokec7 lambda\cf0 \strokec3  x: x[\cf10 \strokec10 0\cf0 \strokec3 ], reverse=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2                 additional_memories = [mem \cf4 \strokec4 for\cf0 \strokec3  _, mem \cf7 \strokec7 in\cf0 \strokec3  similarity_memories[:\cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 1\cf0 \strokec3 , \cf10 \strokec10 4\cf0 \strokec3 -\cf8 \strokec8 len\cf0 \strokec3 (relevant_memories))]]\cb1 \
\cb2                 relevant_memories.extend(additional_memories)\cb1 \
\
\cb2         \cf6 \strokec6 # Use high-quality memories if insufficient\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (relevant_memories) < \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2             high_quality_memories = [m \cf4 \strokec4 for\cf0 \strokec3  m \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory \cf4 \strokec4 if\cf0 \strokec3  m[\cf5 \strokec5 'quality_score'\cf0 \strokec3 ] > \cf10 \strokec10 0.7\cf0 \strokec3 ]\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  high_quality_memories:\cb1 \
\cb2                 relevant_memories.extend(high_quality_memories[\cf10 \strokec10 -2\cf0 \strokec3 :])\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  relevant_memories:\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history.append((\cf7 \strokec7 False\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .prev_reward))\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2         \cf6 \strokec6 # Memory bias calculation\cf0 \cb1 \strokec3 \
\cb2         bias = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         total_weight = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  memory \cf7 \strokec7 in\cf0 \strokec3  relevant_memories[\cf10 \strokec10 -5\cf0 \strokec3 :]:\cb1 \
\cb2             action = memory[\cf5 \strokec5 'action'\cf0 \strokec3 ]\cb1 \
\cb2             reward = memory[\cf5 \strokec5 'reward'\cf0 \strokec3 ]\cb1 \
\cb2             quality = memory[\cf5 \strokec5 'quality_score'\cf0 \strokec3 ]\cb1 \
\cb2             weight = quality * \cf9 \strokec9 self\cf0 \strokec3 .current_memory_influence\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  reward > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 bias[action] += reward * weight\cb1 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  reward < \cf10 \strokec10 0.4\cf0 \strokec3 :\cb1 \
\cb2                 bias[action] -= (\cf10 \strokec10 0.5\cf0 \strokec3  - reward) * weight * \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2             total_weight += weight\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  total_weight > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2             bias = bias / (\cf10 \strokec10 1.0\cf0 \strokec3  + total_weight * \cf10 \strokec10 0.2\cf0 \strokec3 )\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history.append((\cf7 \strokec7 True\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .prev_reward))\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  bias\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 emotional_processing\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Improved emotional processing"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_reward \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = \cf9 \strokec9 self\cf0 \strokec3 .emotion_decay * \cf9 \strokec9 self\cf0 \strokec3 .emotion\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history.append(reward)\cb1 \
\cb2         recent_rewards = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .reward_history)\cb1 \
\
\cb2         current_emotion_updates = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         intensity_factor = \cf10 \strokec10 0.7\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Fear\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  reward < \cf9 \strokec9 self\cf0 \strokec3 .prev_reward - \cf10 \strokec10 0.15\cf0 \strokec3 :\cb1 \
\cb2             fear_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.6\cf0 \strokec3 , \cf10 \strokec10 0.15\cf0 \strokec3  + \cf10 \strokec10 0.4\cf0 \strokec3  * \cf8 \strokec8 abs\cf0 \strokec3 (reward - \cf9 \strokec9 self\cf0 \strokec3 .prev_reward))\cb1 \
\cb2             current_emotion_updates[\cf10 \strokec10 0\cf0 \strokec3 ] = fear_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Joy\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  reward > \cf10 \strokec10 0.7\cf0 \strokec3 :\cb1 \
\cb2             joy_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.7\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3  + \cf10 \strokec10 0.5\cf0 \strokec3  * reward)\cb1 \
\cb2             current_emotion_updates[\cf10 \strokec10 1\cf0 \strokec3 ] = joy_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Hope\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_rewards) >= \cf10 \strokec10 4\cf0 \strokec3 :\cb1 \
\cb2             recent_trend = np.polyfit(\cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 4\cf0 \strokec3 ), recent_rewards[\cf10 \strokec10 -4\cf0 \strokec3 :], \cf10 \strokec10 1\cf0 \strokec3 )[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  recent_trend > \cf10 \strokec10 0.03\cf0 \strokec3 :\cb1 \
\cb2                 hope_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.6\cf0 \strokec3 , \cf10 \strokec10 0.15\cf0 \strokec3  + \cf10 \strokec10 0.6\cf0 \strokec3  * recent_trend * \cf10 \strokec10 10\cf0 \strokec3 )\cb1 \
\cb2                 current_emotion_updates[\cf10 \strokec10 2\cf0 \strokec3 ] = hope_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Sadness\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_rewards) >= \cf10 \strokec10 6\cf0 \strokec3 :\cb1 \
\cb2             avg_recent = np.mean(recent_rewards[\cf10 \strokec10 -6\cf0 \strokec3 :])\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  avg_recent < \cf10 \strokec10 0.4\cf0 \strokec3 :\cb1 \
\cb2                 sadness_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.5\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3  + \cf10 \strokec10 0.4\cf0 \strokec3  * (\cf10 \strokec10 0.4\cf0 \strokec3  - avg_recent) / \cf10 \strokec10 0.4\cf0 \strokec3 )\cb1 \
\cb2                 current_emotion_updates[\cf10 \strokec10 3\cf0 \strokec3 ] = sadness_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Curiosity\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2             action_diversity = \cf8 \strokec8 len\cf0 \strokec3 (\cf11 \strokec11 set\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history)) / \cf8 \strokec8 min\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history), \cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2             recent_performance = np.mean(recent_rewards[\cf10 \strokec10 -3\cf0 \strokec3 :]) \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_rewards) >= \cf10 \strokec10 3\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  recent_performance < \cf10 \strokec10 0.6\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  action_diversity < \cf10 \strokec10 0.8\cf0 \strokec3 :\cb1 \
\cb2                 curiosity_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.7\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3  + \cf10 \strokec10 0.3\cf0 \strokec3  * (\cf10 \strokec10 1\cf0 \strokec3  - action_diversity) +\cb1 \
\cb2                                        \cf10 \strokec10 0.2\cf0 \strokec3  * \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 0.6\cf0 \strokec3  - recent_performance))\cb1 \
\cb2                 current_emotion_updates[\cf10 \strokec10 4\cf0 \strokec3 ] = curiosity_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Anger\cf0 \cb1 \strokec3 \
\cb2         expected_improvement = \cf10 \strokec10 0.05\cf0 \strokec3  * \cf9 \strokec9 self\cf0 \strokec3 .time / \cf10 \strokec10 200\cf0 \cb1 \strokec3 \
\cb2         expected_reward = \cf10 \strokec10 0.5\cf0 \strokec3  + expected_improvement\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  reward < expected_reward - \cf10 \strokec10 0.2\cf0 \strokec3 :\cb1 \
\cb2             anger_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.5\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3  + \cf10 \strokec10 0.4\cf0 \strokec3  * \cf8 \strokec8 abs\cf0 \strokec3 (reward - expected_reward))\cb1 \
\cb2             current_emotion_updates[\cf10 \strokec10 5\cf0 \strokec3 ] = anger_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Pride\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_rewards) >= \cf10 \strokec10 5\cf0 \strokec3 :\cb1 \
\cb2             success_rate = \cf8 \strokec8 sum\cf0 \strokec3 (r > \cf10 \strokec10 0.7\cf0 \strokec3  \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  recent_rewards[\cf10 \strokec10 -5\cf0 \strokec3 :]) / \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  success_rate > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 pride_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.6\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3  + \cf10 \strokec10 0.4\cf0 \strokec3  * success_rate)\cb1 \
\cb2                 current_emotion_updates[\cf10 \strokec10 6\cf0 \strokec3 ] = pride_strength * intensity_factor\cb1 \
\
\cb2         \cf6 \strokec6 # Shame\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recent_rewards) >= \cf10 \strokec10 4\cf0 \strokec3 :\cb1 \
\cb2             failure_rate = \cf8 \strokec8 sum\cf0 \strokec3 (r < \cf10 \strokec10 0.3\cf0 \strokec3  \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  recent_rewards[\cf10 \strokec10 -4\cf0 \strokec3 :]) / \cf10 \strokec10 4\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  failure_rate > \cf10 \strokec10 0.5\cf0 \strokec3 :\cb1 \
\cb2                 shame_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.4\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3  + \cf10 \strokec10 0.3\cf0 \strokec3  * failure_rate)\cb1 \
\cb2                 current_emotion_updates[\cf10 \strokec10 7\cf0 \strokec3 ] = shame_strength * intensity_factor\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .resolve_emotion_conflicts(current_emotion_updates)\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 8\cf0 \strokec3 ):\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .emotion_momentum[i] = \cf10 \strokec10 0.7\cf0 \strokec3  * \cf9 \strokec9 self\cf0 \strokec3 .emotion_momentum[i] + \cf10 \strokec10 0.3\cf0 \strokec3  * current_emotion_updates[i]\cb1 \
\cb2             emotion_change = \cf10 \strokec10 0.5\cf0 \strokec3  * current_emotion_updates[i] + \cf10 \strokec10 0.5\cf0 \strokec3  * \cf9 \strokec9 self\cf0 \strokec3 .emotion_momentum[i]\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .emotion[i] = \cf10 \strokec10 0.7\cf0 \strokec3  * \cf9 \strokec9 self\cf0 \strokec3 .emotion[i] + \cf10 \strokec10 0.3\cf0 \strokec3  * emotion_change\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .normalize_emotions()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = reward\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 resolve_emotion_conflicts\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 emotion_updates\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Emotion conflict resolution"""\cf0 \cb1 \strokec3 \
\cb2         conflicting_pairs = [(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 ), (\cf10 \strokec10 2\cf0 \strokec3 , \cf10 \strokec10 3\cf0 \strokec3 ), (\cf10 \strokec10 6\cf0 \strokec3 , \cf10 \strokec10 7\cf0 \strokec3 )]\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  idx1, idx2 \cf7 \strokec7 in\cf0 \strokec3  conflicting_pairs:\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  emotion_updates[idx1] > \cf10 \strokec10 0.5\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  emotion_updates[idx2] > \cf10 \strokec10 0.5\cf0 \strokec3 :\cb1 \
\cb2                 avg_strength = (emotion_updates[idx1] + emotion_updates[idx2]) / \cf10 \strokec10 2\cf0 \cb1 \strokec3 \
\cb2                 emotion_updates[idx1] = avg_strength * \cf10 \strokec10 0.8\cf0 \cb1 \strokec3 \
\cb2                 emotion_updates[idx2] = avg_strength * \cf10 \strokec10 0.8\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 normalize_emotions\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Emotion normalization"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.clip(\cf9 \strokec9 self\cf0 \strokec3 .emotion, \cf10 \strokec10 0.0\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\cb2         total_emotion_energy = np.\cf8 \strokec8 sum\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  total_emotion_energy > \cf9 \strokec9 self\cf0 \strokec3 .max_total_emotion_energy:\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .emotion = \cf9 \strokec9 self\cf0 \strokec3 .emotion * (\cf9 \strokec9 self\cf0 \strokec3 .max_total_emotion_energy / total_emotion_energy)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 adaptive_eta_adjustment\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Dynamic eta adjustment"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .eta_adaptation_counter += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .eta_adaptation_counter >= \cf10 \strokec10 20\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker) >= \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2             recent_performance = np.mean(\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker)[\cf10 \strokec10 -10\cf0 \strokec3 :])\cb1 \
\cb2             performance_variance = np.var(\cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker)[\cf10 \strokec10 -10\cf0 \strokec3 :])\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  recent_performance > \cf10 \strokec10 0.75\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 0.6\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  recent_performance > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 0.8\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  recent_performance < \cf10 \strokec10 0.4\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 1.3\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  performance_variance > \cf10 \strokec10 0.05\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 1.1\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta\cb1 \
\
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .eta = np.clip(\cf9 \strokec9 self\cf0 \strokec3 .eta, \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 0.3\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .base_eta * \cf10 \strokec10 1.5\cf0 \strokec3 )\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .eta_adaptation_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 select_top_emotions\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Core emotion selection"""\cf0 \cb1 \strokec3 \
\cb2         emotion_indices = np.argsort(\cf9 \strokec9 self\cf0 \strokec3 .emotion)[-\cf9 \strokec9 self\cf0 \strokec3 .top_k:]\cb1 \
\cb2         selective_emotions = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         selective_emotions[emotion_indices] = \cf9 \strokec9 self\cf0 \strokec3 .emotion[emotion_indices]\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  selective_emotions\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_direct_emotion_influence\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Direct emotion-action mapping"""\cf0 \cb1 \strokec3 \
\cb2         influences = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         selective_emotions = \cf9 \strokec9 self\cf0 \strokec3 .select_top_emotions()\cb1 \
\
\cb2         \cf6 \strokec6 # Fear\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  selective_emotions[\cf10 \strokec10 0\cf0 \strokec3 ] > \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2             fear_level = selective_emotions[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2             min_q = np.\cf8 \strokec8 min\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .q_values)\cb1 \
\cb2             max_q = np.\cf8 \strokec8 max\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .q_values)\cb1 \
\cb2             q_range = max_q - min_q + \cf10 \strokec10 0.001\cf0 \cb1 \strokec3 \
\
\cb2             \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2                 relative_badness = (max_q - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]) / q_range\cb1 \
\cb2                 influences[action] -= fear_level * \cf10 \strokec10 0.4\cf0 \strokec3  * relative_badness\cb1 \
\
\cb2         \cf6 \strokec6 # Joy\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  selective_emotions[\cf10 \strokec10 1\cf0 \strokec3 ] > \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2             joy_level = selective_emotions[\cf10 \strokec10 1\cf0 \strokec3 ]\cb1 \
\cb2             min_q = np.\cf8 \strokec8 min\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .q_values)\cb1 \
\cb2             max_q = np.\cf8 \strokec8 max\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .q_values)\cb1 \
\cb2             q_range = max_q - min_q + \cf10 \strokec10 0.001\cf0 \cb1 \strokec3 \
\
\cb2             \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2                 relative_goodness = (\cf9 \strokec9 self\cf0 \strokec3 .q_values[action] - min_q) / q_range\cb1 \
\cb2                 influences[action] += joy_level * \cf10 \strokec10 0.4\cf0 \strokec3  * relative_goodness\cb1 \
\
\cb2         \cf6 \strokec6 # Curiosity\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  selective_emotions[\cf10 \strokec10 4\cf0 \strokec3 ] > \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2             curiosity_level = selective_emotions[\cf10 \strokec10 4\cf0 \strokec3 ]\cb1 \
\cb2             min_count = np.\cf8 \strokec8 min\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_counts)\cb1 \
\cb2             max_count = np.\cf8 \strokec8 max\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_counts) + \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\
\cb2             \cf4 \strokec4 for\cf0 \strokec3  action \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2                 exploration_factor = (max_count - \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action]) / max_count\cb1 \
\cb2                 influences[action] += curiosity_level * \cf10 \strokec10 0.4\cf0 \strokec3  * exploration_factor\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  influences\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 hippocampal_neurogenesis\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Hippocampal neurogenesis simulation"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .time % \cf9 \strokec9 self\cf0 \strokec3 .neurogenesis_cycle == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2             emotion_intensity = np.linalg.norm(\cf9 \strokec9 self\cf0 \strokec3 .emotion)\cb1 \
\cb2             base_boost = \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  emotion_intensity > \cf10 \strokec10 0.7\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = base_boost * \cf10 \strokec10 1.3\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 4\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = base_boost * \cf10 \strokec10 1.2\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = base_boost\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = \cf8 \strokec8 max\cf0 \strokec3 (\cf10 \strokec10 0\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .learning_boost - \cf10 \strokec10 0.01\cf0 \strokec3 )\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 prefrontal_modulation\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Prefrontal cortex modulation"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .episodic_memory) < \cf10 \strokec10 5\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         recent_rewards = [mem[\cf5 \strokec5 'reward'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  mem \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory[\cf10 \strokec10 -10\cf0 \strokec3 :]]\cb1 \
\cb2         reward_stability = \cf10 \strokec10 1.0\cf0 \strokec3  - np.std(recent_rewards) \cf4 \strokec4 if\cf0 \strokec3  recent_rewards \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\
\cb2         context_change = np.mean(\cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes) \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         emotion_volatility = np.std(\cf9 \strokec9 self\cf0 \strokec3 .emotion) \cf4 \strokec4 if\cf0 \strokec3  np.\cf8 \strokec8 sum\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion) > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         emotion_stability = \cf10 \strokec10 1.0\cf0 \strokec3  - \cf8 \strokec8 min\cf0 \strokec3 (emotion_volatility, \cf10 \strokec10 1.0\cf0 \strokec3 )\cb1 \
\
\cb2         performance_trend = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker) >= \cf10 \strokec10 5\cf0 \strokec3 :\cb1 \
\cb2             recent_performance = \cf11 \strokec11 list\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker)[\cf10 \strokec10 -5\cf0 \strokec3 :]\cb1 \
\cb2             performance_trend = np.mean(recent_performance)\cb1 \
\
\cb2         stability = (\cf10 \strokec10 0.35\cf0 \strokec3  * reward_stability + \cf10 \strokec10 0.25\cf0 \strokec3  * emotion_stability -\cb1 \
\cb2                     \cf10 \strokec10 0.15\cf0 \strokec3  * context_change + \cf10 \strokec10 0.25\cf0 \strokec3  * performance_trend)\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.clip(stability, \cf10 \strokec10 0.1\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 )\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_uncertainty_bonus\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Uncertainty-based exploration bonus"""\cf0 \cb1 \strokec3 \
\cb2         uncertainty = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         total_experiences = \cf9 \strokec9 self\cf0 \strokec3 .time + \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2             action_count = \cf9 \strokec9 self\cf0 \strokec3 .action_counts[a] + \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2             count_uncertainty = np.sqrt(np.log(total_experiences) / action_count)\cb1 \
\
\cb2             \cf6 \strokec6 # Collect reward history for this action\cf0 \cb1 \strokec3 \
\cb2             action_rewards = [mem[\cf5 \strokec5 'reward'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  mem \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory \cf4 \strokec4 if\cf0 \strokec3  mem[\cf5 \strokec5 'action'\cf0 \strokec3 ] == a]\cb1 \
\
\cb2             \cf6 \strokec6 # Calculate reward standard deviation\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (action_rewards) > \cf10 \strokec10 1\cf0 \strokec3 :\cb1 \
\cb2                 reward_std = np.std(action_rewards)\cb1 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 reward_std = \cf10 \strokec10 0.5\cf0 \strokec3   \cf6 \strokec6 # Default value\cf0 \cb1 \strokec3 \
\
\cb2             \cf6 \strokec6 # Emotion factor\cf0 \cb1 \strokec3 \
\cb2             emotion_factor = \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 4\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :  \cf6 \strokec6 # Curiosity\cf0 \cb1 \strokec3 \
\cb2                 emotion_factor = \cf10 \strokec10 1.3\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 0\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :  \cf6 \strokec6 # Fear\cf0 \cb1 \strokec3 \
\cb2                 emotion_factor = \cf10 \strokec10 0.7\cf0 \cb1 \strokec3 \
\
\cb2             uncertainty[a] = count_uncertainty * (\cf10 \strokec10 1\cf0 \strokec3  + reward_std) * emotion_factor\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  uncertainty * \cf10 \strokec10 0.3\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 build_context\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 norm_t\cf0 \strokec3 , \cf9 \strokec9 phase_id\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Enhanced context construction"""\cf0 \cb1 \strokec3 \
\cb2         grid_patterns = []\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  scale \cf7 \strokec7 in\cf0 \strokec3  [\cf10 \strokec10 1.0\cf0 \strokec3 , \cf10 \strokec10 3.0\cf0 \strokec3 , \cf10 \strokec10 6.0\cf0 \strokec3 ]:\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  offset \cf7 \strokec7 in\cf0 \strokec3  [\cf10 \strokec10 0.0\cf0 \strokec3 , \cf10 \strokec10 0.33\cf0 \strokec3 , \cf10 \strokec10 0.67\cf0 \strokec3 ]:\cb1 \
\cb2                 grid_patterns.append(np.sin(\cf10 \strokec10 2\cf0 \strokec3 *np.pi * (norm_t * scale + offset)))\cb1 \
\cb2                 grid_patterns.append(np.cos(\cf10 \strokec10 2\cf0 \strokec3 *np.pi * (norm_t * scale + offset)))\cb1 \
\
\cb2         time_cells = [\cb1 \
\cb2             np.exp(-(norm_t - \cf10 \strokec10 0.25\cf0 \strokec3 )**\cf10 \strokec10 2\cf0 \strokec3  / \cf10 \strokec10 0.15\cf0 \strokec3 ),\cb1 \
\cb2             np.exp(-(norm_t - \cf10 \strokec10 0.5\cf0 \strokec3 )**\cf10 \strokec10 2\cf0 \strokec3  / \cf10 \strokec10 0.15\cf0 \strokec3 ),\cb1 \
\cb2             np.exp(-(norm_t - \cf10 \strokec10 0.75\cf0 \strokec3 )**\cf10 \strokec10 2\cf0 \strokec3  / \cf10 \strokec10 0.15\cf0 \strokec3 )\cb1 \
\cb2         ]\cb1 \
\
\cb2         emotion_context = \cf9 \strokec9 self\cf0 \strokec3 .emotion * \cf10 \strokec10 1.5\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.concatenate([grid_patterns, time_cells, [phase_id], emotion_context])\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_context\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 norm_t\cf0 \strokec3 , \cf9 \strokec9 phase_id\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Context update and change tracking"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_context = \cf9 \strokec9 self\cf0 \strokec3 .context.copy() \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .context \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context = \cf9 \strokec9 self\cf0 \strokec3 .build_context(norm_t, phase_id)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_context \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             min_len = \cf8 \strokec8 min\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .context), \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .prev_context))\cb1 \
\cb2             context_change = np.linalg.norm(\cf9 \strokec9 self\cf0 \strokec3 .context[:min_len] - \cf9 \strokec9 self\cf0 \strokec3 .prev_context[:min_len])\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes.append(context_change)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 select_action\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Integrated action selection"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .hippocampal_neurogenesis()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .adaptive_eta_adjustment()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .adaptive_memory_control()\cb1 \
\
\cb2         pfc_stability = \cf9 \strokec9 self\cf0 \strokec3 .prefrontal_modulation()\cb1 \
\
\cb2         \cf6 \strokec6 # Emotion-based exploration adjustment\cf0 \cb1 \strokec3 \
\cb2         curiosity_boost = \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 4\cf0 \strokec3 ] * \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\cb2         fear_penalty = \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 0\cf0 \strokec3 ] * \cf10 \strokec10 0.25\cf0 \cb1 \strokec3 \
\cb2         joy_exploitation = \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 1\cf0 \strokec3 ] * \cf10 \strokec10 0.15\cf0 \cb1 \strokec3 \
\
\cb2         adaptive_epsilon = \cf9 \strokec9 self\cf0 \strokec3 .epsilon * (\cf10 \strokec10 1\cf0 \strokec3  - pfc_stability)\cb1 \
\cb2         adaptive_epsilon = np.clip(\cb1 \
\cb2             adaptive_epsilon + curiosity_boost - fear_penalty - joy_exploitation,\cb1 \
\cb2             \cf10 \strokec10 0.01\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\cb2         )\cb1 \
\
\cb2         \cf6 \strokec6 # Exploration action\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.rand() < adaptive_epsilon:\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 4\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 action_probs = \cf10 \strokec10 1.0\cf0 \strokec3  / (\cf9 \strokec9 self\cf0 \strokec3 .action_counts + \cf10 \strokec10 0.1\cf0 \strokec3 )\cb1 \
\cb2                 action_probs = action_probs / np.\cf8 \strokec8 sum\cf0 \strokec3 (action_probs)\cb1 \
\cb2                 \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(\cf9 \strokec9 self\cf0 \strokec3 .n_actions, p=action_probs)\cb1 \
\cb2             \cf4 \strokec4 elif\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 5\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .action_history) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                     recent_action = \cf9 \strokec9 self\cf0 \strokec3 .action_history[\cf10 \strokec10 -1\cf0 \strokec3 ]\cb1 \
\cb2                     available_actions = [a \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions) \cf4 \strokec4 if\cf0 \strokec3  a != recent_action]\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  available_actions:\cb1 \
\cb2                         \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(available_actions)\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2         \cf6 \strokec6 # Exploitation action\cf0 \cb1 \strokec3 \
\cb2         emotion_influences = \cf9 \strokec9 self\cf0 \strokec3 .compute_direct_emotion_influence()\cb1 \
\cb2         memory_bias = \cf9 \strokec9 self\cf0 \strokec3 .compute_adaptive_memory_bias()\cb1 \
\cb2         uncertainty_bonus = \cf9 \strokec9 self\cf0 \strokec3 .compute_uncertainty_bonus()\cb1 \
\
\cb2         final_values = (\cf9 \strokec9 self\cf0 \strokec3 .q_values +\cb1 \
\cb2                        \cf9 \strokec9 self\cf0 \strokec3 .eta * emotion_influences +\cb1 \
\cb2                        memory_bias +\cb1 \
\cb2                        uncertainty_bonus +\cb1 \
\cb2                        \cf9 \strokec9 self\cf0 \strokec3 .xi * \cf9 \strokec9 self\cf0 \strokec3 .rng.randn(\cf9 \strokec9 self\cf0 \strokec3 .n_actions))\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.argmax(final_values)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_dopamine_learning\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Dopamine-based learning"""\cf0 \cb1 \strokec3 \
\cb2         prediction_error = reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]\cb1 \
\cb2         emotion_intensity = np.linalg.norm(\cf9 \strokec9 self\cf0 \strokec3 .emotion)\cb1 \
\
\cb2         base_alpha = \cf9 \strokec9 self\cf0 \strokec3 .alpha\cb1 \
\cb2         emotional_boost = \cf10 \strokec10 1.0\cf0 \strokec3  + emotion_intensity * \cf10 \strokec10 0.3\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 abs\cf0 \strokec3 (prediction_error) > \cf10 \strokec10 0.3\cf0 \strokec3 :\cb1 \
\cb2             adaptive_alpha = base_alpha * \cf10 \strokec10 1.3\cf0 \strokec3  * emotional_boost\cb1 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  \cf8 \strokec8 abs\cf0 \strokec3 (prediction_error) > \cf10 \strokec10 0.15\cf0 \strokec3 :\cb1 \
\cb2             adaptive_alpha = base_alpha * \cf10 \strokec10 1.1\cf0 \strokec3  * emotional_boost\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             adaptive_alpha = base_alpha * emotional_boost\cb1 \
\
\cb2         adaptive_alpha += \cf9 \strokec9 self\cf0 \strokec3 .learning_boost\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 4\cf0 \strokec3 ] > \cf10 \strokec10 0.6\cf0 \strokec3 :\cb1 \
\cb2             adaptive_alpha *= \cf10 \strokec10 1.2\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[\cf10 \strokec10 0\cf0 \strokec3 ] > \cf10 \strokec10 0.7\cf0 \strokec3 :\cb1 \
\cb2             adaptive_alpha *= \cf10 \strokec10 0.85\cf0 \cb1 \strokec3 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += adaptive_alpha * prediction_error\cb1 \
\
\cb2         habit_strength = \cf8 \strokec8 min\cf0 \strokec3 (\cf10 \strokec10 0.3\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .habit_strength_factor * \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action])\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  reward > \cf10 \strokec10 0.65\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += habit_strength * reward\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.append(reward)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  prediction_error\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , *\cf9 \strokec9 args\cf0 \strokec3 , **\cf9 \strokec9 kwargs\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Integrated update"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (args) == \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2             action, reward = args\cb1 \
\cb2             context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (args) == \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             context, action, reward = args\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .context = context\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             action, reward = args[\cf10 \strokec10 0\cf0 \strokec3 ], args[\cf10 \strokec10 1\cf0 \strokec3 ]\cb1 \
\cb2             context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .hippocampal_neurogenesis()\cb1 \
\cb2         prediction_error = \cf9 \strokec9 self\cf0 \strokec3 .update_dopamine_learning(action, reward)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotional_processing(reward)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .store_adaptive_memory(action, reward, prediction_error)\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_history.append(action)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action] += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .time += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_similarity\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 c1\cf0 \strokec3 , \cf9 \strokec9 c2\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Context similarity calculation"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf8 \strokec8 isinstance\cf0 \strokec3 (c1, np.ndarray) \cf7 \strokec7 or\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf8 \strokec8 isinstance\cf0 \strokec3 (c2, np.ndarray):\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2         min_len = \cf8 \strokec8 min\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (c1), \cf8 \strokec8 len\cf0 \strokec3 (c2))\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  min_len == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2         c1_part, c2_part = c1[:min_len], c2[:min_len]\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  np.linalg.norm(c1_part) == \cf10 \strokec10 0\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  np.linalg.norm(c2_part) == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.dot(c1_part, c2_part) / (np.linalg.norm(c1_part) * np.linalg.norm(c2_part))\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Complete reset"""\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_momentum = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .time = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context = \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .eta = \cf9 \strokec9 self\cf0 \strokec3 .base_eta\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .learning_boost = \cf10 \strokec10 0.2\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .successful_emotion_patterns = \{\}\cb1 \
\
\cb2         \cf6 \strokec6 # Universal memory system reset\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_effectiveness_tracker.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .environment_stability_tracker.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level = \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_usage_history.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .change_detection_window.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .stable_performance_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .memory_cooldown = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .context_clusters.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .cluster_performance.clear()\cb1 \
\
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .recent_context_changes.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_history.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .reward_history.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_action_history.clear()\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .eta_adaptation_counter = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_memory_status\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Universal memory system status"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \{\cb1 \
\cb2             \cf5 \strokec5 'memory_activation_level'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .memory_activation_level, \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'environment_stability'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .assess_environment_stability(), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'memory_effectiveness'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .evaluate_memory_effectiveness(), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'memory_need_score'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .calculate_memory_need(), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'current_memory_threshold'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf8 \strokec8 getattr\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf5 \strokec5 'current_memory_threshold'\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .base_memory_threshold), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'current_memory_influence'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf8 \strokec8 getattr\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf5 \strokec5 'current_memory_influence'\cf0 \strokec3 , \cf9 \strokec9 self\cf0 \strokec3 .base_memory_influence), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'memory_count'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .episodic_memory),\cb1 \
\cb2             \cf5 \strokec5 'high_quality_memories'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 ([m \cf4 \strokec4 for\cf0 \strokec3  m \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .episodic_memory \cf4 \strokec4 if\cf0 \strokec3  m[\cf5 \strokec5 'quality_score'\cf0 \strokec3 ] > \cf10 \strokec10 0.5\cf0 \strokec3 ]),\cb1 \
\cb2             \cf5 \strokec5 'context_clusters'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .context_clusters),\cb1 \
\cb2             \cf5 \strokec5 'memory_cooldown'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .memory_cooldown,\cb1 \
\cb2             \cf5 \strokec5 'performance_trend'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .analyze_performance_trend(), \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .performance_tracker) >= \cf10 \strokec10 10\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\cb2         \}\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_emotion_summary\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Current state summary"""\cf0 \cb1 \strokec3 \
\cb2         selected_emotions = \cf9 \strokec9 self\cf0 \strokec3 .select_top_emotions()\cb1 \
\
\cb2         summary = \{\cb1 \
\cb2             \cf5 \strokec5 'current_eta'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .eta, \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'eta_ratio'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .eta / \cf9 \strokec9 self\cf0 \strokec3 .base_eta, \cf10 \strokec10 2\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'total_emotion_energy'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (np.\cf8 \strokec8 sum\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'selected_emotions'\cf0 \strokec3 : \{\},\cb1 \
\cb2             \cf5 \strokec5 'all_emotions'\cf0 \strokec3 : \{\},\cb1 \
\cb2             \cf5 \strokec5 'memory_status'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .get_memory_status(),\cb1 \
\cb2             \cf5 \strokec5 'learning_boost'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .learning_boost, \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'pfc_stability'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .prefrontal_modulation(), \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .episodic_memory) >= \cf10 \strokec10 5\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \strokec3 ,\cb1 \
\cb2             \cf5 \strokec5 'neurogenesis_cycle'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .time % \cf9 \strokec9 self\cf0 \strokec3 .neurogenesis_cycle,\cb1 \
\cb2             \cf5 \strokec5 'successful_patterns'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .successful_emotion_patterns)\cb1 \
\cb2         \}\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i, name \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion_names):\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  selected_emotions[i] > \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2                 summary[\cf5 \strokec5 'selected_emotions'\cf0 \strokec3 ][name] = \cf8 \strokec8 round\cf0 \strokec3 (\cf11 \strokec11 float\cf0 \strokec3 (selected_emotions[i]), \cf10 \strokec10 3\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i, name \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion_names):\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[i] > \cf10 \strokec10 0.1\cf0 \strokec3 :\cb1 \
\cb2                 summary[\cf5 \strokec5 'all_emotions'\cf0 \strokec3 ][name] = \cf8 \strokec8 round\cf0 \strokec3 (\cf11 \strokec11 float\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion[i]), \cf10 \strokec10 3\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  summary\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_detailed_decision_breakdown\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Detailed decision process analysis"""\cf0 \cb1 \strokec3 \
\cb2         breakdown = \{\cb1 \
\cb2             \cf5 \strokec5 'q_values'\cf0 \strokec3 : [\cf8 \strokec8 round\cf0 \strokec3 (q, \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  q \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .q_values],\cb1 \
\cb2             \cf5 \strokec5 'emotion_influences'\cf0 \strokec3 : [\cf8 \strokec8 round\cf0 \strokec3 (inf, \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  inf \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .compute_direct_emotion_influence()],\cb1 \
\cb2             \cf5 \strokec5 'memory_bias'\cf0 \strokec3 : [\cf8 \strokec8 round\cf0 \strokec3 (mb, \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  mb \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .compute_adaptive_memory_bias()],\cb1 \
\cb2             \cf5 \strokec5 'uncertainty_bonus'\cf0 \strokec3 : [\cf8 \strokec8 round\cf0 \strokec3 (ub, \cf10 \strokec10 3\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  ub \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .compute_uncertainty_bonus()],\cb1 \
\cb2             \cf5 \strokec5 'pfc_stability'\cf0 \strokec3 : \cf8 \strokec8 round\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .prefrontal_modulation(), \cf10 \strokec10 3\cf0 \strokec3 ),\cb1 \
\cb2             \cf5 \strokec5 'current_emotions'\cf0 \strokec3 : \{name: \cf8 \strokec8 round\cf0 \strokec3 (\cf11 \strokec11 float\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion[i]), \cf10 \strokec10 3\cf0 \strokec3 )\cb1 \
\cb2                                \cf4 \strokec4 for\cf0 \strokec3  i, name \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .emotion_names)\cb1 \
\cb2                                \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion[i] > \cf10 \strokec10 0.1\cf0 \strokec3 \},\cb1 \
\cb2             \cf5 \strokec5 'memory_status'\cf0 \strokec3 : \cf9 \strokec9 self\cf0 \strokec3 .get_memory_status()\cb1 \
\cb2         \}\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  breakdown\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 get_dominant_emotion\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Return the strongest emotion and its intensity"""\cf0 \cb1 \strokec3 \
\cb2         max_idx = np.argmax(\cf9 \strokec9 self\cf0 \strokec3 .emotion)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion_names[max_idx], \cf9 \strokec9 self\cf0 \strokec3 .emotion[max_idx]\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # Ablation Study classes (maintaining backward compatibility)\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoEmotion\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Emotion system removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 emotional_processing\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_reward \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = reward\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoMemory\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Memory system removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 store_adaptive_memory\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 pass\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_adaptive_memory_bias\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoDopamine\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Dopamine adaptive learning removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_dopamine_learning\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         prediction_error = reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += \cf10 \strokec10 0.1\cf0 \strokec3  * prediction_error\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.append(reward)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  prediction_error\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_SingleCore\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Single core version (already default is single core)"""\cf0 \cb1 \strokec3 \
\cb2     \cf4 \strokec4 pass\cf0 \cb1 \strokec3 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoDopamine_NoMemory\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Dopamine + Memory removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_dopamine_learning\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         prediction_error = reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += \cf10 \strokec10 0.1\cf0 \strokec3  * prediction_error\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.append(reward)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  prediction_error\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 store_adaptive_memory\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 pass\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_adaptive_memory_bias\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoDopamine_NoEmotion\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Dopamine + Emotion removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_dopamine_learning\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         prediction_error = reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += \cf10 \strokec10 0.1\cf0 \strokec3  * prediction_error\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.append(reward)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  prediction_error\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 emotional_processing\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_reward \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = reward\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoMemory_NoEmotion\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Memory + Emotion removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 store_adaptive_memory\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 pass\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_adaptive_memory_bias\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 emotional_processing\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_reward \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = reward\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 ECIA_NoAll_Components\cf0 \strokec3 (\cf11 \strokec11 ECIA\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """All advanced components removal"""\cf0 \cb1 \strokec3 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update_dopamine_learning\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         prediction_error = reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += \cf10 \strokec10 0.1\cf0 \strokec3  * prediction_error\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .performance_tracker.append(reward)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  prediction_error\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 store_adaptive_memory\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 , \cf9 \strokec9 prediction_error\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 pass\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_adaptive_memory_bias\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 emotional_processing\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .prev_reward \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = \cf10 \strokec10 0.5\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion = np.zeros(\cf10 \strokec10 8\cf0 \strokec3 )\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .prev_reward = reward\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # Basic agents\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  EpsilonGreedyAgent:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 n_actions\cf0 \strokec3 =\cf10 \strokec10 5\cf0 \strokec3 , \cf9 \strokec9 epsilon\cf0 \strokec3 =\cf10 \strokec10 0.1\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .n_actions = n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .epsilon = epsilon\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(n_actions)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 select_action\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.rand() < \cf9 \strokec9 self\cf0 \strokec3 .epsilon:\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .rng.choice(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.argmax(\cf9 \strokec9 self\cf0 \strokec3 .q_values)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action] += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2         alpha = \cf10 \strokec10 1\cf0 \strokec3  / \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += alpha * (reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action])\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  ThompsonSamplingAgent:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 n_actions\cf0 \strokec3 =\cf10 \strokec10 5\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .n_actions = n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .priors = [(\cf10 \strokec10 0.0\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  _ \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (n_actions)]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .observations = [[] \cf4 \strokec4 for\cf0 \strokec3  _ \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (n_actions)]\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .priors = [(\cf10 \strokec10 0.0\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \strokec3 ) \cf4 \strokec4 for\cf0 \strokec3  _ \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions)]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .observations = [[] \cf4 \strokec4 for\cf0 \strokec3  _ \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions)]\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 select_action\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         samples = [\cf9 \strokec9 self\cf0 \strokec3 .rng.normal(mu, sigma) \cf4 \strokec4 for\cf0 \strokec3  mu, sigma \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .priors]\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.argmax(samples)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .observations[action].append(reward)\cb1 \
\cb2         data = \cf9 \strokec9 self\cf0 \strokec3 .observations[action]\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data) > \cf10 \strokec10 1\cf0 \strokec3 :\cb1 \
\cb2             mu = np.mean(data)\cb1 \
\cb2             sigma = np.std(data) \cf4 \strokec4 if\cf0 \strokec3  np.std(data) > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .priors[action] = (mu, sigma)\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  UCBAgent:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """UCB with controlled randomness"""\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 n_actions\cf0 \strokec3 =\cf10 \strokec10 5\cf0 \strokec3 , \cf9 \strokec9 c\cf0 \strokec3 =\cf10 \strokec10 0.5\cf0 \strokec3 , \cf9 \strokec9 random_state\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .n_actions = n_actions\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .c = c\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .total_steps = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  random_state \cf7 \strokec7 is\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf7 \strokec7 None\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState(random_state)\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .rng = np.random.RandomState()\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 reset\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .total_steps = \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 select_action\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .total_steps += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2         ucb_values = np.zeros(\cf9 \strokec9 self\cf0 \strokec3 .n_actions)\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  a \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .n_actions):\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .action_counts[a] == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 return\cf0 \strokec3  a\cb1 \
\cb2             bonus = \cf9 \strokec9 self\cf0 \strokec3 .c * np.sqrt(np.log(\cf9 \strokec9 self\cf0 \strokec3 .total_steps) / \cf9 \strokec9 self\cf0 \strokec3 .action_counts[a])\cb1 \
\cb2             ucb_values[a] = \cf9 \strokec9 self\cf0 \strokec3 .q_values[a] + bonus\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  np.argmax(ucb_values)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 update\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 action\cf0 \strokec3 , \cf9 \strokec9 reward\cf0 \strokec3 ):\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action] += \cf10 \strokec10 1\cf0 \cb1 \strokec3 \
\cb2         alpha = \cf10 \strokec10 1\cf0 \strokec3  / \cf9 \strokec9 self\cf0 \strokec3 .action_counts[action]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .q_values[action] += alpha * (reward - \cf9 \strokec9 self\cf0 \strokec3 .q_values[action])\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 test_unified_ecia\cf0 \strokec3 ():\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Universal integrated ECIA test"""\cf0 \cb1 \strokec3 \
\cb2     agent = ECIA(n_actions=\cf10 \strokec10 5\cf0 \strokec3 , memory_size=\cf10 \strokec10 15\cf0 \strokec3 )\cb1 \
\
\
\cb2     \cf6 \strokec6 # Various environment pattern simulation\cf0 \cb1 \strokec3 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n Various environment pattern test:"\cf0 \strokec3 )\cb1 \
\
\cb2     \cf6 \strokec6 # Pattern 1: Stable environment\cf0 \cb1 \strokec3 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Stable environment simulation..."\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 20\cf0 \strokec3 ):\cb1 \
\cb2         agent.update_context(i/\cf10 \strokec10 50\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2         action = agent.select_action()\cb1 \
\cb2         reward = \cf10 \strokec10 0.7\cf0 \strokec3  + np.random.normal(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3 )\cb1 \
\cb2         agent.update(action, reward)\cb1 \
\
\cb2     stable_status = agent.get_memory_status()\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Memory activation: \cf0 \strokec3 \{stable_status[\cf5 \strokec5 'memory_activation_level'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Environment stability: \cf0 \strokec3 \{stable_status[\cf5 \strokec5 'environment_stability'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Memory need score: \cf0 \strokec3 \{stable_status[\cf5 \strokec5 'memory_need_score'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2     \cf6 \strokec6 # Pattern 2: Changing environment\cf0 \cb1 \strokec3 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n Changing environment simulation..."\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 20\cf0 \strokec3 ):\cb1 \
\cb2         agent.update_context((\cf10 \strokec10 20\cf0 \strokec3 +i)/\cf10 \strokec10 50\cf0 \strokec3 , (i//\cf10 \strokec10 10\cf0 \strokec3 ))\cb1 \
\cb2         action = agent.select_action()\cb1 \
\cb2         reward = \cf10 \strokec10 0.3\cf0 \strokec3  \cf4 \strokec4 if\cf0 \strokec3  i < \cf10 \strokec10 10\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0.8\cf0 \strokec3  + np.random.normal(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 0.2\cf0 \strokec3 )\cb1 \
\cb2         agent.update(action, reward)\cb1 \
\
\cb2     changing_status = agent.get_memory_status()\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Memory activation: \cf0 \strokec3 \{changing_status[\cf5 \strokec5 'memory_activation_level'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Environment stability: \cf0 \strokec3 \{changing_status[\cf5 \strokec5 'environment_stability'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Memory need score: \cf0 \strokec3 \{changing_status[\cf5 \strokec5 'memory_need_score'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Performance trend: \cf0 \strokec3 \{changing_status[\cf5 \strokec5 'performance_trend'\cf0 \strokec3 ]\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\
\cb2     agent.reset()\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 bonferroni_correction\cf0 \strokec3 (\cf9 \strokec9 p_values\cf0 \strokec3 , \cf9 \strokec9 alpha\cf0 \strokec3 =\cf10 \strokec10 0.05\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Simple Bonferroni correction implementation without statsmodels"""\cf0 \cb1 \strokec3 \
\cb2     p_values = np.array(p_values)\cb1 \
\cb2     n_tests = \cf8 \strokec8 len\cf0 \strokec3 (p_values)\cb1 \
\
\cb2     \cf6 \strokec6 # Bonferroni correction\cf0 \cb1 \strokec3 \
\cb2     p_corrected = p_values * n_tests\cb1 \
\cb2     p_corrected = np.clip(p_corrected, \cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2     rejected = p_corrected < alpha\cb1 \
\
\cb2     \cf4 \strokec4 return\cf0 \strokec3  rejected, p_corrected\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 perform_multiple_comparison_correction\cf0 \strokec3 (\cf9 \strokec9 complete_meta_results\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "content/Results/meta_analysis"\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Perform Bonferroni correction for multiple comparisons in analysis"""\cf0 \cb1 \strokec3 \
\
\cb2     \cf4 \strokec4 from\cf0 \strokec3  scipy.stats \cf4 \strokec4 import\cf0 \strokec3  ttest_ind, mannwhitneyu\cb1 \
\cb2     \cf4 \strokec4 import\cf0 \strokec3  pandas \cf4 \strokec4 as\cf0 \strokec3  pd\cb1 \
\
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n MULTIPLE COMPARISON CORRECTION (Bonferroni)"\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 70\cf0 \strokec3 )\cb1 \
\
\cb2     correction_results = \{\}\cb1 \
\
\cb2     \cf4 \strokec4 for\cf0 \strokec3  env_name, env_results \cf7 \strokec7 in\cf0 \strokec3  complete_meta_results.items():\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\\n Environment: \cf0 \strokec3 \{env_name\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Extract seed-level data for all agents\cf0 \cb1 \strokec3 \
\cb2         agent_data = \{\}\cb1 \
\cb2         agent_names = []\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  agent_name, agent_result \cf7 \strokec7 in\cf0 \strokec3  env_results.items():\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  agent_result[\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 ][\cf5 \strokec5 'n_master_seeds'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 seed_means = []\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  seed_key, seed_result \cf7 \strokec7 in\cf0 \strokec3  agent_result[\cf5 \strokec5 'individual_seeds'\cf0 \strokec3 ].items():\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  seed_result[\cf5 \strokec5 'success_rate'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                         seed_means.append(seed_result[\cf5 \strokec5 'mean_reward'\cf0 \strokec3 ])\cb1 \
\
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (seed_means) >= \cf10 \strokec10 3\cf0 \strokec3 :  \cf6 \strokec6 # Minimum data requirement\cf0 \cb1 \strokec3 \
\cb2                     agent_data[agent_name] = seed_means\cb1 \
\cb2                     agent_names.append(agent_name)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (agent_names) < \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Insufficient data for comparisons in \cf0 \strokec3 \{env_name\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Perform all pairwise comparisons\cf0 \cb1 \strokec3 \
\cb2         comparison_results = []\cb1 \
\cb2         p_values = []\cb1 \
\cb2         comparison_names = []\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  j \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (i+\cf10 \strokec10 1\cf0 \strokec3 , \cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                 agent1, agent2 = agent_names[i], agent_names[j]\cb1 \
\cb2                 data1, data2 = agent_data[agent1], agent_data[agent2]\cb1 \
\
\cb2                 \cf6 \strokec6 # Perform appropriate statistical test\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Use t-test (could be enhanced with normality checking)\cf0 \cb1 \strokec3 \
\cb2                     stat, p_val = ttest_ind(data1, data2, equal_var=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\
\cb2                     \cf6 \strokec6 # Effect size (Cohen's d)\cf0 \cb1 \strokec3 \
\cb2                     pooled_std = np.sqrt(((\cf8 \strokec8 len\cf0 \strokec3 (data1) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data1) +\cb1 \
\cb2                                          (\cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data2)) /\cb1 \
\cb2                                         (\cf8 \strokec8 len\cf0 \strokec3 (data1) + \cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 2\cf0 \strokec3 ))\cb1 \
\cb2                     cohens_d = (np.mean(data1) - np.mean(data2)) / pooled_std \cf4 \strokec4 if\cf0 \strokec3  pooled_std > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2                     comparison_results.append(\{\cb1 \
\cb2                         \cf5 \strokec5 'Agent_1'\cf0 \strokec3 : agent1,\cb1 \
\cb2                         \cf5 \strokec5 'Agent_2'\cf0 \strokec3 : agent2,\cb1 \
\cb2                         \cf5 \strokec5 'Mean_1'\cf0 \strokec3 : np.mean(data1),\cb1 \
\cb2                         \cf5 \strokec5 'Mean_2'\cf0 \strokec3 : np.mean(data2),\cb1 \
\cb2                         \cf5 \strokec5 'Mean_Diff'\cf0 \strokec3 : np.mean(data1) - np.mean(data2),\cb1 \
\cb2                         \cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 : p_val,\cb1 \
\cb2                         \cf5 \strokec5 'Cohens_D'\cf0 \strokec3 : cohens_d,\cb1 \
\cb2                         \cf5 \strokec5 'Test_Statistic'\cf0 \strokec3 : stat\cb1 \
\cb2                     \})\cb1 \
\
\cb2                     p_values.append(p_val)\cb1 \
\cb2                     comparison_names.append(\cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{agent1\}\cf5 \strokec5 _vs_\cf0 \strokec3 \{agent2\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2                 \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e:\cb1 \
\cb2                     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "     Test failed for \cf0 \strokec3 \{agent1\}\cf5 \strokec5  vs \cf0 \strokec3 \{agent2\}\cf5 \strokec5 : \cf0 \strokec3 \{e\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  p_values:\cb1 \
\cb2             \cf6 \strokec6 # Apply Bonferroni correction\cf0 \cb1 \strokec3 \
\cb2             rejected, p_corrected = bonferroni_correction(p_values, alpha=\cf10 \strokec10 0.05\cf0 \strokec3 )\cb1 \
\
\
\cb2             \cf6 \strokec6 # Add corrected results\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  i, result \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (comparison_results):\cb1 \
\cb2                 result[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ] = p_corrected[i]\cb1 \
\cb2                 result[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ] = rejected[i]\cb1 \
\cb2                 result[\cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 ] = result[\cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 ] < \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\
\cb2             correction_results[env_name] = comparison_results\cb1 \
\
\cb2             \cf6 \strokec6 # Print significant results after correction\cf0 \cb1 \strokec3 \
\cb2             significant_after_correction = [r \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  comparison_results \cf4 \strokec4 if\cf0 \strokec3  r[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ]]\cb1 \
\
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Total comparisons: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (comparison_results)\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant before correction: \cf0 \strokec3 \{\cf8 \strokec8 sum\cf0 \strokec3 (r[\cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  comparison_results)\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant after Bonferroni: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (significant_after_correction)\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  significant_after_correction:\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant comparisons after Bonferroni correction:"\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  result \cf7 \strokec7 in\cf0 \strokec3  significant_after_correction:\cb1 \
\cb2                     direction = \cf5 \strokec5 ">"\cf0 \strokec3  \cf4 \strokec4 if\cf0 \strokec3  result[\cf5 \strokec5 'Mean_Diff'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf5 \strokec5 "<"\cf0 \cb1 \strokec3 \
\cb2                     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "    \cf0 \strokec3 \{result[\cf5 \strokec5 'Agent_1'\cf0 \strokec3 ]\}\cf5 \strokec5  \cf0 \strokec3 \{direction\}\cf5 \strokec5  \cf0 \strokec3 \{result[\cf5 \strokec5 'Agent_2'\cf0 \strokec3 ]\}\cf5 \strokec5 : "\cf0 \cb1 \strokec3 \
\cb2                           \cf7 \strokec7 f\cf5 \strokec5 "p_corrected=\cf0 \strokec3 \{result[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ]\cf10 \strokec10 :.6f\cf0 \strokec3 \}\cf5 \strokec5 , d=\cf0 \strokec3 \{result[\cf5 \strokec5 'Cohens_D'\cf0 \strokec3 ]\cf10 \strokec10 :.3f\cf0 \strokec3 \}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   No significant differences after Bonferroni correction"\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Save detailed results to CSV\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  comparison_results:\cb1 \
\cb2             df = pd.DataFrame(comparison_results)\cb1 \
\cb2             csv_filename = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /bonferroni_correction_\cf0 \strokec3 \{env_name\}\cf5 \strokec5 .csv"\cf0 \cb1 \strokec3 \
\cb2             df.to_csv(csv_filename, index=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Detailed results saved: \cf0 \strokec3 \{csv_filename\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2     \cf6 \strokec6 # Save overall correction results\cf0 \cb1 \strokec3 \
\cb2     \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /bonferroni_correction_results.pkl"\cf0 \strokec3 , \cf5 \strokec5 "wb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2         pickle.dump(correction_results, f)\cb1 \
\
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\\n Multiple comparison correction completed!"\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 return\cf0 \strokec3  correction_results\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 perform_multiple_comparison_correction_cross_dataset\cf0 \strokec3 (\cf9 \strokec9 complete_results\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "content/Results/cross_dataset_study"\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Perform Bonferroni correction for cross-dataset study (ECIA_Full vs Baseline only)"""\cf0 \cb1 \strokec3 \
\
\cb2     \cf4 \strokec4 from\cf0 \strokec3  scipy.stats \cf4 \strokec4 import\cf0 \strokec3  ttest_ind\cb1 \
\cb2     \cf4 \strokec4 import\cf0 \strokec3  pandas \cf4 \strokec4 as\cf0 \strokec3  pd\cb1 \
\
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n MULTIPLE COMPARISON CORRECTION (Bonferroni) - Cross-Dataset Study"\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 70\cf0 \strokec3 )\cb1 \
\
\cb2     \cf6 \strokec6 # Focus on ECIA_Full vs Baseline only\cf0 \cb1 \strokec3 \
\cb2     baseline_agents = [\cf5 \strokec5 "EpsilonGreedy"\cf0 \strokec3 , \cf5 \strokec5 "UCB"\cf0 \strokec3 , \cf5 \strokec5 "TS"\cf0 \strokec3 ]\cb1 \
\cb2     target_agents = [\cf5 \strokec5 "ECIA_Full"\cf0 \strokec3 ] + baseline_agents\cb1 \
\
\cb2     \cf6 \strokec6 # Metrics to test\cf0 \cb1 \strokec3 \
\cb2     metrics_to_test = [\cb1 \
\cb2         \cf5 \strokec5 'overall_performance_mean'\cf0 \strokec3 ,\cb1 \
\cb2         \cf5 \strokec5 'recovery_rate_mean'\cf0 \strokec3 ,\cb1 \
\cb2         \cf5 \strokec5 'recovery_time_mean'\cf0 \cb1 \strokec3 \
\cb2     ]\cb1 \
\
\cb2     correction_results = \{\}\cb1 \
\
\cb2     \cf4 \strokec4 for\cf0 \strokec3  metric_name \cf7 \strokec7 in\cf0 \strokec3  metrics_to_test:\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\\n Metric: \cf0 \strokec3 \{metric_name\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Extract data for this metric\cf0 \cb1 \strokec3 \
\cb2         agent_data = \{\}\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  agent_name \cf7 \strokec7 in\cf0 \strokec3  target_agents:\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  agent_name \cf7 \strokec7 in\cf0 \strokec3  complete_results:\cb1 \
\cb2                 agent_result = complete_results[agent_name]\cb1 \
\
\cb2                 metric_values = []\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  seed_key, seed_result \cf7 \strokec7 in\cf0 \strokec3  agent_result[\cf5 \strokec5 'individual_seeds'\cf0 \strokec3 ].items():\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  seed_result[\cf5 \strokec5 'n_experiments'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  metric_name == \cf5 \strokec5 'overall_performance_mean'\cf0 \strokec3 :\cb1 \
\cb2                             metric_values.extend(seed_result[\cf5 \strokec5 'overall_performances'\cf0 \strokec3 ])\cb1 \
\cb2                         \cf4 \strokec4 elif\cf0 \strokec3  metric_name == \cf5 \strokec5 'recovery_rate_mean'\cf0 \strokec3 :\cb1 \
\cb2                             metric_values.extend(seed_result[\cf5 \strokec5 'recovery_rates'\cf0 \strokec3 ])\cb1 \
\cb2                         \cf4 \strokec4 elif\cf0 \strokec3  metric_name == \cf5 \strokec5 'recovery_time_mean'\cf0 \strokec3 :\cb1 \
\cb2                             metric_values.extend(seed_result[\cf5 \strokec5 'recovery_times'\cf0 \strokec3 ])\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (metric_values) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2                     agent_data[agent_name] = metric_values\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (agent_data) < \cf10 \strokec10 2\cf0 \strokec3 :\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Insufficient data for \cf0 \strokec3 \{metric_name\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Perform pairwise comparisons\cf0 \cb1 \strokec3 \
\cb2         comparison_results = []\cb1 \
\cb2         p_values = []\cb1 \
\
\cb2         agent_names = \cf11 \strokec11 list\cf0 \strokec3 (agent_data.keys())\cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  j \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (i+\cf10 \strokec10 1\cf0 \strokec3 , \cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                 agent1, agent2 = agent_names[i], agent_names[j]\cb1 \
\cb2                 data1, data2 = agent_data[agent1], agent_data[agent2]\cb1 \
\
\cb2                 \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2                     stat, p_val = ttest_ind(data1, data2, equal_var=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\
\cb2                     \cf6 \strokec6 # Effect size\cf0 \cb1 \strokec3 \
\cb2                     pooled_std = np.sqrt(((\cf8 \strokec8 len\cf0 \strokec3 (data1) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data1) +\cb1 \
\cb2                                          (\cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data2)) /\cb1 \
\cb2                                         (\cf8 \strokec8 len\cf0 \strokec3 (data1) + \cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 2\cf0 \strokec3 ))\cb1 \
\cb2                     cohens_d = (np.mean(data1) - np.mean(data2)) / pooled_std \cf4 \strokec4 if\cf0 \strokec3  pooled_std > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf10 \strokec10 0\cf0 \cb1 \strokec3 \
\
\cb2                     comparison_results.append(\{\cb1 \
\cb2                         \cf5 \strokec5 'Metric'\cf0 \strokec3 : metric_name,\cb1 \
\cb2                         \cf5 \strokec5 'Agent_1'\cf0 \strokec3 : agent1,\cb1 \
\cb2                         \cf5 \strokec5 'Agent_2'\cf0 \strokec3 : agent2,\cb1 \
\cb2                         \cf5 \strokec5 'Mean_1'\cf0 \strokec3 : np.mean(data1),\cb1 \
\cb2                         \cf5 \strokec5 'Mean_2'\cf0 \strokec3 : np.mean(data2),\cb1 \
\cb2                         \cf5 \strokec5 'Mean_Diff'\cf0 \strokec3 : np.mean(data1) - np.mean(data2),\cb1 \
\cb2                         \cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 : p_val,\cb1 \
\cb2                         \cf5 \strokec5 'Cohens_D'\cf0 \strokec3 : cohens_d\cb1 \
\cb2                     \})\cb1 \
\
\cb2                     p_values.append(p_val)\cb1 \
\
\cb2                 \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e:\cb1 \
\cb2                     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "     Test failed for \cf0 \strokec3 \{agent1\}\cf5 \strokec5  vs \cf0 \strokec3 \{agent2\}\cf5 \strokec5 : \cf0 \strokec3 \{e\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  p_values:\cb1 \
\cb2             \cf6 \strokec6 # Apply Bonferroni correction\cf0 \cb1 \strokec3 \
\cb2             rejected, p_corrected = bonferroni_correction(p_values, alpha=\cf10 \strokec10 0.05\cf0 \strokec3 )\cb1 \
\
\cb2             \cf6 \strokec6 # Add corrected results\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  i, result \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (comparison_results):\cb1 \
\cb2                 result[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ] = p_corrected[i]\cb1 \
\cb2                 result[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ] = rejected[i]\cb1 \
\cb2                 result[\cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 ] = result[\cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 ] < \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\
\cb2             correction_results[metric_name] = comparison_results\cb1 \
\
\cb2             \cf6 \strokec6 # Print results\cf0 \cb1 \strokec3 \
\cb2             significant_after = \cf8 \strokec8 sum\cf0 \strokec3 (r[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  comparison_results)\cb1 \
\cb2             significant_before = \cf8 \strokec8 sum\cf0 \strokec3 (r[\cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  r \cf7 \strokec7 in\cf0 \strokec3  comparison_results)\cb1 \
\
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant before/after correction: \cf0 \strokec3 \{significant_before\}\cf5 \strokec5 /\cf0 \strokec3 \{significant_after\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  significant_after > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant after Bonferroni:"\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  result \cf7 \strokec7 in\cf0 \strokec3  comparison_results:\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  result[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ]:\cb1 \
\cb2                         direction = \cf5 \strokec5 ">"\cf0 \strokec3  \cf4 \strokec4 if\cf0 \strokec3  result[\cf5 \strokec5 'Mean_Diff'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3  \cf4 \strokec4 else\cf0 \strokec3  \cf5 \strokec5 "<"\cf0 \cb1 \strokec3 \
\cb2                         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "    \cf0 \strokec3 \{result[\cf5 \strokec5 'Agent_1'\cf0 \strokec3 ]\}\cf5 \strokec5  \cf0 \strokec3 \{direction\}\cf5 \strokec5  \cf0 \strokec3 \{result[\cf5 \strokec5 'Agent_2'\cf0 \strokec3 ]\}\cf5 \strokec5 : "\cf0 \cb1 \strokec3 \
\cb2                               \cf7 \strokec7 f\cf5 \strokec5 "p_corrected=\cf0 \strokec3 \{result[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ]\cf10 \strokec10 :.6f\cf0 \strokec3 \}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2     \cf6 \strokec6 # Save results\cf0 \cb1 \strokec3 \
\cb2     \cf4 \strokec4 if\cf0 \strokec3  correction_results:\cb1 \
\cb2         all_results = []\cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  metric_name, metric_results \cf7 \strokec7 in\cf0 \strokec3  correction_results.items():\cb1 \
\cb2             all_results.extend(metric_results)\cb1 \
\
\cb2         df = pd.DataFrame(all_results)\cb1 \
\cb2         csv_filename = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /cross_dataset_bonferroni_correction.csv"\cf0 \cb1 \strokec3 \
\cb2         df.to_csv(csv_filename, index=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\\n Detailed results saved: \cf0 \strokec3 \{csv_filename\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /cross_dataset_bonferroni_correction_results.pkl"\cf0 \strokec3 , \cf5 \strokec5 "wb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2             pickle.dump(correction_results, f)\cb1 \
\
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "\\n Cross-dataset multiple comparison correction completed!"\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 return\cf0 \strokec3  correction_results\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb2 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 __name__\cf0 \strokec3  == \cf5 \strokec5 "__main__"\cf0 \strokec3 :\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     test_unified_ecia()\cb1 \
\
\
\
\pard\pardeftab720\partightenfactor0
\cf4 \cb2 \strokec4 import\cf0 \strokec3  numpy \cf4 \strokec4 as\cf0 \strokec3  np\cb1 \
\cf4 \cb2 \strokec4 import\cf0 \strokec3  pandas \cf4 \strokec4 as\cf0 \strokec3  pd\cb1 \
\cf4 \cb2 \strokec4 import\cf0 \strokec3  os\cb1 \
\cf4 \cb2 \strokec4 from\cf0 \strokec3  scipy \cf4 \strokec4 import\cf0 \strokec3  stats\cb1 \
\cf4 \cb2 \strokec4 from\cf0 \strokec3  collections \cf4 \strokec4 import\cf0 \strokec3  defaultdict\cb1 \
\cf4 \cb2 \strokec4 import\cf0 \strokec3  warnings\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2 warnings.filterwarnings(\cf5 \strokec5 'ignore'\cf0 \strokec3 )\cb1 \
\
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 class\cf0 \strokec3  AdvancedStatisticalAnalyzer:\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """Advanced statistical analysis with comprehensive testing pipeline"""\cf0 \cb1 \strokec3 \
\cb2     \cb1 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 __init__\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 results_pkl_path\cf0 \strokec3 , \cf9 \strokec9 cross_dataset_pkl_path\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 , \cf9 \strokec9 emotion_data_path\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5         Initialize analyzer with pkl file paths\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         \cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         Args:\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             results_pkl_path: Path to complete_results_full.pkl (EnvA-C results)\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             cross_dataset_pkl_path: Path to cross_dataset results (optional)\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             emotion_data_path: Path to directory containing emotion .npy files (optional)\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2         \cf9 \strokec9 self\cf0 \strokec3 .results_pkl_path = results_pkl_path\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_pkl_path = cross_dataset_pkl_path\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path = emotion_data_path\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Load data\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .load_data()\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Environment and agent configurations\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .environments = [\cf5 \strokec5 "EnvA"\cf0 \strokec3 , \cf5 \strokec5 "EnvB"\cf0 \strokec3 , \cf5 \strokec5 "EnvC"\cf0 \strokec3 ]\cb1 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .baseline_agents = [\cf5 \strokec5 "EpsilonGreedy"\cf0 \strokec3 , \cf5 \strokec5 "UCB"\cf0 \strokec3 , \cf5 \strokec5 "TS"\cf0 \strokec3 ]\cb1 \
\cb2         \cb1 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 load_data\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Load pkl data files with error handling"""\cf0 \cb1 \strokec3 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Loading pkl data files..."\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Load EnvA-C results\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 import\cf0 \strokec3  pickle \cb1 \
\cb2             \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .results_pkl_path, \cf5 \strokec5 "rb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .complete_results = pickle.load(f)\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Loaded EnvA-C results: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .results_pkl_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Failed to load EnvA-C results: \cf0 \strokec3 \{e\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Trying alternative loading method..."\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2                 \cf6 \strokec6 # Alternative loading with custom unpickler\cf0 \cb1 \strokec3 \
\cb2                 \cf4 \strokec4 import\cf0 \strokec3  pickle\cb1 \
\cb2                 \cf7 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 SafeUnpickler\cf0 \strokec3 (\cf11 \strokec11 pkl\cf0 \strokec3 .\cf11 \strokec11 Unpickler\cf0 \strokec3 ):\cb1 \
\cb2                     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 find_class\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 module\cf0 \strokec3 , \cf9 \strokec9 name\cf0 \strokec3 ):\cb1 \
\cb2                         \cf6 \strokec6 # Handle missing classes gracefully\cf0 \cb1 \strokec3 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  name \cf7 \strokec7 in\cf0 \strokec3  [\cf5 \strokec5 'EnvironmentA'\cf0 \strokec3 , \cf5 \strokec5 'EnvironmentB'\cf0 \strokec3 , \cf5 \strokec5 'EnvironmentC'\cf0 \strokec3 , \cf5 \strokec5 'RandomShiftEnvironment'\cf0 \strokec3 ,\cb1 \
\cb2                                    \cf5 \strokec5 'ECIA'\cf0 \strokec3 , \cf5 \strokec5 'EpsilonGreedyAgent'\cf0 \strokec3 , \cf5 \strokec5 'UCBAgent'\cf0 \strokec3 , \cf5 \strokec5 'ThompsonSamplingAgent'\cf0 \strokec3 ,\cb1 \
\cb2                                    \cf5 \strokec5 'ECIA_NoEmotion'\cf0 \strokec3 , \cf5 \strokec5 'ECIA_NoMemory'\cf0 \strokec3 , \cf5 \strokec5 'ECIA_NoDopamine'\cf0 \strokec3 ,\cb1 \
\cb2                                    \cf5 \strokec5 'ECIA_NoDopamine_NoMemory'\cf0 \strokec3 , \cf5 \strokec5 'ECIA_NoDopamine_NoEmotion'\cf0 \strokec3 ,\cb1 \
\cb2                                    \cf5 \strokec5 'ECIA_NoMemory_NoEmotion'\cf0 \strokec3 , \cf5 \strokec5 'ECIA_NoAll_Components'\cf0 \strokec3 ]:\cb1 \
\cb2                             \cf4 \strokec4 return\cf0 \strokec3  \cf11 \strokec11 type\cf0 \strokec3 (name, (), \{\})  \cf6 \strokec6 # Return empty class\cf0 \cb1 \strokec3 \
\cb2                         \cf4 \strokec4 return\cf0 \strokec3  super().find_class(module, name)\cb1 \
\cb2                 \cb1 \
\cb2                 \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .results_pkl_path, \cf5 \strokec5 "rb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .complete_results = SafeUnpickler(f).load()\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Loaded EnvA-C results with safe unpickler"\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e2:\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Alternative loading also failed: \cf0 \strokec3 \{e2\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2                 \cf9 \strokec9 self\cf0 \strokec3 .complete_results = \{\}\cb1 \
\cb2             \cb1 \
\cb2         \cf6 \strokec6 # Load cross-dataset results if provided\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_pkl_path:\cb1 \
\cb2             \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_pkl_path, \cf5 \strokec5 "rb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results = pickle.load(f)\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Loaded cross-dataset results: \cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_pkl_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e:\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Failed to load cross-dataset results: \cf0 \strokec3 \{e\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Trying alternative loading method..."\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2                     \cf7 \strokec7 class\cf0 \strokec3  \cf11 \strokec11 SafeUnpickler\cf0 \strokec3 (\cf11 \strokec11 pickle\cf0 \strokec3 .\cf11 \strokec11 Unpickler\cf0 \strokec3 ):\cb1 \
\cb2                         \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 find_class\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 module\cf0 \strokec3 , \cf9 \strokec9 name\cf0 \strokec3 ):\cb1 \
\cb2                             \cf4 \strokec4 if\cf0 \strokec3  name \cf7 \strokec7 in\cf0 \strokec3  [\cf5 \strokec5 'EnvironmentA'\cf0 \strokec3 , \cf5 \strokec5 'EnvironmentB'\cf0 \strokec3 , \cf5 \strokec5 'EnvironmentC'\cf0 \strokec3 , \cf5 \strokec5 'RandomShiftEnvironment'\cf0 \strokec3 ,\cb1 \
\cb2                                        \cf5 \strokec5 'ECIA'\cf0 \strokec3 , \cf5 \strokec5 'EpsilonGreedyAgent'\cf0 \strokec3 , \cf5 \strokec5 'UCBAgent'\cf0 \strokec3 , \cf5 \strokec5 'ThompsonSamplingAgent'\cf0 \strokec3 ]:\cb1 \
\cb2                                 \cf4 \strokec4 return\cf0 \strokec3  \cf11 \strokec11 type\cf0 \strokec3 (name, (), \{\})\cb1 \
\cb2                             \cf4 \strokec4 return\cf0 \strokec3  super().find_class(module, name)\cb1 \
\cb2                     \cb1 \
\cb2                     \cf4 \strokec4 with\cf0 \strokec3  \cf8 \strokec8 open\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_pkl_path, \cf5 \strokec5 "rb"\cf0 \strokec3 ) \cf4 \strokec4 as\cf0 \strokec3  f:\cb1 \
\cb2                         \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results = SafeUnpickler(f).load()\cb1 \
\cb2                     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Loaded cross-dataset results with safe unpickler"\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 except\cf0 \strokec3  Exception \cf4 \strokec4 as\cf0 \strokec3  e2:\cb1 \
\cb2                     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Cross-dataset alternative loading also failed: \cf0 \strokec3 \{e2\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2                     \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results = \{\}\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results = \{\}\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 extract_seed_level_data\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 agent_result\cf0 \strokec3 , \cf9 \strokec9 metric_type\cf0 \strokec3 =\cf5 \strokec5 'overall_performance'\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5         Extract seed-level data for statistical testing\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         \cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         Args:\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             agent_result: Agent result dictionary from pkl\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             metric_type: Type of metric ('overall_performance', 'recovery_rate', 'recovery_time')\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         \cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         Returns:\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             List of seed-level means\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2         seed_means = []\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  seed_key, seed_result \cf7 \strokec7 in\cf0 \strokec3  agent_result[\cf5 \strokec5 'individual_seeds'\cf0 \strokec3 ].items():\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  seed_result.get(\cf5 \strokec5 'success_rate'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  metric_type == \cf5 \strokec5 'overall_performance'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # For EnvA-C: use mean_reward from seed result\cf0 \cb1 \strokec3 \
\cb2                     seed_means.append(seed_result.get(\cf5 \strokec5 'mean_reward'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_rate'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Calculate recovery rate for this seed\cf0 \cb1 \strokec3 \
\cb2                     meta_stats = agent_result.get(\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 , \{\})\cb1 \
\cb2                     seed_recovery = meta_stats.get(\cf5 \strokec5 'meta_recovery_rate_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                     seed_means.append(seed_recovery)\cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_time'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Calculate recovery time for this seed\cf0 \cb1 \strokec3 \
\cb2                     meta_stats = agent_result.get(\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 , \{\})\cb1 \
\cb2                     seed_recovery_time = meta_stats.get(\cf5 \strokec5 'meta_recovery_time_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                     seed_means.append(seed_recovery_time)\cb1 \
\cb2                     \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  seed_means\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 extract_cross_dataset_seed_data\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 agent_result\cf0 \strokec3 , \cf9 \strokec9 metric_type\cf0 \strokec3 =\cf5 \strokec5 'overall_performance'\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Extract seed-level data for cross-dataset results"""\cf0 \cb1 \strokec3 \
\cb2         seed_means = []\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  seed_key, seed_result \cf7 \strokec7 in\cf0 \strokec3  agent_result[\cf5 \strokec5 'individual_seeds'\cf0 \strokec3 ].items():\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  seed_result.get(\cf5 \strokec5 'n_experiments'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  metric_type == \cf5 \strokec5 'overall_performance'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Average of all experiments in this seed\cf0 \cb1 \strokec3 \
\cb2                     seed_means.append(seed_result.get(\cf5 \strokec5 'mean_overall_performance'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_rate'\cf0 \strokec3 :\cb1 \
\cb2                     seed_means.append(seed_result.get(\cf5 \strokec5 'mean_recovery_rate'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_time'\cf0 \strokec3 :\cb1 \
\cb2                     seed_means.append(seed_result.get(\cf5 \strokec5 'mean_recovery_time'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  seed_means\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 perform_normality_test\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 data\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Perform Shapiro-Wilk normality test"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data) < \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 False\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2             statistic, p_value = stats.shapiro(data)\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  p_value > \cf10 \strokec10 0.05\cf0 \strokec3 , p_value\cb1 \
\cb2         \cf4 \strokec4 except\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 False\cf0 \strokec3 , \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 perform_equal_variance_test\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 data1\cf0 \strokec3 , \cf9 \strokec9 data2\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Perform Levene's test for equal variances"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data1) < \cf10 \strokec10 3\cf0 \strokec3  \cf7 \strokec7 or\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data2) < \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "unknown"\cf0 \strokec3 , \cf10 \strokec10 1.0\cf0 \cb1 \strokec3 \
\cb2             \cb1 \
\cb2         \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2             statistic, p_value = stats.levene(data1, data2)\cb1 \
\cb2             equal_var = p_value > \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "equal"\cf0 \strokec3  \cf4 \strokec4 if\cf0 \strokec3  equal_var \cf4 \strokec4 else\cf0 \strokec3  \cf5 \strokec5 "unequal"\cf0 \strokec3 , p_value\cb1 \
\cb2         \cf4 \strokec4 except\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "unknown"\cf0 \strokec3 , \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 choose_statistical_test\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 data1\cf0 \strokec3 , \cf9 \strokec9 data2\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5         Choose appropriate statistical test based on assumptions\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         \cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         Returns:\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5             test_name, statistic, p_value, equal_variances, p_levene\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2         \cf6 \strokec6 # Check normality\cf0 \cb1 \strokec3 \
\cb2         normal_1, p_norm_1 = \cf9 \strokec9 self\cf0 \strokec3 .perform_normality_test(data1)\cb1 \
\cb2         normal_2, p_norm_2 = \cf9 \strokec9 self\cf0 \strokec3 .perform_normality_test(data2)\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  normal_1 \cf7 \strokec7 and\cf0 \strokec3  normal_2:\cb1 \
\cb2             \cf6 \strokec6 # Both normal - check equal variances\cf0 \cb1 \strokec3 \
\cb2             equal_var_result, p_levene = \cf9 \strokec9 self\cf0 \strokec3 .perform_equal_variance_test(data1, data2)\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  equal_var_result == \cf5 \strokec5 "equal"\cf0 \strokec3 :\cb1 \
\cb2                 \cf6 \strokec6 # Use Student's t-test\cf0 \cb1 \strokec3 \
\cb2                 statistic, p_value = stats.ttest_ind(data1, data2, equal_var=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2                 test_name = \cf5 \strokec5 "Student's t-test"\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2                 \cf6 \strokec6 # Use Welch's t-test\cf0 \cb1 \strokec3 \
\cb2                 statistic, p_value = stats.ttest_ind(data1, data2, equal_var=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2                 test_name = \cf5 \strokec5 "Welch's t-test"\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf6 \strokec6 # Non-normal - use Mann-Whitney U test\cf0 \cb1 \strokec3 \
\cb2             statistic, p_value = stats.mannwhitneyu(data1, data2, alternative=\cf5 \strokec5 'two-sided'\cf0 \strokec3 )\cb1 \
\cb2             test_name = \cf5 \strokec5 "Mann-Whitney U test"\cf0 \cb1 \strokec3 \
\cb2             equal_var_result, p_levene = \cf5 \strokec5 "N/A (non-parametric)"\cf0 \strokec3 , np.nan\cb1 \
\
\cb2         \cf4 \strokec4 return\cf0 \strokec3  test_name, statistic, p_value, equal_var_result, p_levene, normal_1, normal_2, p_norm_1, p_norm_2\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 calculate_cohens_d\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 data1\cf0 \strokec3 , \cf9 \strokec9 data2\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Calculate Cohen's d effect size"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 try\cf0 \strokec3 :\cb1 \
\cb2             pooled_std = np.sqrt(((\cf8 \strokec8 len\cf0 \strokec3 (data1) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data1, ddof=\cf10 \strokec10 0\cf0 \strokec3 ) +\cb1 \
\cb2                                 (\cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 1\cf0 \strokec3 ) * np.var(data2, ddof=\cf10 \strokec10 0\cf0 \strokec3 )) /\cb1 \
\cb2                                (\cf8 \strokec8 len\cf0 \strokec3 (data1) + \cf8 \strokec8 len\cf0 \strokec3 (data2) - \cf10 \strokec10 2\cf0 \strokec3 ))\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  pooled_std == \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\cb2                 \cb1 \
\cb2             cohens_d = (np.mean(data1) - np.mean(data2)) / pooled_std\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  cohens_d\cb1 \
\cb2         \cf4 \strokec4 except\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.0\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 interpret_effect_size\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 cohens_d\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Interpret Cohen's d effect size"""\cf0 \cb1 \strokec3 \
\cb2         abs_d = \cf8 \strokec8 abs\cf0 \strokec3 (cohens_d)\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  abs_d < \cf10 \strokec10 0.2\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "negligible"\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  abs_d < \cf10 \strokec10 0.5\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "small"\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  abs_d < \cf10 \strokec10 0.8\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "medium"\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf5 \strokec5 "large"\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 bonferroni_correction\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 p_values\cf0 \strokec3 , \cf9 \strokec9 alpha\cf0 \strokec3 =\cf10 \strokec10 0.05\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Apply Bonferroni correction"""\cf0 \cb1 \strokec3 \
\cb2         p_values = np.array(p_values)\cb1 \
\cb2         n_tests = \cf8 \strokec8 len\cf0 \strokec3 (p_values)\cb1 \
\cb2         p_corrected = p_values * n_tests\cb1 \
\cb2         p_corrected = np.clip(p_corrected, \cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\cb2         rejected = p_corrected < alpha\cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  rejected, p_corrected\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 extract_metric_data_from_pkl\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 agent_result\cf0 \strokec3 , \cf9 \strokec9 metric_type\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Extract metric-specific data from pkl results"""\cf0 \cb1 \strokec3 \
\cb2         seed_values = []\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  seed_key, seed_result \cf7 \strokec7 in\cf0 \strokec3  agent_result[\cf5 \strokec5 'individual_seeds'\cf0 \strokec3 ].items():\cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  seed_result.get(\cf5 \strokec5 'success_rate'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  metric_type == \cf5 \strokec5 'overall_performance'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Use mean_reward from seed result\cf0 \cb1 \strokec3 \
\cb2                     seed_values.append(seed_result.get(\cf5 \strokec5 'mean_reward'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     \cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_rate'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Calculate recovery rate for this seed using rewards\cf0 \cb1 \strokec3 \
\cb2                     rewards = seed_result.get(\cf5 \strokec5 'rewards'\cf0 \strokec3 , np.array([]))\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  rewards.size > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                         recovery_rates = \cf9 \strokec9 self\cf0 \strokec3 .compute_recovery_rate_for_seed(rewards, env_name)\cb1 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recovery_rates) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                             seed_values.append(np.mean(recovery_rates))\cb1 \
\cb2                         \cb1 \
\cb2                 \cf4 \strokec4 elif\cf0 \strokec3  metric_type == \cf5 \strokec5 'recovery_time'\cf0 \strokec3 :\cb1 \
\cb2                     \cf6 \strokec6 # Calculate recovery time for this seed using rewards\cf0 \cb1 \strokec3 \
\cb2                     rewards = seed_result.get(\cf5 \strokec5 'rewards'\cf0 \strokec3 , np.array([]))\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  rewards.size > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                         recovery_times = \cf9 \strokec9 self\cf0 \strokec3 .compute_recovery_time_for_seed(rewards, env_name)\cb1 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (recovery_times) > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                             seed_values.append(np.mean(recovery_times))\cb1 \
\cb2                             \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  seed_values\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_recovery_rate_for_seed\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 rewards\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Compute recovery rate for a seed's rewards"""\cf0 \cb1 \strokec3 \
\cb2         \cf6 \strokec6 # Simplified recovery rate calculation\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvA"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 100\cf0 \strokec3 ]\cb1 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 ]\cb1 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvB"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 40\cf0 \strokec3 , \cf10 \strokec10 80\cf0 \strokec3 , \cf10 \strokec10 120\cf0 \strokec3 , \cf10 \strokec10 160\cf0 \strokec3 ]\cb1 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 ]\cb1 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvC"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 50\cf0 \strokec3 , \cf10 \strokec10 100\cf0 \strokec3 , \cf10 \strokec10 150\cf0 \strokec3 ]  \cf6 \strokec6 # Default fallback\cf0 \cb1 \strokec3 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.85\cf0 \strokec3 , \cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.85\cf0 \strokec3 ]\cb1 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  []\cb1 \
\cb2             \cb1 \
\cb2         recovery_rates = []\cb1 \
\cb2         analysis_window = \cf10 \strokec10 30\cf0 \cb1 \strokec3 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  run_idx \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (rewards.shape[\cf10 \strokec10 0\cf0 \strokec3 ]):\cb1 \
\cb2             run_rewards = rewards[run_idx]\cb1 \
\cb2             run_recovery_rates = []\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  change_idx, change_point \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (change_points):\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  change_point >= \cf8 \strokec8 len\cf0 \strokec3 (run_rewards) - analysis_window:\cb1 \
\cb2                     \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                 post_start = change_point\cb1 \
\cb2                 post_end = \cf8 \strokec8 min\cf0 \strokec3 (change_point + analysis_window, \cf8 \strokec8 len\cf0 \strokec3 (run_rewards))\cb1 \
\cb2                 \cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  post_end <= post_start:\cb1 \
\cb2                     \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                 segment_optimal = optimal_rewards[\cf8 \strokec8 min\cf0 \strokec3 (change_idx, \cf8 \strokec8 len\cf0 \strokec3 (optimal_rewards) - \cf10 \strokec10 1\cf0 \strokec3 )]\cb1 \
\cb2                 post_change_performance = np.mean(run_rewards[post_start:post_end])\cb1 \
\cb2                 recovery_rate = post_change_performance / segment_optimal\cb1 \
\cb2                 \cb1 \
\cb2                 run_recovery_rates.append(recovery_rate)\cb1 \
\cb2                 \cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  run_recovery_rates:\cb1 \
\cb2                 recovery_rates.append(np.mean(run_recovery_rates))\cb1 \
\cb2                 \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  recovery_rates\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 compute_recovery_time_for_seed\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 rewards\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Compute recovery time for a seed's rewards"""\cf0 \cb1 \strokec3 \
\cb2         \cf6 \strokec6 # Simplified recovery time calculation\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvA"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 100\cf0 \strokec3 ]\cb1 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.9\cf0 \strokec3 ]\cb1 \
\cb2             threshold_ratio = \cf10 \strokec10 0.85\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvB"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 40\cf0 \strokec3 , \cf10 \strokec10 80\cf0 \strokec3 , \cf10 \strokec10 120\cf0 \strokec3 , \cf10 \strokec10 160\cf0 \strokec3 ]\cb1 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 , \cf10 \strokec10 0.95\cf0 \strokec3 ]\cb1 \
\cb2             threshold_ratio = \cf10 \strokec10 0.90\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 elif\cf0 \strokec3  env_name == \cf5 \strokec5 "EnvC"\cf0 \strokec3 :\cb1 \
\cb2             change_points = [\cf10 \strokec10 50\cf0 \strokec3 , \cf10 \strokec10 100\cf0 \strokec3 , \cf10 \strokec10 150\cf0 \strokec3 ]\cb1 \
\cb2             optimal_rewards = [\cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.85\cf0 \strokec3 , \cf10 \strokec10 0.8\cf0 \strokec3 , \cf10 \strokec10 0.85\cf0 \strokec3 ]\cb1 \
\cb2             threshold_ratio = \cf10 \strokec10 0.85\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 else\cf0 \strokec3 :\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  []\cb1 \
\cb2             \cb1 \
\cb2         recovery_times = []\cb1 \
\cb2         analysis_window = \cf10 \strokec10 50\cf0 \cb1 \strokec3 \
\cb2         stability_window = \cf10 \strokec10 5\cf0 \cb1 \strokec3 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  run_idx \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (rewards.shape[\cf10 \strokec10 0\cf0 \strokec3 ]):\cb1 \
\cb2             run_rewards = rewards[run_idx]\cb1 \
\cb2             run_recovery_times = []\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  change_idx, change_point \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (change_points):\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  change_point >= \cf8 \strokec8 len\cf0 \strokec3 (run_rewards) - \cf10 \strokec10 10\cf0 \strokec3 :\cb1 \
\cb2                     \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                 segment_optimal = optimal_rewards[\cf8 \strokec8 min\cf0 \strokec3 (change_idx, \cf8 \strokec8 len\cf0 \strokec3 (optimal_rewards) - \cf10 \strokec10 1\cf0 \strokec3 )]\cb1 \
\cb2                 threshold = segment_optimal * threshold_ratio\cb1 \
\cb2                 \cb1 \
\cb2                 post_change_start = change_point\cb1 \
\cb2                 post_change_end = \cf8 \strokec8 min\cf0 \strokec3 (change_point + analysis_window, \cf8 \strokec8 len\cf0 \strokec3 (run_rewards))\cb1 \
\cb2                 post_change_rewards = run_rewards[post_change_start:post_change_end]\cb1 \
\cb2                 \cb1 \
\cb2                 recovery_time = \cf8 \strokec8 len\cf0 \strokec3 (post_change_rewards)\cb1 \
\cb2                 \cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 3\cf0 \strokec3 , \cf8 \strokec8 len\cf0 \strokec3 (post_change_rewards) - stability_window + \cf10 \strokec10 1\cf0 \strokec3 ):\cb1 \
\cb2                     window = post_change_rewards[i:i + stability_window]\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  np.mean(window) >= threshold:\cb1 \
\cb2                         recovery_time = i + stability_window // \cf10 \strokec10 2\cf0 \cb1 \strokec3 \
\cb2                         \cf4 \strokec4 break\cf0 \cb1 \strokec3 \
\cb2                         \cb1 \
\cb2                 run_recovery_times.append(recovery_time)\cb1 \
\cb2                 \cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  run_recovery_times:\cb1 \
\cb2                 recovery_times.append(np.mean(run_recovery_times))\cb1 \
\cb2                 \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  recovery_times\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 create_comprehensive_bonferroni_table\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "output"\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5         Create comprehensive Bonferroni correction table matching the example format\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Creating comprehensive Bonferroni correction table..."\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         all_comparisons = []\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Process EnvA-C results\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  env_name, env_results \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .complete_results.items():\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "  Processing \cf0 \strokec3 \{env_name\}\cf5 \strokec5 ..."\cf0 \strokec3 )\cb1 \
\cb2             \cb1 \
\cb2             \cf6 \strokec6 # Define metrics to test\cf0 \cb1 \strokec3 \
\cb2             metrics = [\cb1 \
\cb2                 (\cf5 \strokec5 'Overall Performance'\cf0 \strokec3 , \cf5 \strokec5 'overall_performance'\cf0 \strokec3 ),\cb1 \
\cb2                 (\cf5 \strokec5 'Recovery Rate'\cf0 \strokec3 , \cf5 \strokec5 'recovery_rate'\cf0 \strokec3 ), \cb1 \
\cb2                 (\cf5 \strokec5 'Recovery Time'\cf0 \strokec3 , \cf5 \strokec5 'recovery_time'\cf0 \strokec3 )\cb1 \
\cb2             ]\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  metric_display_name, metric_type \cf7 \strokec7 in\cf0 \strokec3  metrics:\cb1 \
\cb2                 \cf6 \strokec6 # Extract agent data for this metric\cf0 \cb1 \strokec3 \
\cb2                 agent_data = \{\}\cb1 \
\cb2                 \cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  agent_name, agent_result \cf7 \strokec7 in\cf0 \strokec3  env_results.items():\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  agent_result[\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 ][\cf5 \strokec5 'n_master_seeds'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                         seed_data = \cf9 \strokec9 self\cf0 \strokec3 .extract_metric_data_from_pkl(agent_result, metric_type, env_name)\cb1 \
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (seed_data) >= \cf10 \strokec10 3\cf0 \strokec3 :  \cf6 \strokec6 # Minimum for statistical testing\cf0 \cb1 \strokec3 \
\cb2                             agent_data[agent_name] = seed_data\cb1 \
\
\cb2                 \cf6 \strokec6 # Perform pairwise comparisons\cf0 \cb1 \strokec3 \
\cb2                 agent_names = \cf11 \strokec11 list\cf0 \strokec3 (agent_data.keys())\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                     \cf4 \strokec4 for\cf0 \strokec3  j \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (i+\cf10 \strokec10 1\cf0 \strokec3 , \cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                         agent1, agent2 = agent_names[i], agent_names[j]\cb1 \
\cb2                         data1, data2 = agent_data[agent1], agent_data[agent2]\cb1 \
\
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data1) >= \cf10 \strokec10 3\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data2) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2                             \cf6 \strokec6 # Perform comprehensive statistical testing\cf0 \cb1 \strokec3 \
\cb2                             test_name, statistic, p_value, equal_var_result, p_levene, normal_1, normal_2, p_norm_1, p_norm_2 = \cf9 \strokec9 self\cf0 \strokec3 .choose_statistical_test(data1, data2)\cb1 \
\cb2                             \cb1 \
\cb2                             \cf6 \strokec6 # Calculate effect size\cf0 \cb1 \strokec3 \
\cb2                             cohens_d = \cf9 \strokec9 self\cf0 \strokec3 .calculate_cohens_d(data1, data2)\cb1 \
\cb2                             effect_size_interp = \cf9 \strokec9 self\cf0 \strokec3 .interpret_effect_size(cohens_d)\cb1 \
\
\cb2                             comparison = \{\cb1 \
\cb2                                 \cf5 \strokec5 'Environment'\cf0 \strokec3 : env_name,\cb1 \
\cb2                                 \cf5 \strokec5 'Metric'\cf0 \strokec3 : metric_display_name,\cb1 \
\cb2                                 \cf5 \strokec5 'Agent_1'\cf0 \strokec3 : agent1,\cb1 \
\cb2                                 \cf5 \strokec5 'Agent_2'\cf0 \strokec3 : agent2,\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_1'\cf0 \strokec3 : np.mean(data1),\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_2'\cf0 \strokec3 : np.mean(data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Std_1'\cf0 \strokec3 : np.std(data1, ddof=\cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                                 \cf5 \strokec5 'Std_2'\cf0 \strokec3 : np.std(data2, ddof=\cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                                 \cf5 \strokec5 'N_Seeds_1'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (data1),\cb1 \
\cb2                                 \cf5 \strokec5 'N_Seeds_2'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_Difference'\cf0 \strokec3 : np.mean(data1) - np.mean(data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Test_Used'\cf0 \strokec3 : test_name,\cb1 \
\cb2                                 \cf5 \strokec5 'Statistic'\cf0 \strokec3 : statistic,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 : p_value,\cb1 \
\cb2                                 \cf5 \strokec5 'Cohens_D'\cf0 \strokec3 : cohens_d,\cb1 \
\cb2                                 \cf5 \strokec5 'Effect_Size'\cf0 \strokec3 : effect_size_interp,\cb1 \
\cb2                                 \cf5 \strokec5 'Normal_1'\cf0 \strokec3 : normal_1,\cb1 \
\cb2                                 \cf5 \strokec5 'Normal_2'\cf0 \strokec3 : normal_2,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Normality_1'\cf0 \strokec3 : p_norm_1,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Normality_2'\cf0 \strokec3 : p_norm_2,\cb1 \
\cb2                                 \cf5 \strokec5 'Equal_Variances'\cf0 \strokec3 : equal_var_result,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Levene'\cf0 \strokec3 : p_levene \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  np.isnan(p_levene) \cf4 \strokec4 else\cf0 \strokec3  \cf5 \strokec5 "N/A"\cf0 \strokec3 ,\cb1 \
\cb2                                 \cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 : p_value < \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\cb2                             \}\cb1 \
\cb2                             \cb1 \
\cb2                             all_comparisons.append(comparison)\cb1 \
\
\cb2         \cf6 \strokec6 # Process cross-dataset results if available\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "  Processing Cross-Dataset..."\cf0 \strokec3 )\cb1 \
\cb2             \cb1 \
\cb2             metrics = [\cb1 \
\cb2                 (\cf5 \strokec5 'Overall Performance'\cf0 \strokec3 , \cf5 \strokec5 'overall_performance'\cf0 \strokec3 ),\cb1 \
\cb2                 (\cf5 \strokec5 'Recovery Rate'\cf0 \strokec3 , \cf5 \strokec5 'recovery_rate'\cf0 \strokec3 ),\cb1 \
\cb2                 (\cf5 \strokec5 'Recovery Time'\cf0 \strokec3 , \cf5 \strokec5 'recovery_time'\cf0 \strokec3 )\cb1 \
\cb2             ]\cb1 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  metric_display_name, metric_type \cf7 \strokec7 in\cf0 \strokec3  metrics:\cb1 \
\cb2                 agent_data = \{\}\cb1 \
\cb2                 \cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  agent_name, agent_result \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results.items():\cb1 \
\cb2                     seed_data = \cf9 \strokec9 self\cf0 \strokec3 .extract_cross_dataset_seed_data(agent_result, metric_type)\cb1 \
\cb2                     \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (seed_data) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2                         agent_data[agent_name] = seed_data\cb1 \
\
\cb2                 \cf6 \strokec6 # Perform pairwise comparisons\cf0 \cb1 \strokec3 \
\cb2                 agent_names = \cf11 \strokec11 list\cf0 \strokec3 (agent_data.keys())\cb1 \
\cb2                 \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                     \cf4 \strokec4 for\cf0 \strokec3  j \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (i+\cf10 \strokec10 1\cf0 \strokec3 , \cf8 \strokec8 len\cf0 \strokec3 (agent_names)):\cb1 \
\cb2                         agent1, agent2 = agent_names[i], agent_names[j]\cb1 \
\cb2                         data1, data2 = agent_data[agent1], agent_data[agent2]\cb1 \
\
\cb2                         \cf4 \strokec4 if\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data1) >= \cf10 \strokec10 3\cf0 \strokec3  \cf7 \strokec7 and\cf0 \strokec3  \cf8 \strokec8 len\cf0 \strokec3 (data2) >= \cf10 \strokec10 3\cf0 \strokec3 :\cb1 \
\cb2                             test_name, statistic, p_value, equal_var_result, p_levene, normal_1, normal_2, p_norm_1, p_norm_2 = \cf9 \strokec9 self\cf0 \strokec3 .choose_statistical_test(data1, data2)\cb1 \
\cb2                             \cb1 \
\cb2                             cohens_d = \cf9 \strokec9 self\cf0 \strokec3 .calculate_cohens_d(data1, data2)\cb1 \
\cb2                             effect_size_interp = \cf9 \strokec9 self\cf0 \strokec3 .interpret_effect_size(cohens_d)\cb1 \
\
\cb2                             comparison = \{\cb1 \
\cb2                                 \cf5 \strokec5 'Environment'\cf0 \strokec3 : \cf5 \strokec5 'Cross-Dataset'\cf0 \strokec3 ,\cb1 \
\cb2                                 \cf5 \strokec5 'Metric'\cf0 \strokec3 : metric_display_name,\cb1 \
\cb2                                 \cf5 \strokec5 'Agent_1'\cf0 \strokec3 : agent1,\cb1 \
\cb2                                 \cf5 \strokec5 'Agent_2'\cf0 \strokec3 : agent2,\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_1'\cf0 \strokec3 : np.mean(data1),\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_2'\cf0 \strokec3 : np.mean(data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Std_1'\cf0 \strokec3 : np.std(data1, ddof=\cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                                 \cf5 \strokec5 'Std_2'\cf0 \strokec3 : np.std(data2, ddof=\cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                                 \cf5 \strokec5 'N_Seeds_1'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (data1),\cb1 \
\cb2                                 \cf5 \strokec5 'N_Seeds_2'\cf0 \strokec3 : \cf8 \strokec8 len\cf0 \strokec3 (data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Mean_Difference'\cf0 \strokec3 : np.mean(data1) - np.mean(data2),\cb1 \
\cb2                                 \cf5 \strokec5 'Test_Used'\cf0 \strokec3 : test_name,\cb1 \
\cb2                                 \cf5 \strokec5 'Statistic'\cf0 \strokec3 : statistic,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 : p_value,\cb1 \
\cb2                                 \cf5 \strokec5 'Cohens_D'\cf0 \strokec3 : cohens_d,\cb1 \
\cb2                                 \cf5 \strokec5 'Effect_Size'\cf0 \strokec3 : effect_size_interp,\cb1 \
\cb2                                 \cf5 \strokec5 'Normal_1'\cf0 \strokec3 : normal_1,\cb1 \
\cb2                                 \cf5 \strokec5 'Normal_2'\cf0 \strokec3 : normal_2,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Normality_1'\cf0 \strokec3 : p_norm_1,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Normality_2'\cf0 \strokec3 : p_norm_2,\cb1 \
\cb2                                 \cf5 \strokec5 'Equal_Variances'\cf0 \strokec3 : equal_var_result,\cb1 \
\cb2                                 \cf5 \strokec5 'P_Levene'\cf0 \strokec3 : p_levene \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  np.isnan(p_levene) \cf4 \strokec4 else\cf0 \strokec3  \cf5 \strokec5 "N/A"\cf0 \strokec3 ,\cb1 \
\cb2                                 \cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 : p_value < \cf10 \strokec10 0.05\cf0 \cb1 \strokec3 \
\cb2                             \}\cb1 \
\cb2                             \cb1 \
\cb2                             all_comparisons.append(comparison)\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  all_comparisons:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " No valid comparisons found"\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \strokec3  \cf7 \strokec7 None\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Apply Bonferroni correction\cf0 \cb1 \strokec3 \
\cb2         p_values = [comp[\cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 ] \cf4 \strokec4 for\cf0 \strokec3  comp \cf7 \strokec7 in\cf0 \strokec3  all_comparisons]\cb1 \
\cb2         rejected, p_corrected = \cf9 \strokec9 self\cf0 \strokec3 .bonferroni_correction(p_values)\cb1 \
\
\cb2         \cf6 \strokec6 # Add corrected results\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i, comparison \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 enumerate\cf0 \strokec3 (all_comparisons):\cb1 \
\cb2             comparison[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ] = p_corrected[i]\cb1 \
\cb2             comparison[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ] = rejected[i]\cb1 \
\
\cb2         \cf6 \strokec6 # Create DataFrame\cf0 \cb1 \strokec3 \
\cb2         df = pd.DataFrame(all_comparisons)\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Save results\cf0 \cb1 \strokec3 \
\cb2         os.makedirs(save_path, exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2         csv_path = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /significant_results_bonferroni.csv"\cf0 \cb1 \strokec3 \
\cb2         df.to_csv(csv_path, index=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Saved comprehensive Bonferroni table: \cf0 \strokec3 \{csv_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Total comparisons: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (df)\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant before correction: \cf0 \strokec3 \{df[\cf5 \strokec5 'Significant_Raw'\cf0 \strokec3 ].\cf8 \strokec8 sum\cf0 \strokec3 ()\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Significant after Bonferroni: \cf0 \strokec3 \{df[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ].\cf8 \strokec8 sum\cf0 \strokec3 ()\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2       \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  df\cb1 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 create_environment_specific_bonferroni_tables\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 complete_df\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Create separate Bonferroni tables for each environment with all metrics"""\cf0 \cb1 \strokec3 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Creating environment-specific Bonferroni tables..."\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Create separate tables for each environment\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  env_name \cf7 \strokec7 in\cf0 \strokec3  complete_df[\cf5 \strokec5 'Environment'\cf0 \strokec3 ].unique():\cb1 \
\cb2             env_df = complete_df[complete_df[\cf5 \strokec5 'Environment'\cf0 \strokec3 ] == env_name].copy()\cb1 \
\cb2             \cb1 \
\cb2             \cf6 \strokec6 # Re-apply Bonferroni correction for this environment only\cf0 \cb1 \strokec3 \
\cb2             env_p_values = env_df[\cf5 \strokec5 'P_Value_Raw'\cf0 \strokec3 ].values\cb1 \
\cb2             env_rejected, env_p_corrected = \cf9 \strokec9 self\cf0 \strokec3 .bonferroni_correction(env_p_values)\cb1 \
\cb2             \cb1 \
\cb2             env_df[\cf5 \strokec5 'P_Value_Bonferroni'\cf0 \strokec3 ] = env_p_corrected\cb1 \
\cb2             env_df[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ] = env_rejected\cb1 \
\cb2             \cb1 \
\cb2             \cf6 \strokec6 # Save environment-specific table\cf0 \cb1 \strokec3 \
\cb2             env_csv_path = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /bonferroni_all_metrics_\cf0 \strokec3 \{env_name\}\cf5 \strokec5 .csv"\cf0 \cb1 \strokec3 \
\cb2             env_df.to_csv(env_csv_path, index=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2             \cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Saved \cf0 \strokec3 \{env_name\}\cf5 \strokec5 : \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (env_df)\}\cf5 \strokec5  comparisons, \cf0 \strokec3 \{env_df[\cf5 \strokec5 'Significant_Bonferroni'\cf0 \strokec3 ].\cf8 \strokec8 sum\cf0 \strokec3 ()\}\cf5 \strokec5  significant"\cf0 \strokec3 )\cb1 \
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 calculate_adaptation_speed\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 agent_result\cf0 \strokec3 , \cf9 \strokec9 env_name\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Calculate adaptation speed metric (placeholder implementation)"""\cf0 \cb1 \strokec3 \
\cb2         \cf6 \strokec6 # This would need to be implemented based on your specific definition\cf0 \cb1 \strokec3 \
\cb2         \cf6 \strokec6 # For now, return a placeholder value\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  \cf10 \strokec10 0.5\cf0 \strokec3 , \cf10 \strokec10 0.1\cf0 \strokec3   \cf6 \strokec6 # mean, std\cf0 \cb1 \strokec3 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 create_wide_format_summary\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "output"\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5         Create wide format summary table matching the example format\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Creating wide format summary table..."\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         summary_data = []\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Process EnvA-C results\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  env_name, env_results \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .complete_results.items():\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  agent_name, agent_result \cf7 \strokec7 in\cf0 \strokec3  env_results.items():\cb1 \
\cb2                 \cf4 \strokec4 if\cf0 \strokec3  agent_result[\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 ][\cf5 \strokec5 'n_master_seeds'\cf0 \strokec3 ] > \cf10 \strokec10 0\cf0 \strokec3 :\cb1 \
\cb2                     meta_stats = agent_result[\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 ]\cb1 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Calculate 95% confidence intervals\cf0 \cb1 \strokec3 \
\cb2                     overall_ci_lower = meta_stats.get(\cf5 \strokec5 'ci_lower'\cf0 \strokec3 , meta_stats[\cf5 \strokec5 'meta_mean'\cf0 \strokec3 ])\cb1 \
\cb2                     overall_ci_upper = meta_stats.get(\cf5 \strokec5 'ci_upper'\cf0 \strokec3 , meta_stats[\cf5 \strokec5 'meta_mean'\cf0 \strokec3 ])\cb1 \
\cb2                     overall_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{overall_ci_lower\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{overall_ci_upper\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                     recovery_rate_ci_lower = meta_stats.get(\cf5 \strokec5 'recovery_rate_ci_lower'\cf0 \strokec3 , meta_stats.get(\cf5 \strokec5 'meta_recovery_rate_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     recovery_rate_ci_upper = meta_stats.get(\cf5 \strokec5 'recovery_rate_ci_upper'\cf0 \strokec3 , meta_stats.get(\cf5 \strokec5 'meta_recovery_rate_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     recovery_rate_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{recovery_rate_ci_lower\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{recovery_rate_ci_upper\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                     recovery_time_ci_lower = meta_stats.get(\cf5 \strokec5 'recovery_time_ci_lower'\cf0 \strokec3 , meta_stats.get(\cf5 \strokec5 'meta_recovery_time_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     recovery_time_ci_upper = meta_stats.get(\cf5 \strokec5 'recovery_time_ci_upper'\cf0 \strokec3 , meta_stats.get(\cf5 \strokec5 'meta_recovery_time_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ))\cb1 \
\cb2                     recovery_time_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{recovery_time_ci_lower\cf10 \strokec10 :.2f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{recovery_time_ci_upper\cf10 \strokec10 :.2f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Calculate adaptation speed (placeholder)\cf0 \cb1 \strokec3 \
\cb2                     adapt_speed_mean, adapt_speed_std = \cf9 \strokec9 self\cf0 \strokec3 .calculate_adaptation_speed(agent_result, env_name)\cb1 \
\cb2                     adapt_speed_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{adapt_speed_mean\cf10 \strokec10 -1.96\cf0 \strokec3 *adapt_speed_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{adapt_speed_mean+\cf10 \strokec10 1.96\cf0 \strokec3 *adapt_speed_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                     \cb1 \
\cb2                     row = \{\cb1 \
\cb2                         \cf5 \strokec5 'Agent'\cf0 \strokec3 : agent_name,\cb1 \
\cb2                         \cf5 \strokec5 'Environment'\cf0 \strokec3 : env_name,\cb1 \
\cb2                         \cf5 \strokec5 'Agent_Environment'\cf0 \strokec3 : \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{agent_name\}\cf5 \strokec5 _\cf0 \strokec3 \{env_name\}\cf5 \strokec5 "\cf0 \strokec3 ,\cb1 \
\cb2                         \cb1 \
\cb2                         \cf6 \strokec6 # Overall Performance\cf0 \cb1 \strokec3 \
\cb2                         \cf5 \strokec5 'Overall Performance_Mean'\cf0 \strokec3 : meta_stats[\cf5 \strokec5 'meta_mean'\cf0 \strokec3 ],\cb1 \
\cb2                         \cf5 \strokec5 'Overall Performance_95%CI'\cf0 \strokec3 : overall_ci_str,\cb1 \
\cb2                         \cf5 \strokec5 'Overall Performance_STD'\cf0 \strokec3 : meta_stats[\cf5 \strokec5 'meta_std'\cf0 \strokec3 ],\cb1 \
\cb2                         \cb1 \
\cb2                         \cf6 \strokec6 # Recovery Rate\cf0 \cb1 \strokec3 \
\cb2                         \cf5 \strokec5 'Recovery Rate_Mean'\cf0 \strokec3 : meta_stats.get(\cf5 \strokec5 'meta_recovery_rate_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                         \cf5 \strokec5 'Recovery Rate_95%CI'\cf0 \strokec3 : recovery_rate_ci_str,\cb1 \
\cb2                         \cf5 \strokec5 'Recovery Rate_STD'\cf0 \strokec3 : meta_stats.get(\cf5 \strokec5 'meta_recovery_rate_std'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                         \cb1 \
\cb2                         \cf6 \strokec6 # Recovery Time\cf0 \cb1 \strokec3 \
\cb2                         \cf5 \strokec5 'Recovery Time_Mean'\cf0 \strokec3 : meta_stats.get(\cf5 \strokec5 'meta_recovery_time_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                         \cf5 \strokec5 'Recovery Time_95%CI'\cf0 \strokec3 : recovery_time_ci_str,\cb1 \
\cb2                         \cf5 \strokec5 'Recovery Time_STD'\cf0 \strokec3 : meta_stats.get(\cf5 \strokec5 'meta_recovery_time_std'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 ),\cb1 \
\cb2                         \cb1 \
\cb2                         \cf6 \strokec6 # Adaptation Speed\cf0 \cb1 \strokec3 \
\cb2                         \cf5 \strokec5 'Adaptation Speed_Mean'\cf0 \strokec3 : adapt_speed_mean,\cb1 \
\cb2                         \cf5 \strokec5 'Adaptation Speed_95%CI'\cf0 \strokec3 : adapt_speed_ci_str,\cb1 \
\cb2                         \cf5 \strokec5 'Adaptation Speed_STD'\cf0 \strokec3 : adapt_speed_std\cb1 \
\cb2                     \}\cb1 \
\cb2                     \cb1 \
\cb2                     summary_data.append(row)\cb1 \
\
\cb2         \cf6 \strokec6 # Process cross-dataset results if available\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results:\cb1 \
\cb2             \cf4 \strokec4 for\cf0 \strokec3  agent_name, agent_result \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .cross_dataset_results.items():\cb1 \
\cb2                 meta_stats = agent_result[\cf5 \strokec5 'meta_statistics'\cf0 \strokec3 ]\cb1 \
\cb2                 \cb1 \
\cb2                 \cf6 \strokec6 # Calculate 95% confidence intervals for cross-dataset\cf0 \cb1 \strokec3 \
\cb2                 overall_mean = meta_stats.get(\cf5 \strokec5 'overall_performance_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 overall_std = meta_stats.get(\cf5 \strokec5 'overall_performance_std'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 overall_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{overall_mean\cf10 \strokec10 -1.96\cf0 \strokec3 *overall_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{overall_mean+\cf10 \strokec10 1.96\cf0 \strokec3 *overall_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                 \cb1 \
\cb2                 recovery_rate_mean = meta_stats.get(\cf5 \strokec5 'recovery_rate_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 recovery_rate_std = meta_stats.get(\cf5 \strokec5 'recovery_rate_std'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 recovery_rate_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{recovery_rate_mean\cf10 \strokec10 -1.96\cf0 \strokec3 *recovery_rate_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{recovery_rate_mean+\cf10 \strokec10 1.96\cf0 \strokec3 *recovery_rate_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                 \cb1 \
\cb2                 recovery_time_mean = meta_stats.get(\cf5 \strokec5 'recovery_time_mean'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 recovery_time_std = meta_stats.get(\cf5 \strokec5 'recovery_time_std'\cf0 \strokec3 , \cf10 \strokec10 0\cf0 \strokec3 )\cb1 \
\cb2                 recovery_time_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{recovery_time_mean\cf10 \strokec10 -1.96\cf0 \strokec3 *recovery_time_std\cf10 \strokec10 :.2f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{recovery_time_mean+\cf10 \strokec10 1.96\cf0 \strokec3 *recovery_time_std\cf10 \strokec10 :.2f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                 \cb1 \
\cb2                 \cf6 \strokec6 # Adaptation speed for cross-dataset\cf0 \cb1 \strokec3 \
\cb2                 adapt_speed_mean, adapt_speed_std = \cf10 \strokec10 0.6\cf0 \strokec3 , \cf10 \strokec10 0.12\cf0 \strokec3   \cf6 \strokec6 # Placeholder\cf0 \cb1 \strokec3 \
\cb2                 adapt_speed_ci_str = \cf7 \strokec7 f\cf5 \strokec5 "[\cf0 \strokec3 \{adapt_speed_mean\cf10 \strokec10 -1.96\cf0 \strokec3 *adapt_speed_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 , \cf0 \strokec3 \{adapt_speed_mean+\cf10 \strokec10 1.96\cf0 \strokec3 *adapt_speed_std\cf10 \strokec10 :.4f\cf0 \strokec3 \}\cf5 \strokec5 ]"\cf0 \cb1 \strokec3 \
\cb2                 \cb1 \
\cb2                 row = \{\cb1 \
\cb2                     \cf5 \strokec5 'Agent'\cf0 \strokec3 : agent_name,\cb1 \
\cb2                     \cf5 \strokec5 'Environment'\cf0 \strokec3 : \cf5 \strokec5 'Cross-Dataset'\cf0 \strokec3 ,\cb1 \
\cb2                     \cf5 \strokec5 'Agent_Environment'\cf0 \strokec3 : \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{agent_name\}\cf5 \strokec5 _Cross-Dataset"\cf0 \strokec3 ,\cb1 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Overall Performance\cf0 \cb1 \strokec3 \
\cb2                     \cf5 \strokec5 'Overall Performance_Mean'\cf0 \strokec3 : overall_mean,\cb1 \
\cb2                     \cf5 \strokec5 'Overall Performance_95%CI'\cf0 \strokec3 : overall_ci_str,\cb1 \
\cb2                     \cf5 \strokec5 'Overall Performance_STD'\cf0 \strokec3 : overall_std,\cb1 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Recovery Rate\cf0 \cb1 \strokec3 \
\cb2                     \cf5 \strokec5 'Recovery Rate_Mean'\cf0 \strokec3 : recovery_rate_mean,\cb1 \
\cb2                     \cf5 \strokec5 'Recovery Rate_95%CI'\cf0 \strokec3 : recovery_rate_ci_str,\cb1 \
\cb2                     \cf5 \strokec5 'Recovery Rate_STD'\cf0 \strokec3 : recovery_rate_std,\cb1 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Recovery Time\cf0 \cb1 \strokec3 \
\cb2                     \cf5 \strokec5 'Recovery Time_Mean'\cf0 \strokec3 : recovery_time_mean,\cb1 \
\cb2                     \cf5 \strokec5 'Recovery Time_95%CI'\cf0 \strokec3 : recovery_time_ci_str,\cb1 \
\cb2                     \cf5 \strokec5 'Recovery Time_STD'\cf0 \strokec3 : recovery_time_std,\cb1 \
\cb2                     \cb1 \
\cb2                     \cf6 \strokec6 # Adaptation Speed\cf0 \cb1 \strokec3 \
\cb2                     \cf5 \strokec5 'Adaptation Speed_Mean'\cf0 \strokec3 : adapt_speed_mean,\cb1 \
\cb2                     \cf5 \strokec5 'Adaptation Speed_95%CI'\cf0 \strokec3 : adapt_speed_ci_str,\cb1 \
\cb2                     \cf5 \strokec5 'Adaptation Speed_STD'\cf0 \strokec3 : adapt_speed_std\cb1 \
\cb2                 \}\cb1 \
\cb2                 \cb1 \
\cb2                 summary_data.append(row)\cb1 \
\
\cb2         \cf6 \strokec6 # Create DataFrame\cf0 \cb1 \strokec3 \
\cb2         df = pd.DataFrame(summary_data)\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Save results\cf0 \cb1 \strokec3 \
\cb2         os.makedirs(save_path, exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\cb2         csv_path = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /fibonacci_environments_wide_format.csv"\cf0 \cb1 \strokec3 \
\cb2         df.to_csv(csv_path, index=\cf7 \strokec7 False\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Saved wide format summary: \cf0 \strokec3 \{csv_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Total Agent-Environment combinations: \cf0 \strokec3 \{\cf8 \strokec8 len\cf0 \strokec3 (df)\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  df\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 extract_emotion_trajectories\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "output"\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Extract emotion trajectory plots from .npy files"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Emotion data path not provided"\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 import\cf0 \strokec3  matplotlib.pyplot \cf4 \strokec4 as\cf0 \strokec3  plt\cb1 \
\cb2         \cb1 \
\cb2         emotion_names = [\cb1 \
\cb2             \cf5 \strokec5 "Fear"\cf0 \strokec3 , \cf5 \strokec5 "Joy"\cf0 \strokec3 , \cf5 \strokec5 "Hope"\cf0 \strokec3 , \cf5 \strokec5 "Sadness"\cf0 \strokec3 ,\cb1 \
\cb2             \cf5 \strokec5 "Curiosity"\cf0 \strokec3 , \cf5 \strokec5 "Anger"\cf0 \strokec3 , \cf5 \strokec5 "Pride"\cf0 \strokec3 , \cf5 \strokec5 "Shame"\cf0 \cb1 \strokec3 \
\cb2         ]\cb1 \
\
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Creating emotion trajectory plots..."\cf0 \strokec3 )\cb1 \
\cb2         os.makedirs(save_path, exist_ok=\cf7 \strokec7 True\cf0 \strokec3 )\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  env_name \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .environments:\cb1 \
\cb2             emotion_file = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path\}\cf5 \strokec5 /emotion_data_\cf0 \strokec3 \{env_name\}\cf5 \strokec5 .npy"\cf0 \cb1 \strokec3 \
\cb2             \cb1 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  os.path.exists(emotion_file):\cb1 \
\cb2                 \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Emotion file not found: \cf0 \strokec3 \{emotion_file\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2                 \cf4 \strokec4 continue\cf0 \cb1 \strokec3 \
\
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "  Creating emotion trajectory plot for \cf0 \strokec3 \{env_name\}\cf5 \strokec5 ..."\cf0 \strokec3 )\cb1 \
\
\cb2             \cf6 \strokec6 # Load emotion data\cf0 \cb1 \strokec3 \
\cb2             emotion_data = np.load(emotion_file)  \cf6 \strokec6 # Shape: [n_runs, n_trials, 8]\cf0 \cb1 \strokec3 \
\
\cb2             \cf6 \strokec6 # Calculate average emotion trajectories across runs\cf0 \cb1 \strokec3 \
\cb2             avg_emotions = np.mean(emotion_data, axis=\cf10 \strokec10 0\cf0 \strokec3 )  \cf6 \strokec6 # Shape: [n_trials, 8]\cf0 \cb1 \strokec3 \
\cb2             std_emotions = np.std(emotion_data, axis=\cf10 \strokec10 0\cf0 \strokec3 )   \cf6 \strokec6 # Shape: [n_trials, 8]\cf0 \cb1 \strokec3 \
\
\cb2             n_trials = avg_emotions.shape[\cf10 \strokec10 0\cf0 \strokec3 ]\cb1 \
\cb2             trials = np.arange(n_trials)\cb1 \
\
\cb2             \cf6 \strokec6 # Create 4x2 subplot (4 rows, 2 columns)\cf0 \cb1 \strokec3 \
\cb2             fig, axes = plt.subplots(\cf10 \strokec10 4\cf0 \strokec3 , \cf10 \strokec10 2\cf0 \strokec3 , figsize=(\cf10 \strokec10 12\cf0 \strokec3 , \cf10 \strokec10 16\cf0 \strokec3 ))\cb1 \
\cb2             axes = axes.flatten()\cb1 \
\
\cb2             colors = [\cf5 \strokec5 '#d62728'\cf0 \strokec3 , \cf5 \strokec5 '#ff7f0e'\cf0 \strokec3 , \cf5 \strokec5 '#2ca02c'\cf0 \strokec3 , \cf5 \strokec5 '#1f77b4'\cf0 \strokec3 ,\cb1 \
\cb2                       \cf5 \strokec5 '#9467bd'\cf0 \strokec3 , \cf5 \strokec5 '#8c564b'\cf0 \strokec3 , \cf5 \strokec5 '#e377c2'\cf0 \strokec3 , \cf5 \strokec5 '#7f7f7f'\cf0 \strokec3 ]\cb1 \
\
\cb2             \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 8\cf0 \strokec3 ):\cb1 \
\cb2                 ax = axes[i]\cb1 \
\cb2                 emotion_name = emotion_names[i]\cb1 \
\
\cb2                 \cf6 \strokec6 # Plot mean trajectory\cf0 \cb1 \strokec3 \
\cb2                 ax.plot(trials, avg_emotions[:, i], color=colors[i], linewidth=\cf10 \strokec10 2\cf0 \strokec3 ,\cb1 \
\cb2                         label=\cf7 \strokec7 f\cf5 \strokec5 'Mean \cf0 \strokec3 \{emotion_name\}\cf5 \strokec5 '\cf0 \strokec3 )\cb1 \
\
\cb2                 \cf6 \strokec6 # Plot confidence interval (mean \'b1 std)\cf0 \cb1 \strokec3 \
\cb2                 ax.fill_between(trials,\cb1 \
\cb2                                avg_emotions[:, i] - std_emotions[:, i],\cb1 \
\cb2                                avg_emotions[:, i] + std_emotions[:, i],\cb1 \
\cb2                                color=colors[i], alpha=\cf10 \strokec10 0.3\cf0 \strokec3 )\cb1 \
\
\cb2                 ax.set_title(\cf7 \strokec7 f\cf5 \strokec5 '\cf0 \strokec3 \{emotion_name\}\cf5 \strokec5 '\cf0 \strokec3 , fontweight=\cf5 \strokec5 'bold'\cf0 \strokec3 , fontsize=\cf10 \strokec10 12\cf0 \strokec3 )\cb1 \
\cb2                 ax.set_xlabel(\cf5 \strokec5 'Trial'\cf0 \strokec3 )\cb1 \
\cb2                 ax.set_ylabel(\cf5 \strokec5 'Emotion Intensity'\cf0 \strokec3 )\cb1 \
\cb2                 ax.grid(\cf7 \strokec7 True\cf0 \strokec3 , alpha=\cf10 \strokec10 0.3\cf0 \strokec3 )\cb1 \
\cb2                 ax.set_ylim(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2                 \cf6 \strokec6 # Add some stats\cf0 \cb1 \strokec3 \
\cb2                 mean_intensity = np.mean(avg_emotions[:, i])\cb1 \
\cb2                 ax.text(\cf10 \strokec10 0.02\cf0 \strokec3 , \cf10 \strokec10 0.98\cf0 \strokec3 , \cf7 \strokec7 f\cf5 \strokec5 'Avg: \cf0 \strokec3 \{mean_intensity\cf10 \strokec10 :.3f\cf0 \strokec3 \}\cf5 \strokec5 '\cf0 \strokec3 ,\cb1 \
\cb2                         transform=ax.transAxes, fontsize=\cf10 \strokec10 9\cf0 \strokec3 ,\cb1 \
\cb2                         bbox=\cf11 \strokec11 dict\cf0 \strokec3 (boxstyle=\cf5 \strokec5 "round,pad=0.3"\cf0 \strokec3 , facecolor=\cf5 \strokec5 "white"\cf0 \strokec3 , alpha=\cf10 \strokec10 0.8\cf0 \strokec3 ),\cb1 \
\cb2                         verticalalignment=\cf5 \strokec5 'top'\cf0 \strokec3 )\cb1 \
\
\cb2             plt.suptitle(\cf7 \strokec7 f\cf5 \strokec5 'ECIA_Full Emotion Trajectories - \cf0 \strokec3 \{env_name\}\cf5 \strokec5 \\n'\cf0 \cb1 \strokec3 \
\cb2                          \cf7 \strokec7 f\cf5 \strokec5 'Average across \cf0 \strokec3 \{emotion_data.shape[\cf10 \strokec10 0\cf0 \strokec3 ]\}\cf5 \strokec5  runs'\cf0 \strokec3 ,\cb1 \
\cb2                          fontsize=\cf10 \strokec10 14\cf0 \strokec3 , fontweight=\cf5 \strokec5 'bold'\cf0 \strokec3 )\cb1 \
\cb2             plt.tight_layout()\cb1 \
\
\cb2             \cf6 \strokec6 # Save plot\cf0 \cb1 \strokec3 \
\cb2             plot_path = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /emotion_trajectories_\cf0 \strokec3 \{env_name\}\cf5 \strokec5 .png"\cf0 \cb1 \strokec3 \
\cb2             plt.savefig(plot_path, dpi=\cf10 \strokec10 300\cf0 \strokec3 , bbox_inches=\cf5 \strokec5 'tight'\cf0 \strokec3 )\cb1 \
\cb2             plt.close()\cb1 \
\
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Saved emotion plot: \cf0 \strokec3 \{plot_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Create comparison plot for all environments\cf0 \cb1 \strokec3 \
\cb2         \cf9 \strokec9 self\cf0 \strokec3 .create_emotion_comparison_plot(save_path)\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 create_emotion_comparison_plot\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Create comparison plot showing all environments together"""\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path:\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         \cf4 \strokec4 import\cf0 \strokec3  matplotlib.pyplot \cf4 \strokec4 as\cf0 \strokec3  plt\cb1 \
\cb2         \cb1 \
\cb2         emotion_names = [\cb1 \
\cb2             \cf5 \strokec5 "Fear"\cf0 \strokec3 , \cf5 \strokec5 "Joy"\cf0 \strokec3 , \cf5 \strokec5 "Hope"\cf0 \strokec3 , \cf5 \strokec5 "Sadness"\cf0 \strokec3 ,\cb1 \
\cb2             \cf5 \strokec5 "Curiosity"\cf0 \strokec3 , \cf5 \strokec5 "Anger"\cf0 \strokec3 , \cf5 \strokec5 "Pride"\cf0 \strokec3 , \cf5 \strokec5 "Shame"\cf0 \cb1 \strokec3 \
\cb2         ]\cb1 \
\
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "  Creating emotion comparison plot..."\cf0 \strokec3 )\cb1 \
\
\cb2         \cf6 \strokec6 # Load all data\cf0 \cb1 \strokec3 \
\cb2         all_env_data = \{\}\cb1 \
\cb2         \cf4 \strokec4 for\cf0 \strokec3  env_name \cf7 \strokec7 in\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .environments:\cb1 \
\cb2             emotion_file = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{\cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path\}\cf5 \strokec5 /emotion_data_\cf0 \strokec3 \{env_name\}\cf5 \strokec5 .npy"\cf0 \cb1 \strokec3 \
\cb2             \cf4 \strokec4 if\cf0 \strokec3  os.path.exists(emotion_file):\cb1 \
\cb2                 emotion_data = np.load(emotion_file)\cb1 \
\cb2                 avg_emotions = np.mean(emotion_data, axis=\cf10 \strokec10 0\cf0 \strokec3 )  \cf6 \strokec6 # Average across runs\cf0 \cb1 \strokec3 \
\cb2                 all_env_data[env_name] = avg_emotions\cb1 \
\
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf7 \strokec7 not\cf0 \strokec3  all_env_data:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   No emotion data found for comparison plot"\cf0 \strokec3 )\cb1 \
\cb2             \cf4 \strokec4 return\cf0 \cb1 \strokec3 \
\
\cb2         \cf6 \strokec6 # Create comparison plot - 4x2 layout\cf0 \cb1 \strokec3 \
\cb2         fig, axes = plt.subplots(\cf10 \strokec10 4\cf0 \strokec3 , \cf10 \strokec10 2\cf0 \strokec3 , figsize=(\cf10 \strokec10 12\cf0 \strokec3 , \cf10 \strokec10 16\cf0 \strokec3 ))\cb1 \
\cb2         axes = axes.flatten()\cb1 \
\
\cb2         colors = \{\cf5 \strokec5 'EnvA'\cf0 \strokec3 : \cf5 \strokec5 '#1f77b4'\cf0 \strokec3 , \cf5 \strokec5 'EnvB'\cf0 \strokec3 : \cf5 \strokec5 '#ff7f0e'\cf0 \strokec3 , \cf5 \strokec5 'EnvC'\cf0 \strokec3 : \cf5 \strokec5 '#2ca02c'\cf0 \strokec3 \}\cb1 \
\
\cb2         \cf4 \strokec4 for\cf0 \strokec3  i \cf7 \strokec7 in\cf0 \strokec3  \cf8 \strokec8 range\cf0 \strokec3 (\cf10 \strokec10 8\cf0 \strokec3 ):\cb1 \
\cb2             ax = axes[i]\cb1 \
\cb2             emotion_name = emotion_names[i]\cb1 \
\
\cb2             \cf4 \strokec4 for\cf0 \strokec3  env_name, avg_emotions \cf7 \strokec7 in\cf0 \strokec3  all_env_data.items():\cb1 \
\cb2                 trials = np.arange(\cf8 \strokec8 len\cf0 \strokec3 (avg_emotions))\cb1 \
\cb2                 ax.plot(trials, avg_emotions[:, i],\cb1 \
\cb2                        color=colors[env_name], linewidth=\cf10 \strokec10 2\cf0 \strokec3 ,\cb1 \
\cb2                        label=env_name, alpha=\cf10 \strokec10 0.8\cf0 \strokec3 )\cb1 \
\
\cb2             ax.set_title(\cf7 \strokec7 f\cf5 \strokec5 '\cf0 \strokec3 \{emotion_name\}\cf5 \strokec5 '\cf0 \strokec3 , fontweight=\cf5 \strokec5 'bold'\cf0 \strokec3 , fontsize=\cf10 \strokec10 12\cf0 \strokec3 )\cb1 \
\cb2             ax.set_xlabel(\cf5 \strokec5 'Trial'\cf0 \strokec3 )\cb1 \
\cb2             ax.set_ylabel(\cf5 \strokec5 'Emotion Intensity'\cf0 \strokec3 )\cb1 \
\cb2             ax.grid(\cf7 \strokec7 True\cf0 \strokec3 , alpha=\cf10 \strokec10 0.3\cf0 \strokec3 )\cb1 \
\cb2             ax.set_ylim(\cf10 \strokec10 0\cf0 \strokec3 , \cf10 \strokec10 1\cf0 \strokec3 )\cb1 \
\
\cb2             \cf4 \strokec4 if\cf0 \strokec3  i == \cf10 \strokec10 0\cf0 \strokec3 :  \cf6 \strokec6 # Add legend to first subplot\cf0 \cb1 \strokec3 \
\cb2                 ax.legend(loc=\cf5 \strokec5 'upper right'\cf0 \strokec3 )\cb1 \
\
\cb2         plt.suptitle(\cf5 \strokec5 'ECIA_Full Emotion Trajectories - Environment Comparison'\cf0 \strokec3 ,\cb1 \
\cb2                      fontsize=\cf10 \strokec10 16\cf0 \strokec3 , fontweight=\cf5 \strokec5 'bold'\cf0 \strokec3 )\cb1 \
\cb2         plt.tight_layout()\cb1 \
\
\cb2         \cf6 \strokec6 # Save comparison plot\cf0 \cb1 \strokec3 \
\cb2         comparison_path = \cf7 \strokec7 f\cf5 \strokec5 "\cf0 \strokec3 \{save_path\}\cf5 \strokec5 /emotion_comparison_all_environments.png"\cf0 \cb1 \strokec3 \
\cb2         plt.savefig(comparison_path, dpi=\cf10 \strokec10 300\cf0 \strokec3 , bbox_inches=\cf5 \strokec5 'tight'\cf0 \strokec3 )\cb1 \
\cb2         plt.close()\cb1 \
\
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   Saved emotion comparison plot: \cf0 \strokec3 \{comparison_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\
\cb2     \cf7 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 run_complete_analysis\cf0 \strokec3 (\cf9 \strokec9 self\cf0 \strokec3 , \cf9 \strokec9 save_path\cf0 \strokec3 =\cf5 \strokec5 "output"\cf0 \strokec3 ):\cb1 \
\cb2         \cf5 \strokec5 """Run complete statistical analysis with ALL metrics"""\cf0 \cb1 \strokec3 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Starting comprehensive statistical analysis with ALL metrics..."\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 60\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "  Processing:"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 Wide format summary tables"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 Comprehensive Bonferroni (ALL metrics)"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 Environment-specific Bonferroni tables"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 Emotion trajectories (if available)"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 60\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Create statistical tables\cf0 \cb1 \strokec3 \
\cb2         bonferroni_df = \cf9 \strokec9 self\cf0 \strokec3 .create_comprehensive_bonferroni_table(save_path)\cb1 \
\cb2         wide_format_df = \cf9 \strokec9 self\cf0 \strokec3 .create_wide_format_summary(save_path)\cb1 \
\cb2         \cb1 \
\cb2         \cf6 \strokec6 # Create emotion trajectories if emotion data available\cf0 \cb1 \strokec3 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path:\cb1 \
\cb2             \cf9 \strokec9 self\cf0 \strokec3 .extract_emotion_trajectories(save_path)\cb1 \
\cb2         \cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 60\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Complete statistical analysis finished!"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Files saved to: \cf0 \strokec3 \{save_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n Generated files:"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 comprehensive_bonferroni_all_metrics.csv - All environments & metrics"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 bonferroni_all_metrics_EnvA.csv - EnvA with all metrics"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 bonferroni_all_metrics_EnvB.csv - EnvB with all metrics"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 bonferroni_all_metrics_EnvC.csv - EnvC with all metrics"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 bonferroni_all_metrics_Cross-Dataset.csv - Cross-dataset with all metrics"\cf0 \strokec3 )\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 fibonacci_environments_wide_format.csv - Agent-Environment summary"\cf0 \strokec3 )\cb1 \
\cb2         \cf4 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 self\cf0 \strokec3 .emotion_data_path:\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 emotion_trajectories_EnvX.png - Emotion plots"\cf0 \strokec3 )\cb1 \
\cb2             \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "   \'95 emotion_comparison_all_environments.png - Environment comparison"\cf0 \strokec3 )\cb1 \
\cb2         \cb1 \
\cb2         \cf4 \strokec4 return\cf0 \strokec3  bonferroni_df, wide_format_df\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # Main execution function\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf7 \cb2 \strokec7 def\cf0 \strokec3  \cf8 \strokec8 run_advanced_statistical_analysis\cf0 \strokec3 (\cf9 \strokec9 results_pkl_path\cf0 \strokec3 , \cf9 \strokec9 cross_dataset_pkl_path\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 , \cf9 \strokec9 emotion_data_path\cf0 \strokec3 =\cf7 \strokec7 None\cf0 \strokec3 , \cf9 \strokec9 output_path\cf0 \strokec3 =\cf5 \strokec5 "statistical_output"\cf0 \strokec3 ):\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf5 \strokec5 """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf5 \cb2 \strokec5     Main function to run advanced statistical analysis\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5     \cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5     Args:\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         results_pkl_path: Path to complete_results_full.pkl\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         cross_dataset_pkl_path: Path to cross_dataset results (optional)\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         emotion_data_path: Path to directory containing emotion .npy files (optional)\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5         output_path: Output directory\cf0 \cb1 \strokec3 \
\cf5 \cb2 \strokec5     """\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " ADVANCED STATISTICAL ANALYSIS TOOL"\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 50\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 " Input files:"\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   \'95 EnvA-C results: \cf0 \strokec3 \{results_pkl_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 if\cf0 \strokec3  cross_dataset_pkl_path:\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   \'95 Cross-dataset results: \cf0 \strokec3 \{cross_dataset_pkl_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf4 \strokec4 if\cf0 \strokec3  emotion_data_path:\cb1 \
\cb2         \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 "   \'95 Emotion data: \cf0 \strokec3 \{emotion_data_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf7 \strokec7 f\cf5 \strokec5 " Output directory: \cf0 \strokec3 \{output_path\}\cf5 \strokec5 "\cf0 \strokec3 )\cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "="\cf0 \strokec3  * \cf10 \strokec10 50\cf0 \strokec3 )\cb1 \
\cb2     \cb1 \
\cb2     \cf6 \strokec6 # Initialize analyzer\cf0 \cb1 \strokec3 \
\cb2     analyzer = AdvancedStatisticalAnalyzer(\cb1 \
\cb2         results_pkl_path=results_pkl_path,\cb1 \
\cb2         cross_dataset_pkl_path=cross_dataset_pkl_path,\cb1 \
\cb2         emotion_data_path=emotion_data_path\cb1 \
\cb2     )\cb1 \
\cb2     \cb1 \
\cb2     \cf6 \strokec6 # Run complete analysis\cf0 \cb1 \strokec3 \
\cb2     bonferroni_df, wide_format_df = analyzer.run_complete_analysis(output_path)\cb1 \
\cb2     \cb1 \
\cb2     \cf4 \strokec4 return\cf0 \strokec3  analyzer, bonferroni_df, wide_format_df\cb1 \
\
\
\pard\pardeftab720\partightenfactor0
\cf6 \cb2 \strokec6 # Example usage\cf0 \cb1 \strokec3 \
\pard\pardeftab720\partightenfactor0
\cf4 \cb2 \strokec4 if\cf0 \strokec3  \cf9 \strokec9 __name__\cf0 \strokec3  == \cf5 \strokec5 "__main__"\cf0 \strokec3 :\cb1 \
\pard\pardeftab720\partightenfactor0
\cf0 \cb2     \cf6 \strokec6 # Set your file paths here\cf0 \cb1 \strokec3 \
\cb2     RESULTS_PKL = \cf5 \strokec5 "content/Results/complete_results_full.pkl"\cf0 \cb1 \strokec3 \
\cb2     CROSS_DATASET_PKL = \cf5 \strokec5 "content/Results/complete_cross_dataset_results_unified.pkl"\cf0 \cb1 \strokec3 \
\cb2     EMOTION_DATA_DIR = \cf5 \strokec5 "content/Results"\cf0 \strokec3   \cf6 \strokec6 # Directory containing .npy files\cf0 \cb1 \strokec3 \
\cb2     OUTPUT_DIR = \cf5 \strokec5 "statistical_analysis_output"\cf0 \cb1 \strokec3 \
\cb2     \cb1 \
\cb2     \cf6 \strokec6 # Run analysis\cf0 \cb1 \strokec3 \
\cb2     analyzer, bonferroni_df, wide_format_df = run_advanced_statistical_analysis(\cb1 \
\cb2         results_pkl_path=RESULTS_PKL,\cb1 \
\cb2         cross_dataset_pkl_path=CROSS_DATASET_PKL,\cb1 \
\cb2         emotion_data_path=EMOTION_DATA_DIR,\cb1 \
\cb2         output_path=OUTPUT_DIR\cb1 \
\cb2     )\cb1 \
\cb2     \cb1 \
\cb2     \cf8 \strokec8 print\cf0 \strokec3 (\cf5 \strokec5 "\\n COMPREHENSIVE STATISTICAL ANALYSIS COMPLETED!"\cf0 \strokec3 )\cb1 \
\
}